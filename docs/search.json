[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cohort analysis",
    "section": "",
    "text": "Preface\nThis “book” is an iterative reworking of Chapter 4 of Tanimura (2021).\n\n\n\n\nTanimura, C. 2021. SQL for Data Analysis. O’Reilly Media. https://books.google.com.au/books?id=ojhCEAAAQBAJ.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "original_sql.html",
    "href": "original_sql.html",
    "title": "1  Cohort Analysis – Original",
    "section": "",
    "text": "1.1 Cohorts: A Useful Analysis Framework\nIn Chapter 3 we covered time series analysis. With those techniques in hand, we will now turn to a related type of analysis with many business and other applications: cohort analysis.\nI remember the first time I encountered a cohort analysis. I was working at my first data analyst job, at a small startup. I was reviewing a purchase analysis I’d worked on with the CEO, and he suggested that I break up the customer base by cohorts to see whether behavior was changing over time. I assumed it was some fancy business school thing and probably useless, but he was the CEO, so of course I humored him. Turns out it wasn’t just a lark. Breaking populations into cohorts and following them over time is a powerful way to analyze your data and avoid various biases. Cohorts can provide clues to how subpopulations differ from each other and how they change over time.\nIn this chapter, we’ll first take a look at what cohorts are and at the building blocks of certain types of cohort analysis. After an introduction to the legislators data set used for the examples, we’ll learn how to construct a retention analysis and deal with various challenges such as defining the cohort and handling sparse data. Next, we’ll cover survivorship, returnship, and cumulative calculations, all of which are similar to retention analysis in the way the SQL code is structured. Finally, we’ll look at how to combine cohort analysis with cross-sectional analysis to understand the makeup of populations over time.\nBefore we get into the code, I will define what cohorts are, consider the types of questions we can answer with this type of analysis, and describe the components of any cohort analysis.\nA cohort is a group of individuals who share some characteristic of interest, described below, at the time we start observing them. Cohort members are often people but can be any type of entity we want to study: companies, products, or physical world phenomena. Individuals in a cohort may be aware of their membership, just as children in a first-grade class are aware they are part of a peer group of first graders, or participants in a drug trial are aware they are part of a group receiving a treatment. At other times, entities are grouped into cohorts virtually, as when a software company groups all customers acquired in a certain year to study how long they remain customers. It’s always important to consider the ethical implications of cohorting entities without their awareness, if any different treatment is to be applied to them.\nCohort analysis is a useful way to compare groups of entities over time. Many important behaviors take weeks, months, or years to occur or evolve, and cohort analysis is a way to understand these changes. Cohort analysis provides a framework for detecting correlations between cohort characteristics and these long-term trends, which can lead to hypotheses about the causal drivers. For example, customers acquired through a marketing campaign may have different long-term purchase patterns than those who were persuaded by a friend to try a company’s products. Cohort analysis can be used to monitor new cohorts of users or customers and assess how they compare to previous cohorts. Such monitoring can provide an early alert signal that something has gone wrong (or right) for new customers. Cohort analysis is also used to mine historical data. A/B tests, discussed in Chapter 7, are the gold standard for determining causality, but we can’t go back in time and run every test for every question about the past in which we are interested. We should of course be cautious about attaching causal meaning to cohort analysis and instead use cohort analysis as a way to understand customers and generate hypotheses that can be tested rigorously in the future.\nCohort analyses have three components: the cohort grouping, a time series of data over which the cohort is observed, and an aggregate metric that measures an action done by cohort members.\nCohort grouping is often based on a start date: the customer’s first purchase or subscription date, the date a student started school, and so on. However, cohorts can also be formed around other characteristics that are either innate or changing over time. Innate qualities include birth year and country of origin, or the year a company was founded. Characteristics that can change over time include city of residence and marital status. When these are used, we need to be careful to cohort only on the value on the starting date, or else entities can jump between cohort groups.\nThe second component of any cohort analysis is the time series. This is a series of purchases, logins, interactions, or other actions that are taken by the customers or entities to be cohorted. It’s important that the time series covers the entire life span of the entities, or there will be survivorship bias in early cohorts. Survivorship bias occurs when only customers who have stayed are in the data set; churned customers are excluded because they are no longer around, so the rest of the customers appear to be of higher quality or fit in comparison to newer cohorts (see “Survivorship Bias”). It’s also important to have a time series that is long enough for the entities to complete the action of interest. For example, if customers tend to purchase once a month, a time series of several months is needed. If, on the other hand, purchases happen only once a year, a time series of several years would be preferable. Inevitably, more recently acquired customers will not have had as long to complete actions as those customers who were acquired further in the past. In order to normalize, cohort analysis usually measures the number of periods that have elapsed from a starting date, rather than calendar months. In this way, cohorts can be compared in period 1, period 2, and so on to see how they evolve over time, regardless of which month the action actually occurred. The intervals may be days, weeks, months, or years.\nThe aggregate metric should be related to the actions that matter to the health of the organization, such as customers continuing to use or purchase the product. Metric values are aggregated across the cohort, usually with sum, count, or average, though any relevant aggregation works. The result is a time series that can then be used to understand changes in behavior over time.\nIn this chapter, I’ll cover four types of cohort analysis: retention, survivorship, returnship or repeat purchase behavior, and cumulative behavior.\nThe four types of cohort analysis allow us to compare subgroups and understand how they differ over time in order to make better product, marketing, and financial decisions. The calculations for the different types are similar, so we will set the stage with retention, and then I’ll show how to modify retention code to calculate the other types. Before we dive into constructing our cohort analysis, let’s take a look at the data set we’ll be using for the examples in this chapter.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Cohort Analysis -- Original</span>"
    ]
  },
  {
    "objectID": "original_sql.html#cohorts-a-useful-analysis-framework",
    "href": "original_sql.html#cohorts-a-useful-analysis-framework",
    "title": "1  Cohort Analysis – Original",
    "section": "",
    "text": "Cohort or Segment?\n\n\n\nThese two terms are often used in similar ways, or even interchangeably, but it’s worth drawing a distinction between them for the sake of clarity. A cohort is a group of users (or other entities) who have a common starting date and are followed over time. A segment is a grouping of users who share a common characteristic or set of characteristics at a point in time, regardless of their starting date. Similar to cohorts, segments can be based on innate factors such as age or on behavioral characteristics. A segment of users that signs up in the same month can be put into a cohort and followed over time. Or different groupings of users can be explored with cohort analysis so that you can see which ones have the most valuable characteristics. The analyses we’ll cover in this chapter, such as retention, can help put concrete data behind marketing segments.\n\n\n\n\n\n\nRetention\n\nRetention is concerned with whether the cohort member has a record in the time series on a particular date, expressed as a number of periods from the starting date. This is useful in any kind of organization in which repeated actions are expected, from playing an online game to using a product or renewing a subscription, and it helps to answer questions about how sticky or engaging a product is and how many entities can be expected to appear on future dates.\n\nSurvivorship\n\nSurvivorship is concerned with how many entities remained in the data set for a certain length of time or longer, regardless of the number or frequency of actions up to that time. Survivorship is useful for answering questions about the proportion of the population that can be expected to remain—either in a positive sense by not churning or passing away, or in a negative sense by not graduating or fulfilling some requirement.\n\nReturnship\n\nReturnship or repeat purchase behavior is concerned with whether an action has happened more than some minimum threshold of times—often simply more than once—during a fixed window of time. This type of analysis is useful in situations in which the behavior is intermittent and unpredictable, such as in retail, where it characterizes the share of repeat purchasers in each cohort within a fixed time window.\n\nCumulative\n\nCumulative calculations are concerned with the total number or amounts measured at one or more fixed time windows, regardless of when they happened during that window. Cumulative calculations are often used in calculations of customer lifetime value (LTV or CLTV).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Cohort Analysis -- Original</span>"
    ]
  },
  {
    "objectID": "original_sql.html#the-legislators-data-set",
    "href": "original_sql.html#the-legislators-data-set",
    "title": "1  Cohort Analysis – Original",
    "section": "1.2 The Legislators Data Set",
    "text": "1.2 The Legislators Data Set\nThe SQL examples in this chapter will use a data set of past and present members of the United States Congress maintained in a GitHub repository. In the US, Congress is responsible for writing laws or legislation, so its members are also known as legislators. Since the data set is a JSON file, I have applied some transformations to produce a more suitable data model for analysis, and I have posted data in a format suitable for following along with the examples in the book’s GitHub legislators folder.\nThe source repository has an excellent data dictionary, so I won’t repeat all the details here. I will provide a few details, however, that should help those who aren’t familiar with the US government to follow along with the analyses in this chapter.\nCongress has two chambers, the Senate (“sen” in the data set) and the House of Representatives (“rep”). Each state has two senators, and they are elected for six-year terms. Representatives are allocated to states based on population; each representative has a district that they alone represent. Representatives are elected for two-year terms. Actual terms in either chamber can be shorter in the event that the legislator dies or is elected or appointed to a higher office. Legislators accumulate power and influence via leadership positions the longer they are in office, and thus standing for re-election is common. Finally, a legislator may belong to a political party, or they may be an “independent”. In the modern era, the vast majority of legislators are Democrats or Republicans, and the rivalry between the two parties is well known. Legislators occasionally change parties while in office.\nFor the analyses, we’ll make use of two tables: legislators and legislators_terms. The legislators table contains a list of all the people included in the data set, with birthday, gender, and a set of ID fields that can be used to look up the person in other data sets. The legislators_terms table contains a record for each term in office for each legislator, with start and end date, and other attributes such as chamber and id_bioguide field is used as the unique identifier of a legislator and appears in each table. Table 3.1 shows a sample of the legislators data. Table 3.2 shows a sample of the legislators_terms data.\n\n\n\n\nTable 1.1: Sample of the legislators table\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                full_name\n                first_name\n                last_name\n                birthday\n                gender\n                id_bioguide\n                id_govtrack\n              \n        \n        \n        \n                \n                  Sherrod Brown        \n                  Sherrod \n                  Brown     \n                  1952-11-09\n                  M\n                  B000944\n                  400050\n                \n                \n                  Maria Cantwell       \n                  Maria   \n                  Cantwell  \n                  1958-10-13\n                  F\n                  C000127\n                  300018\n                \n                \n                  Benjamin L. Cardin   \n                  Benjamin\n                  Cardin    \n                  1943-10-05\n                  M\n                  C000141\n                  400064\n                \n                \n                  Thomas R. Carper     \n                  Thomas  \n                  Carper    \n                  1947-01-23\n                  M\n                  C000174\n                  300019\n                \n                \n                  Robert P. Casey, Jr. \n                  Robert  \n                  Casey     \n                  1960-04-13\n                  M\n                  C001070\n                  412246\n                \n                \n                  Dianne Feinstein     \n                  Dianne  \n                  Feinstein \n                  1933-06-22\n                  F\n                  F000062\n                  300043\n                \n                \n                  Russ Fulcher         \n                  Russ    \n                  Fulcher   \n                  1973-07-19\n                  M\n                  F000469\n                  412773\n                \n                \n                  Amy Klobuchar        \n                  Amy     \n                  Klobuchar \n                  1960-05-25\n                  F\n                  K000367\n                  412242\n                \n                \n                  Robert Menendez      \n                  Robert  \n                  Menendez  \n                  1954-01-01\n                  M\n                  M000639\n                  400272\n                \n                \n                  Bernard Sanders      \n                  Bernard \n                  Sanders   \n                  1941-09-08\n                  M\n                  S000033\n                  400357\n                \n                \n                  Debbie Stabenow      \n                  Debbie  \n                  Stabenow  \n                  1950-04-29\n                  F\n                  S000770\n                  300093\n                \n                \n                  Jon Tester           \n                  Jon     \n                  Tester    \n                  1956-08-21\n                  M\n                  T000464\n                  412244\n                \n                \n                  Sheldon Whitehouse   \n                  Sheldon \n                  Whitehouse\n                  1955-10-20\n                  M\n                  W000802\n                  412247\n                \n                \n                  Nanette Diaz Barragán\n                  Nanette \n                  Barragán  \n                  1976-09-15\n                  F\n                  B001300\n                  412687\n                \n                \n                  John Barrasso        \n                  John    \n                  Barrasso  \n                  1952-07-21\n                  M\n                  B001261\n                  412251\n                \n                \n                  Roger F. Wicker      \n                  Roger   \n                  Wicker    \n                  1951-07-05\n                  M\n                  W000437\n                  400432\n                \n                \n                  Lamar Alexander      \n                  Lamar   \n                  Alexander \n                  1940-07-03\n                  M\n                  A000360\n                  300002\n                \n                \n                  Susan M. Collins     \n                  Susan   \n                  Collins   \n                  1952-12-07\n                  F\n                  C001035\n                  300025\n                \n                \n                  John Cornyn          \n                  John    \n                  Cornyn    \n                  1952-02-02\n                  M\n                  C001056\n                  300027\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n\n\nTable 1.2: Sample of the legislators_terms table\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                id_bioguide\n                term_id\n                term_type\n                term_start\n                term_end\n                state\n                district\n                party\n              \n        \n        \n        \n                \n                  B000944\n                  B000944-0\n                  rep\n                  1993-01-05\n                  1995-01-03\n                  OH\n                  13\n                  Democrat   \n                \n                \n                  C000127\n                  C000127-0\n                  rep\n                  1993-01-05\n                  1995-01-03\n                  WA\n                   1\n                  Democrat   \n                \n                \n                  C000141\n                  C000141-0\n                  rep\n                  1987-01-06\n                  1989-01-03\n                  MD\n                   3\n                  Democrat   \n                \n                \n                  C000174\n                  C000174-0\n                  rep\n                  1983-01-03\n                  1985-01-03\n                  DE\n                   0\n                  Democrat   \n                \n                \n                  C001070\n                  C001070-0\n                  sen\n                  2007-01-04\n                  2013-01-03\n                  PA\n                  NA\n                  Democrat   \n                \n                \n                  F000062\n                  F000062-0\n                  sen\n                  1992-11-10\n                  1995-01-03\n                  CA\n                  NA\n                  Democrat   \n                \n                \n                  F000469\n                  F000469-0\n                  rep\n                  2019-01-03\n                  2021-01-03\n                  ID\n                   1\n                  Republican \n                \n                \n                  K000367\n                  K000367-0\n                  sen\n                  2007-01-04\n                  2013-01-03\n                  MN\n                  NA\n                  Democrat   \n                \n                \n                  M000639\n                  M000639-0\n                  rep\n                  1993-01-05\n                  1995-01-03\n                  NJ\n                  13\n                  Democrat   \n                \n                \n                  S000033\n                  S000033-0\n                  rep\n                  1991-01-03\n                  1993-01-03\n                  VT\n                   0\n                  Independent\n                \n                \n                  S000770\n                  S000770-0\n                  rep\n                  1997-01-07\n                  1999-01-03\n                  MI\n                   8\n                  Democrat   \n                \n                \n                  T000464\n                  T000464-0\n                  sen\n                  2007-01-04\n                  2013-01-03\n                  MT\n                  NA\n                  Democrat   \n                \n                \n                  W000802\n                  W000802-0\n                  sen\n                  2007-01-04\n                  2013-01-03\n                  RI\n                  NA\n                  Democrat   \n                \n                \n                  B001300\n                  B001300-0\n                  rep\n                  2017-01-03\n                  2019-01-03\n                  CA\n                  44\n                  Democrat   \n                \n                \n                  B001261\n                  B001261-0\n                  sen\n                  2007-06-25\n                  2013-01-03\n                  WY\n                  NA\n                  Republican \n                \n                \n                  W000437\n                  W000437-0\n                  rep\n                  1995-01-04\n                  1997-01-03\n                  MS\n                   1\n                  Republican \n                \n                \n                  A000360\n                  A000360-0\n                  sen\n                  2003-01-07\n                  2009-01-03\n                  TN\n                  NA\n                  Republican \n                \n                \n                  C001035\n                  C001035-0\n                  sen\n                  1997-01-07\n                  2003-01-03\n                  ME\n                  NA\n                  Republican \n                \n                \n                  C001056\n                  C001056-0\n                  sen\n                  2002-11-30\n                  2003-01-03\n                  TX\n                  NA\n                  Republican \n                \n        \n      \n    \n\n\n\n\n\n\nNow that we have an understanding of what cohort analysis is and of the data set we’ll be using for examples, let’s get into how to write SQL for retention analysis. The key question SQL will help us answer is: once representatives take office, how long do they keep their jobs?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Cohort Analysis -- Original</span>"
    ]
  },
  {
    "objectID": "original_sql.html#retention",
    "href": "original_sql.html#retention",
    "title": "1  Cohort Analysis – Original",
    "section": "1.3 Retention",
    "text": "1.3 Retention\nOne of the most common types of cohort analysis is retention analysis. To retain is to keep or continue something. Many skills need to be practiced to be retained. Businesses usually want their customers to keep purchasing their products or using their services, since retaining customers is more profitable than acquiring new ones. Employers want to retain their employees, because recruiting replacements is expensive and time consuming. Elected officials seek reelection in order to continue working on the priorities of their constituents.\nThe main question in retention analysis is whether the starting size of the cohort—number of subscribers or employees, amount spent, or another key metric—will remain constant, decay, or increase over time. When there is an increase or a decrease, the amount and speed of change are also interesting questions. In most retention analyses, the starting size will tend to decay over time, since a cohort can lose but cannot gain new members once it is formed. Revenue is an interesting exception, since a cohort of customers can spend more in subsequent months than they did in the first month collectively, even if some of them churn.\nRetention analysis uses the count of entities or sum of money or actions present in the data set for each period from the starting date, and it normalizes by dividing this number by the count or sum of entities, money, or actions in the first time period. The result is expressed as a percentage, and retention in the starting period is always 100%. Over time, retention based on counts generally declines and can never exceed 100%, whereas money- or action-based retention, while often declining, can increase and be greater than 100% in a time period. Retention analysis output is typically displayed in either table or graph form, which is referred to as a retention curve. We’ll see a number of examples of retention curves later in this chapter.\nGraphs of retention curves can be used to compare cohorts. The first characteristic to pay attention to is the shape of the curve in the initial few periods, where there is often an initial steep drop. For many consumer apps, losing half a cohort in the first few months is common. A cohort with a curve that is either more or less steep than others can indicate changes in the product or customer acquisition source that merit further investigation. A second characteristic to look for is whether the curve flattens after some number of periods or continues declining rapidly to zero. A flattening curve indicates that there is a point in time from which most of the cohort that remains stays indefinitely. A retention curve that inflects upward, sometimes called a smile curve, can occur if cohort members return or reactivate after falling out of the data set for some period. Finally, retention curves that measure subscription revenue are monitored for signs of increasing revenue per customer over time, a sign of a healthy SaaS software business.\nThis section will show how to create a retention analysis, add cohort groupings from the time series itself and other tables, and handle missing and sparse data that can occur in time series data. With this framework in hand, you’ll learn in the subsequent section how to make modifications to create the other related types of cohort analysis. As a result, this section on retention will be the longest one in the chapter, as you build up code and develop your intuition about the calculations.\n\n1.3.1 SQL for a Basic Retention Curve\n\nSELECT id_bioguide, min(term_start) AS first_term\nFROM legislators_terms \nGROUP BY 1;\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nfirst_term\n\n\n\n\nA000360\n2003-01-07\n\n\nC001035\n1997-01-07\n\n\nD000563\n1983-01-03\n\n\nS001194\n2012-12-27\n\n\nM001176\n2009-01-06\n\n\nR000122\n1991-01-03\n\n\nB001257\n2007-01-04\n\n\nC001075\n2009-01-06\n\n\nC001067\n2007-01-04\n\n\nD000598\n2001-01-03\n\n\n\n\n\nThe next step is to put this code into a subquery and JOIN it to the time series. The age function is applied to calculate the intervals between each term_start and the first_term for each legislator. Applying the date_part functions to the result, with year, transforms this into the number of yearly periods. Since elections happen every two or six years, we’ll use years as the time interval to calculate the periods. We could use a shorter interval, but in this data set there is little fluctuation daily or weekly. The count of legislators with records for that period is the number retained:\n\nSELECT date_part('year', age(b.term_start,a.first_term)) as period,\n  count(distinct a.id_bioguide) as cohort_retained\nFROM\n(\n    SELECT id_bioguide, min(term_start) as first_term\n    FROM legislators_terms \n    GROUP BY 1\n) a\nJOIN legislators_terms b \nON a.id_bioguide = b.id_bioguide \nGROUP BY 1\nORDER BY 1;\n\n\nDisplaying records 1 - 10\n\n\nperiod\ncohort_retained\n\n\n\n\n0\n12518\n\n\n1\n3600\n\n\n2\n3619\n\n\n3\n1831\n\n\n4\n3210\n\n\n5\n1744\n\n\n6\n2385\n\n\n7\n1360\n\n\n8\n1607\n\n\n9\n1028\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn databases that support the datediff function, the date_part-and-age construction can be replaced by this simpler function:\ndatediff('year', first_term, term_start)\nSome databases, such as Oracle, place the date_part last:\ndatediff(first_term, term_start, 'year')\n\n\nNow that we have the periods and the number of legislators retained in each, the final step is to calculate the total cohort_size and populate it in each row so that the cohort_retained can be divided by it. The first_value window function returns the first record in the PARTITION BY clause, according to the ordering set in the ORDER BY, a convenient way to get the cohort size in each row. In this case, the cohort_size comes from the first record in the entire data set, so the PARTITION BY is omitted:\nfirst_value(cohort_retained) over (order by period) as cohort_size\nTo find the percent retained, divide the cohort_retained value by this same calculation:\n\nSELECT period,\n  first_value(cohort_retained) over (order by period) as cohort_size,\n  cohort_retained,\n  cohort_retained / first_value(cohort_retained) over (order by period) as pct_retained\nFROM\n(\n    SELECT date_part('year',age(b.term_start,a.first_term)) as period,\n    count(distinct a.id_bioguide) as cohort_retained\n    FROM\n    (\n        SELECT id_bioguide, min(term_start) as first_term\n        FROM legislators_terms \n        GROUP BY 1\n    ) a\n    JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n    GROUP BY 1\n) aa\n\nWe now have a retention calculation, and we can see that there is a big drop-off between the 100% of legislators retained in period 0, or on their start date, and the share with another term record that starts a year later. Graphing the results, as in Figure 3.1, demonstrates how the curve flattens and eventually goes to zero, as even the longest-serving legislators eventually retire or die.\n\n\n\n\n\n\n\n\nFigure 1.1: Retention from start of first term for US legislators\n\n\n\n\n\nWe can take the cohort retention result and reshape the data to show it in table format. Pivot and flatten the results using an aggregate function with a CASE statement; max is used in this example, but other aggregations such as min or avg would return the same result. Retention is calculated for years 0 through 4, but additional years can be added by following the same pattern:\n\nSELECT cohort_size,\n  max(case when period = 0 then pct_retained end) as yr0,\n  max(case when period = 1 then pct_retained end) as yr1,\n  max(case when period = 2 then pct_retained end) as yr2,\n  max(case when period = 3 then pct_retained end) as yr3,\n  max(case when period = 4 then pct_retained end) as yr4\nFROM\n(\n    SELECT period,\n      first_value(cohort_retained) over (order by period) as cohort_size,\n      cohort_retained \n     / first_value(cohort_retained) over (order by period) as pct_retained\n    FROM\n    (\n        SELECT \n        date_part('year',age(b.term_start,a.first_term)) as period\n        ,count(*) as cohort_retained\n        FROM\n        (\n            SELECT id_bioguide, min(term_start) as first_term\n            FROM legislators_terms \n            GROUP BY 1\n        ) a\n        JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n        GROUP BY 1\n    ) aa\n) aaa\nGROUP BY 1\n\n\n1 records\n\n\ncohort_size\nyr0\nyr1\nyr2\nyr3\nyr4\n\n\n\n\n12647\n1\n0.2847316\n0.2865502\n0.1450146\n0.2539733\n\n\n\n\n\nRetention appears to be quite low, and from the graph we can see that it is jagged in the first few years. One reason for this is that a representative’s term lasts two years, and senators’ terms last six years, but the data set only contains records for the start of new terms; thus we are missing data for years in which a legislator was still in office but did not start a new term. Measuring retention each year is misleading in this case. One option is to measure retention only on a two- or six-year cycle, but there is also another strategy we can employ to fill in the “missing” data. I will cover this next before returning to the topic of forming cohort groups.\n\n\n1.3.2 Adjusting Time Series to Increase Retention Accuracy\nWe discussed techniques for cleaning “missing” data in Chapter 2, and we will turn to those techniques in this section in order to arrive at a smoother and more truthful retention curve for the legislators. When working with time series data, such as in cohort analysis, it’s important to consider not only the data that is present but also whether that data accurately reflects the presence or absence of entities at each time period. This is particularly a problem in contexts in which an event captured in the data leads to the entity persisting for some period of time that is not captured in the data. For example, a customer buying a software subscription is represented in the data at the time of the transaction, but that customer is entitled to use the software for months or years and is not necessarily represented in the data over that span. To correct for this, we need a way to derive the span of time in which the entity is still present, either with an explicit end date or with knowledge of the length of the subscription or term. Then we can say that the entity was present at any date in between those start and end dates.\nIn the legislators data set, we have a record for a term’s start date, but we are missing the notion that this “entitles” a legislator to serve for two or six years, depending on the chamber. To correct for this and smooth out the curve, we need to fill in the “missing” values for the years that legislators are still in office between new terms. Since this data set includes a term_end value for each term, I’ll show how to create a more accurate cohort retention analysis by filling in dates between the start and end values. Then I’ll show how you can impute end dates when the data set does not include an end date.\nCalculating retention using a start and end date defined in the data is the most accurate approach. For the following examples, we will consider legislators retained in a particular year if they were still in office as of the last day of the year, December 31. Prior to the Twentieth Amendment to the US Constitution, terms began on March 4, but afterward the start date moved to January 3, or to a subsequent weekday if the third falls on a weekend. Legislators can be sworn in on other days of the year due to special off-cycle elections or appointments to fill vacant seats. As a result, term_start dates cluster in January but are spread across the year. While we could pick another day, December 31 is a strategy for normalizing around these varying start dates.\nThe first step is to create a data set that contains a record for each December 31 that each legislator was in office. This can be accomplished by JOINing the subquery that found the first_term to the legislators_terms table to find the term_start and term_end for each term. A second JOIN to the date_dim retrieves the dates that fall between the start and end dates, restricting the returned values to c.month_name = 'December' and c.day_of_month = 31. The period is calculated as the years between the date from the date_dim and the first_term. Note that even though more than 11 months may have elapsed between being sworn in in January and December 31, the first year still appears as 0:\n\nSELECT a.id_bioguide, a.first_term,\n  b.term_start, b.term_end, c.date,\n  date_part('year',age(c.date,a.first_term)) as period\nFROM\n(\n    SELECT id_bioguide, min(term_start) as first_term\n    FROM legislators_terms \n    GROUP BY 1\n) a\nJOIN legislators_terms b on a.id_bioguide = b.id_bioguide \nLEFT JOIN date_dim c on c.date between b.term_start and b.term_end\nand c.month_name = 'December' and c.day_of_month = 31\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nfirst_term\nterm_start\nterm_end\ndate\nperiod\n\n\n\n\nM000031\n1789-03-04\n1789-03-04\n1791-03-03\n1789-12-31\n0\n\n\nM000031\n1789-03-04\n1789-03-04\n1791-03-03\n1790-12-31\n1\n\n\nG000500\n1789-03-04\n1789-03-04\n1791-03-03\n1789-12-31\n0\n\n\nG000500\n1789-03-04\n1789-03-04\n1791-03-03\n1790-12-31\n1\n\n\nH000995\n1789-03-04\n1789-03-04\n1791-03-03\n1789-12-31\n0\n\n\nH000995\n1789-03-04\n1789-03-04\n1791-03-03\n1790-12-31\n1\n\n\nB000546\n1789-03-04\n1789-03-04\n1791-03-03\n1789-12-31\n0\n\n\nB000546\n1789-03-04\n1789-03-04\n1791-03-03\n1790-12-31\n1\n\n\nB001086\n1789-03-04\n1789-03-04\n1791-03-03\n1789-12-31\n0\n\n\nB001086\n1789-03-04\n1789-03-04\n1791-03-03\n1790-12-31\n1\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf a date dimension is not available, you can create a subquery with the necessary dates in a couple of ways. If your database supports generate_series, you can create a subquery that returns the desired dates:\n\nSELECT generate_series::date as date\nFROM generate_series('1770-12-31'::date,\n                     '2020-12-31'::date,\n                     interval '1 year')\n\nYou may want to save this as a table or view for later use. Alternatively, you can query the data set or any other table in the database that has a full set of dates. In this case, the table has all of the necessary years, but we will make a December 31 date for each year using the make_date function:\n\nSELECT DISTINCT\n  make_date(date_part('year',term_start)::int, 12, 31) AS date\nFROM legislators_terms\nORDER BY date\n\nThere are a number of creative ways to get the series of dates needed. Use whichever method is available and simplest within your queries.\n\n\nWe now have a row for each date (year end) for which we would like to calculate retention. The next step is to calculate the cohort_retained for each period, which is done with a count of id_bioguide. A coalesce function is used on period to set a default value of 0 when null. This handles the cases in which a legislator’s term starts and ends in the same year, giving credit for serving in that year:\n\nSELECT \ncoalesce(date_part('year',age(c.date,a.first_term)),0) as period,\n  count(distinct a.id_bioguide) as cohort_retained\nFROM\n(\n    SELECT id_bioguide, min(term_start) as first_term\n    FROM legislators_terms \n    GROUP BY 1\n) a\nJOIN legislators_terms b on a.id_bioguide = b.id_bioguide \nLEFT JOIN date_dim c on c.date between b.term_start and b.term_end\nand c.month_name = 'December' and c.day_of_month = 31\nGROUP BY 1\nORDER BY 1\n\n\nDisplaying records 1 - 10\n\n\nperiod\ncohort_retained\n\n\n\n\n0\n12518\n\n\n1\n12328\n\n\n2\n8166\n\n\n3\n8069\n\n\n4\n5862\n\n\n5\n5795\n\n\n6\n4361\n\n\n7\n4339\n\n\n8\n3521\n\n\n9\n3485\n\n\n\n\n\nThe final step is to calculate the cohort_size and pct_retained as we did previously using first_value window functions:\n\nSELECT period,\n  first_value(cohort_retained) over (order by period) as cohort_size,\n  cohort_retained,\n  cohort_retained * 1.0 / \n    first_value(cohort_retained) over (order by period) as pct_retained\nFROM\n(\n    SELECT coalesce(date_part('year',age(c.date,a.first_term)),0) as period,\n      count(distinct a.id_bioguide) as cohort_retained\n    FROM\n    (\n        SELECT id_bioguide, min(term_start) as first_term\n        FROM legislators_terms \n        GROUP BY 1\n    ) a\n    JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n    LEFT JOIN date_dim c on c.date between b.term_start and b.term_end\n    and c.month_name = 'December' and c.day_of_month = 31\n    GROUP BY 1\n) aa\n\nThe results, graphed in Figure 3.2, are now much more accurate. Almost all legislators are still in office in year 1, and the first big drop-off occurs in year 2, when some representatives will fail to be reelected.\n\n\n\n\n\n\n\n\nFigure 1.2: Legislator retention after adjusting for actual years in office\n\n\n\n\n\nIf the data set does not contain an end date, there are a couple of options for imputing one. One option is to add a fixed interval to the start date, when the length of a subscription or term is known. This can be done with date math by adding a constant interval to the term_start. Here, a CASE statement handles the addition for the two term_types:\n\nSELECT a.id_bioguide, a.first_term,\n  b.term_start,\n  case when b.term_type = 'rep' then b.term_start + interval '2 years'\n      when b.term_type = 'sen' then b.term_start + interval '6 years'\n      end as term_end\nFROM\n(\n    SELECT id_bioguide, min(term_start) as first_term\n    FROM legislators_terms \n    GROUP BY 1\n) a\nJOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nfirst_term\nterm_start\nterm_end\n\n\n\n\nB000944\n1993-01-05\n1993-01-05\n1995-01-05\n\n\nC000127\n1993-01-05\n1993-01-05\n1995-01-05\n\n\nC000141\n1987-01-06\n1987-01-06\n1989-01-06\n\n\nC000174\n1983-01-03\n1983-01-03\n1985-01-03\n\n\nC001070\n2007-01-04\n2007-01-04\n2013-01-04\n\n\nF000062\n1992-11-10\n1992-11-10\n1998-11-10\n\n\nF000469\n2019-01-03\n2019-01-03\n2021-01-03\n\n\nK000367\n2007-01-04\n2007-01-04\n2013-01-04\n\n\nM000639\n1993-01-05\n1993-01-05\n1995-01-05\n\n\nS000033\n1991-01-03\n1991-01-03\n1993-01-03\n\n\n\n\n\nThis block of code can then be plugged into the retention code to derive the period and pct_retained. The drawback to this method is that it fails to capture instances in which a legislator did not complete a full term, which can happen in the event of death or appointment to a higher office.\nA second option is to use the subsequent starting date, minus one day, as the term_end date. This can be calculated with the lead window function. This function is similar to the lag function we’ve used previously, but rather than returning a value from a row earlier in the partition, it returns a value from a row later in the partition, as determined in the ORDER BY clause. The default is one row, which we will use here, but the function has an optional argument indicating a different number of rows. Here we find the term_start date of the subsequent term using lead and then subtract the interval '1 day' to derive the term_end:\n\nSELECT a.id_bioguide, a.first_term,\n  b.term_start,\n  lead(b.term_start) over (partition by a.id_bioguide \n                          order by b.term_start) \n - interval '1 day' as term_end\nFROM\n(\n    SELECT id_bioguide, min(term_start) as first_term\n    FROM legislators_terms \n    GROUP BY 1\n) a\nJOIN legislators_terms b on a.id_bioguide = b.id_bioguide\nORDER BY a.id_bioguide\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nfirst_term\nterm_start\nterm_end\n\n\n\n\nA000001\n1951-01-03\n1951-01-03\nNA\n\n\nA000002\n1947-01-03\n1947-01-03\n1949-01-02\n\n\nA000002\n1947-01-03\n1949-01-03\n1951-01-02\n\n\nA000002\n1947-01-03\n1951-01-03\n1953-01-02\n\n\nA000002\n1947-01-03\n1953-01-03\n1955-01-04\n\n\nA000002\n1947-01-03\n1955-01-05\n1957-01-02\n\n\nA000002\n1947-01-03\n1957-01-03\n1959-01-06\n\n\nA000002\n1947-01-03\n1959-01-07\n1961-01-02\n\n\nA000002\n1947-01-03\n1961-01-03\n1963-01-08\n\n\nA000002\n1947-01-03\n1963-01-09\n1965-01-03\n\n\n\n\n\nThis code block can then be plugged into the retention code. This method has a couple of drawbacks. First, when there is no subsequent term, the lead function returns null, leaving that term without a term_end. A default value, such as a default interval shown in the last example, could be used in such cases. The second drawback is that this method assumes that terms are always consecutive, with no time spent out of office. Although most legislators tend to serve continuously until their congressional careers end, there are certainly examples of gaps between terms spanning several years.\nAny time we make adjustments to fill in missing data, we need to be careful about the assumptions we make. In subscription- or term-based contexts, explicit start and end dates tend to be most accurate. Either of the two other methods shown—adding a fixed interval or setting the end date relative to the next start date—can be used when no end date is present and we have a reasonable expectation that most customers or users will stay for the duration assumed.\nNow that we’ve seen how to calculate a basic retention curve and correct for missing dates, we can start adding in cohort groups. Comparing retention between different groups is one of the main reasons to do cohort analysis. Next, I’ll discuss forming groups from the time series itself, and after that, I’ll discuss forming cohort groups from data in other tables.\n\n\n1.3.3 Cohorts Derived from the Time Series Itself\nNow that we have SQL code to calculate retention, we can start to split the entities into cohorts. In this section, I will show how to derive cohort groupings from the time series itself. First I’ll discuss time-based cohorts based on the first date, and I’ll explain how to make cohorts based on other attributes from the time series.\nThe most common way to create the cohorts is based on the first or minimum date or time that the entity appears in the time series. This means that only one table is necessary for the cohort retention analysis: the time series itself. Cohorting by the first appearance or action is interesting because often groups that start at different times behave differently. For consumer services, early adopters are often more enthusiastic and retain differently than later adopters, whereas in SaaS software, later adopters may retain better because the product is more mature. Time-based cohorts can be grouped by any time granularity that is meaningful to the organization, though weekly, monthly, or yearly cohorts are common. If you’re not sure what grouping to use, try running the cohort analysis with different groupings, without making the cohort sizes too small, to see where meaningful patterns emerge. Fortunately, once you know how to construct the cohorts and retention analysis, substituting different time granularities is straightforward.\nThe first example will use yearly cohorts, and then I will demonstrate swapping in centuries. The key question we will consider is whether the era in which a legislator first took office has any correlation with their retention. Political trends and the public mood do change over time, but by how much?\nTo calculate yearly cohorts, we first add the year of the first_term calculated previously to the query that finds the period and cohort_retained:\n\nSELECT date_part('year',a.first_term) as first_year,\n  coalesce(date_part('year',age(c.date,a.first_term)),0) as period,\n  count(distinct a.id_bioguide) as cohort_retained\nFROM\n(\n    SELECT id_bioguide, min(term_start) as first_term\n    FROM legislators_terms \n    GROUP BY 1\n) a\nJOIN legislators_terms b on a.id_bioguide = b.id_bioguide \nLEFT JOIN date_dim c on c.date between b.term_start and b.term_end\n  and c.month_name = 'December' and c.day_of_month = 31\nGROUP BY 1, 2\nORDER BY 1, 2\n\n\nDisplaying records 1 - 10\n\n\nfirst_year\nperiod\ncohort_retained\n\n\n\n\n1789\n0\n89\n\n\n1789\n1\n89\n\n\n1789\n2\n57\n\n\n1789\n3\n56\n\n\n1789\n4\n42\n\n\n1789\n5\n40\n\n\n1789\n6\n31\n\n\n1789\n7\n32\n\n\n1789\n8\n20\n\n\n1789\n9\n19\n\n\n\n\n\nThis query is then used as the subquery, and the cohort_size and pct_retained are calculated in the outer query as previously. In this case, however, we need a PARTITION BY clause that includes first_year so that the first_value is calculated only within the set of rows for that first_year, rather than across the whole result set from the subquery:\n\nSELECT first_year, period,\n  first_value(cohort_retained) over (partition by first_year \n                                    order by period) as cohort_size,\n  cohort_retained,\n  cohort_retained / \n first_value(cohort_retained) over (partition by first_year \n                                    order by period) as pct_retained\nFROM\n(\n    SELECT date_part('year',a.first_term) as first_year\n    ,coalesce(date_part('year',age(c.date,a.first_term)),0) as period\n    ,count(distinct a.id_bioguide) as cohort_retained\n    FROM\n    (\n        SELECT id_bioguide, min(term_start) as first_term\n        FROM legislators_terms \n        GROUP BY 1\n    ) a\n    JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n    LEFT JOIN date_dim c on c.date between b.term_start and b.term_end\n    and c.month_name = 'December' and c.day_of_month = 31\n    GROUP BY 1,2\n) aa\nORDER BY 1, 2\n\n\nDisplaying records 1 - 10\n\n\nfirst_year\nperiod\ncohort_size\ncohort_retained\npct_retained\n\n\n\n\n1789\n0\n89\n89\n1.0000000\n\n\n1789\n1\n89\n89\n1.0000000\n\n\n1789\n2\n89\n57\n0.6404494\n\n\n1789\n3\n89\n56\n0.6292135\n\n\n1789\n4\n89\n42\n0.4719101\n\n\n1789\n5\n89\n40\n0.4494382\n\n\n1789\n6\n89\n31\n0.3483146\n\n\n1789\n7\n89\n32\n0.3595506\n\n\n1789\n8\n89\n20\n0.2247191\n\n\n1789\n9\n89\n19\n0.2134831\n\n\n\n\n\nThis data set includes over two hundred starting years, too many to easily graph or examine in a table. Next we’ll look at a less granular interval and cohort the legislators by the century of the first_term. This change is easily made by substituting century for year in the date_part function in subquery aa. Recall that century names are offset from the years they represent, so that the 18th century lasted from 1700 to 1799, the 19th century lasted from 1800 to 1899, and so on.1 The partitioning in the first_value function changes to the first_century field:\n\nSELECT first_century, period\n,first_value(cohort_retained) over (partition by first_century \n                                    order by period) as cohort_size\n,cohort_retained\n,cohort_retained / \n first_value(cohort_retained) over (partition by first_century \n                                    order by period) as pct_retained\nFROM\n(\n    SELECT date_part('century',a.first_term) as first_century\n    ,coalesce(date_part('year',age(c.date,a.first_term)),0) as period\n    ,count(distinct a.id_bioguide) as cohort_retained\n    FROM\n    (\n        SELECT id_bioguide, min(term_start) as first_term\n        FROM legislators_terms \n        GROUP BY 1\n    ) a\n    JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n    LEFT JOIN date_dim c on c.date between b.term_start and b.term_end\n    and c.month_name = 'December' and c.day_of_month = 31\n    GROUP BY 1,2\n) aa\nORDER BY 1,2\n\nThe results are graphed in Figure 3.3. Retention in the early years has been higher for those first elected in the 20th or 21st century. The 21st century is still underway, and thus many of those legislators have not had the opportunity to stay in office for five or more years, though they are still included in the denominator. We might want to consider removing the 21st century from the analysis, but I’ve left it here to demonstrate how the retention curve drops artificially due to this circumstance.\n\n\n\n\n\n\n\n\nFigure 1.3: Legislator retention by century in which first term began\n\n\n\n\n\nCohorts can be defined from other attributes in a time series besides the first date, with options depending on the values in the table. The legislators_terms table has a state field, indicating which state the person is representing for that term. We can use this to create cohorts, and we will base them on the first state in order to ensure that anyone who has represented multiple states appears in the data only once.\n\n\n\n\n\n\nWarning\n\n\n\nWhen cohorting on an attribute that can change over time, it’s important to ensure that each entity is assigned only one value. Otherwise the entity may be represented in multiple cohorts, introducing bias into the analysis. Usually the value from the earliest record in the data set is used.\n\n\nTo find the first state for each legislator, we can use the first_value window function. In this example, we’ll also turn the min function into a window function to avoid a lengthy GROUP BY clause:\n\nSELECT distinct id_bioguide,\n  min(term_start) over (partition by id_bioguide) as first_term,\n  first_value(state) over (partition by id_bioguide \n                          order by term_start) as first_state\nFROM legislators_terms \n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nfirst_term\nfirst_state\n\n\n\n\nP000012\n1901-12-02\nTN\n\n\nP000592\n2005-01-04\nTX\n\n\nR000244\n1897-03-15\nKS\n\n\nR000256\n1937-01-05\nIL\n\n\nS000074\n1859-12-05\nDE\n\n\nS000325\n1861-07-04\nOH\n\n\nS000532\n1941-01-03\nPA\n\n\nS000609\n1793-12-02\nMD\n\n\nS000730\n1918-01-01\nMO\n\n\nS000767\n1843-12-04\nOH\n\n\n\n\n\nWe can then plug this code into our retention code to find the retention by first_state:\n\nSELECT first_state, period\n,first_value(cohort_retained) over (partition by first_state \n                                    order by period) as cohort_size\n,cohort_retained\n,cohort_retained / \n first_value(cohort_retained) over (partition by first_state \n                                    order by period) as pct_retained\nFROM\n(\n    SELECT a.first_state\n    ,coalesce(date_part('year',age(c.date,a.first_term)),0) as period\n    ,count(distinct a.id_bioguide) as cohort_retained\n    FROM\n    (\n        SELECT distinct id_bioguide\n        ,min(term_start) over (partition by id_bioguide) as first_term\n        ,first_value(state) over (partition by id_bioguide order by term_start) \n         as first_state\n        FROM legislators_terms \n    ) a\n    JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n    LEFT JOIN date_dim c on c.date between b.term_start and b.term_end\n    and c.month_name = 'December' and c.day_of_month = 31\n    GROUP BY 1,2\n) aa\n;\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                first_state\n                period\n                cohort_size\n                cohort_retained\n                pct_retained\n              \n        \n        \n        \n                \n                  AZ\n                  0\n                  59\n                  59\n                  1.0000000\n                \n                \n                  AZ\n                  1\n                  59\n                  59\n                  1.0000000\n                \n                \n                  AZ\n                  2\n                  59\n                  47\n                  0.7966102\n                \n                \n                  AZ\n                  3\n                  59\n                  45\n                  0.7627119\n                \n                \n                  AZ\n                  4\n                  59\n                  38\n                  0.6440678\n                \n                \n                  AZ\n                  5\n                  59\n                  37\n                  0.6271186\n                \n        \n      \n    \n\n\n\nThe retention curves for the five states with the highest total number of legislators are graphed in Figure 3.4. Those elected in Illinois and Massachusetts have the highest retention, while New Yorkers have the lowest retention. Determining the reasons why would be an interesting offshoot of this analysis.\n\n\n\n\n\n\n\n\nFigure 1.4: Legislator retention by first state: top five states by total legislators\n\n\n\n\n\nDefining cohorts from the time series is relatively straightforward using a min date for each entity and then converting that date into a month, year, or century as appropriate for the analysis. Switching between month and year or other levels of granularity also is straightforward, allowing for multiple options to be tested in order to find a grouping that is meaningful for the organization. Other attributes can be used for cohorting with the first_value window function. Next, we’ll turn to cases in which the cohorting attribute comes from a table other than that of the time series.\n\n\n1.3.4 Defining the Cohort from a Separate Table\nOften the characteristics that define a cohort exist in a table separate from the one that contains the time series. For example, a database might have a customer table with information such as acquisition source or registration date by which customers can be cohorted. Adding in attributes from other tables, or even subqueries, is relatively straightforward and can be done in retention analysis and related analyses discussed later in the chapter.\nFor this example, we’ll consider whether the gender of the legislator has any impact on their retention. The legislators table has a gender field, where F means female and M means male, that we can use to cohort the legislators. To do this, we’ll JOIN the legislators table in as alias d to add gender to the calculation of cohort_retained, in place of year or century:\n\nSELECT d.gender\n,coalesce(date_part('year',age(c.date,a.first_term)),0) as period\n,count(distinct a.id_bioguide) as cohort_retained\nFROM\n(\n    SELECT id_bioguide, min(term_start) as first_term\n    FROM legislators_terms \n    GROUP BY 1\n) a\nJOIN legislators_terms b on a.id_bioguide = b.id_bioguide \nLEFT JOIN date_dim c on c.date between b.term_start and b.term_end\nand c.month_name = 'December' and c.day_of_month = 31\nJOIN legislators d on a.id_bioguide = d.id_bioguide\nGROUP BY 1, 2\nORDER BY 2, 1\n\n\nDisplaying records 1 - 10\n\n\ngender\nperiod\ncohort_retained\n\n\n\n\nF\n0\n366\n\n\nM\n0\n12152\n\n\nF\n1\n349\n\n\nM\n1\n11979\n\n\nF\n2\n261\n\n\nM\n2\n7905\n\n\nF\n3\n256\n\n\nM\n3\n7813\n\n\nF\n4\n223\n\n\nM\n4\n5639\n\n\n\n\n\nIt’s immediately clear that many more males than females have served legislative terms. We can now calculate the percent_retained so we can compare the retention for these groups:\n\nSELECT gender, period\n,first_value(cohort_retained) over (partition by gender \n                                    order by period) as cohort_size\n,cohort_retained\n,cohort_retained/ \n first_value(cohort_retained) over (partition by gender \n                                    order by period) as pct_retained\nFROM\n(\n    SELECT d.gender\n    ,coalesce(date_part('year',age(c.date,a.first_term)),0) as period\n    ,count(distinct a.id_bioguide) as cohort_retained\n    FROM\n    (\n        SELECT id_bioguide, min(term_start) as first_term\n        FROM legislators_terms \n        GROUP BY 1\n    ) a\n    JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n    LEFT JOIN date_dim c on c.date between b.term_start and b.term_end\n    and c.month_name = 'December' and c.day_of_month = 31\n    JOIN legislators d on a.id_bioguide = d.id_bioguide\n    GROUP BY 1,2\n) aa\nORDER BY 2, 1\n\nWe can see from the results graphed in Figure 3.5 that retention is higher for female legislators than for their male counterparts for periods 2 through 29. The first female legislator did not take office until 1917, when Jeannette Rankin joined the House as a Republican representative from Montana. As we saw earlier, retention has increased in more recent centuries.\n\n\n\n\n\n\n\n\nFigure 1.5: Legislator retention by gender\n\n\n\n\n\nTo make a fairer comparison, we might restrict the legislators included in the analysis to only those whose first_term started since there have been women in Congress. We can do this by adding a WHERE filter to subquery aa. Here the results are also restricted to those who started before 2000, to ensure the cohorts have had at least 20 possible years to stay in office:\n\nSELECT gender, period\n,first_value(cohort_retained) over (partition by gender \n                                    order by period) as cohort_size\n,cohort_retained\n,cohort_retained / \n first_value(cohort_retained) over (partition by gender \n                                    order by period) as pct_retained\nFROM\n(\n    SELECT d.gender\n    ,coalesce(date_part('year',age(c.date,a.first_term)),0) as period\n    ,count(distinct a.id_bioguide) as cohort_retained\n    FROM\n    (\n        SELECT id_bioguide, min(term_start) as first_term\n        FROM legislators_terms \n        GROUP BY 1\n    ) a\n    JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n    LEFT JOIN date_dim c on c.date between b.term_start and b.term_end\n    and c.month_name = 'December' and c.day_of_month = 31\n    JOIN legislators d on a.id_bioguide = d.id_bioguide\n    WHERE a.first_term between '1917-01-01' and '1999-12-31'\n    GROUP BY 1,2\n) aa\n\nMale legislators still outnumber female legislators, but by a smaller margin. The retention for the cohorts is graphed in Figure 3.6. With the revised cohorts, male legislators have higher retention through year 7, but starting in year 12, female legislators have higher retention. The difference between the two gender-based cohort analyses underscores the importance of setting up appropriate cohorts and ensuring that they have comparable amounts of time to be present or complete other actions of interest. To further improve this analysis, we could cohort by both starting year or decade and gender, in order to control for additional changes in retention through the 20th century and into the 21st century.\n\n\n\n\n\n\n\n\nFigure 1.6: Legislator retention by gender: cohorts from 1917 to 1999\n\n\n\n\n\nCohorts can be defined in multiple ways, from the time series and from other tables. With the framework we’ve developed, subqueries, views, or other derived tables can be swapped in, opening up a whole range of calculations to be the basis of a cohort. Multiple criteria, such as starting year and gender, can be used. One caution when dividing populations into cohorts based on multiple criteria is that this can lead to sparse cohorts, where some of the defined groups are too small and are not represented in the data set for all time periods. The next section will discuss methods for overcoming this challenge.\n\n\n1.3.5 Dealing with Sparse Cohorts\nIn the ideal data set, every cohort has some action or record in the time series for every period of interest. We’ve already seen how “missing” dates can occur due to subscriptions or terms lasting over multiple periods, and we looked at how to correct for them using a date dimension to infer intermediate dates. Another issue can arise when, due to grouping criteria, the cohort becomes too small and as a result is represented only sporadically in the data. A cohort may disappear from the result set, when we would prefer it to appear with a zero retention value. This problem is called sparse cohorts, and it can be worked around with the careful use of LEFT JOINs.\nTo demonstrate this, let’s attempt to cohort female legislators by the first state they represented to see if there are any differences in retention. We’ve already seen that there have been relatively few female legislators. Cohorting them further by state is highly likely to create some sparse cohorts in which there are very few members. Before making code adjustments, let’s add first_state (calculated in the section on deriving cohorts from the time series) into our previous gender example and look at the results:\n\nSELECT first_state, gender, period\n,first_value(cohort_retained) over (partition by first_state, gender \n                                    order by period) as cohort_size\n,cohort_retained\n,cohort_retained / \n first_value(cohort_retained) over (partition by first_state, gender \n                                    order by period) as pct_retained\nFROM\n(\n    SELECT a.first_state, d.gender\n    ,coalesce(date_part('year',age(c.date,a.first_term)),0) as period\n    ,count(distinct a.id_bioguide) as cohort_retained\n    FROM\n    (\n        SELECT distinct id_bioguide\n        ,min(term_start) over (partition by id_bioguide) as first_term\n        ,first_value(state) over (partition by id_bioguide \n                                  order by term_start) as first_state\n        FROM legislators_terms \n    ) a\n    JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n    LEFT JOIN date_dim c on c.date between b.term_start and b.term_end\n    and c.month_name = 'December' and c.day_of_month = 31\n    JOIN legislators d on a.id_bioguide = d.id_bioguide\n    WHERE a.first_term between '1917-01-01' and '1999-12-31'\n    GROUP BY 1,2,3\n) aa\nORDER BY 1, 3, 2\n\nGraphing the results for the first 20 periods, as in Figure 3.7, reveals the sparse cohorts. Alaska did not have any female legislators, while Arizona’s female retention curve disappears after year 3. Only California, a large state with many legislators, has complete retention curves for both genders. This pattern repeats for other small and large states.\n\n\n\n\n\n\n\n\nFigure 1.7: Legislator retention by gender and first state\n\n\n\n\n\nNow let’s look at how to ensure a record for every period so that the query returns zero values for retention instead of nulls. The first step is to query for all combinations of periods and cohort attributes, in this case first_state and gender, with the starting cohort_size for each combination. This can be done by JOINing subquery aa, which calculates the cohort, with a generate_series subquery that returns all integers from 0 to 20, with the criterion on 1 = 1. This is a handy way to force a Cartesian JOIN when the two subqueries don’t have any fields in common:\n\nSELECT aa.gender, aa.first_state, cc.period, aa.cohort_size\nFROM\n(\n    SELECT b.gender, a.first_state \n    ,count(distinct a.id_bioguide) as cohort_size\n    FROM \n    (\n        SELECT distinct id_bioguide\n        ,min(term_start) over (partition by id_bioguide) as first_term\n        ,first_value(state) over (partition by id_bioguide \n                                  order by term_start) as first_state\n        FROM legislators_terms \n    ) a\n    JOIN legislators b on a.id_bioguide = b.id_bioguide\n    WHERE a.first_term between '1917-01-01' and '1999-12-31' \n    GROUP BY 1,2\n) aa\nJOIN\n(\n    SELECT generate_series as period \n    FROM generate_series(0,20,1)\n) cc on 1 = 1\nORDER BY 2, 3, 1\n\n\nDisplaying records 1 - 10\n\n\ngender\nfirst_state\nperiod\ncohort_size\n\n\n\n\nM\nAK\n0\n13\n\n\nM\nAK\n1\n13\n\n\nM\nAK\n2\n13\n\n\nM\nAK\n3\n13\n\n\nM\nAK\n4\n13\n\n\nM\nAK\n5\n13\n\n\nM\nAK\n6\n13\n\n\nM\nAK\n7\n13\n\n\nM\nAK\n8\n13\n\n\nM\nAK\n9\n13\n\n\n\n\n\nThe next step is to JOIN this back to the actual periods in office, with a LEFT JOIN to ensure all the time periods remain in the final result:\n\nSELECT aaa.gender, aaa.first_state, aaa.period, aaa.cohort_size\n,coalesce(ddd.cohort_retained,0) as cohort_retained\n,coalesce(ddd.cohort_retained,0) / aaa.cohort_size as pct_retained\nFROM\n(\n    SELECT aa.gender, aa.first_state, cc.period, aa.cohort_size\n    FROM\n    (\n        SELECT b.gender, a.first_state\n        ,count(distinct a.id_bioguide) as cohort_size\n        FROM \n        (\n            SELECT distinct id_bioguide\n            ,min(term_start) over (partition by id_bioguide) \n             as first_term\n            ,first_value(state) over (partition by id_bioguide \n                                      order by term_start) \n                                      as first_state\n            FROM legislators_terms \n        ) a\n        JOIN legislators b on a.id_bioguide = b.id_bioguide \n        WHERE a.first_term between '1917-01-01' and '1999-12-31' \n        GROUP BY 1,2\n    ) aa\n    JOIN\n    (\n        SELECT generate_series as period \n        FROM generate_series(0,20,1)\n    ) cc on 1 = 1\n) aaa\nLEFT JOIN\n(\n    SELECT d.first_state, g.gender\n    ,coalesce(date_part('year',age(f.date,d.first_term)),0) as period\n    ,count(distinct d.id_bioguide) as cohort_retained\n    FROM\n    (\n        SELECT distinct id_bioguide\n        ,min(term_start) over (partition by id_bioguide) as first_term\n        ,first_value(state) over (partition by id_bioguide \n                                  order by term_start) as first_state\n        FROM legislators_terms \n    ) d\n    JOIN legislators_terms e on d.id_bioguide = e.id_bioguide \n    LEFT JOIN date_dim f on f.date between e.term_start and e.term_end\n     and f.month_name = 'December' and f.day_of_month = 31\n    JOIN legislators g on d.id_bioguide = g.id_bioguide\n    WHERE d.first_term between '1917-01-01' and '1999-12-31'\n    GROUP BY 1,2,3\n) ddd on aaa.gender = ddd.gender and aaa.first_state = ddd.first_state \nand aaa.period = ddd.period\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\ngender\nfirst_state\nperiod\ncohort_size\ncohort_retained\npct_retained\n\n\n\n\nM\nSD\n0\n25\n25\n1.00\n\n\nM\nSD\n1\n25\n24\n0.96\n\n\nM\nSD\n2\n25\n23\n0.92\n\n\nM\nSD\n4\n25\n19\n0.76\n\n\nM\nSD\n5\n25\n18\n0.72\n\n\nM\nSD\n6\n25\n16\n0.64\n\n\nM\nSD\n7\n25\n16\n0.64\n\n\nM\nSD\n8\n25\n15\n0.60\n\n\nM\nSD\n9\n25\n15\n0.60\n\n\nM\nSD\n10\n25\n14\n0.56\n\n\n\n\n\nWe can then pivot the results and confirm that a value exists for each cohort for each period:\n\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\n\n\ngender\nfirst_state\nyr0\nyr2\nyr4\nyr6\nyr8\nyr10\n\n\n\n\nF\nAL\n1\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n\n\nF\nAR\n1\n0.8000000\n0.2000000\n0.4000000\n0.4000000\n0.4000000\n\n\nF\nAZ\n1\n0.5000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n\n\nF\nCA\n1\n0.9200000\n0.8000000\n0.6400000\n0.6800000\n0.6800000\n\n\nF\nCO\n1\n1.0000000\n1.0000000\n1.0000000\n1.0000000\n1.0000000\n\n\nF\nCT\n1\n0.8333333\n0.6666667\n0.5000000\n0.5000000\n0.5000000\n\n\nF\nDC\n1\n1.0000000\n1.0000000\n1.0000000\n1.0000000\n1.0000000\n\n\nF\nFL\n1\n1.0000000\n0.8571429\n0.7142857\n0.5714286\n0.2857143\n\n\nF\nGA\n1\n0.4000000\n0.4000000\n0.4000000\n0.2000000\n0.0000000\n\n\nF\nHI\n1\n1.0000000\n0.3333333\n0.3333333\n0.3333333\n0.3333333\n\n\n\n\n\nNotice that at this point, the SQL code has gotten quite long. One of the harder parts of writing SQL for cohort retention analysis is keeping all of the logic straight and the code organized, a topic I’ll discuss more in Chapter 8. When building up retention code, I find it helpful to go step-by-step, checking results along the way. I also spot-check individual cohorts to validate that the final result is accurate.\nCohorts can be defined in many ways. So far, we’ve normalized all our cohorts to the first date they appear in the time series data. This isn’t the only option, however, and interesting analysis can be done starting in the middle of an entity’s life span. Before concluding our work on retention analysis, let’s take a look at this additional way to define cohorts.\n\n\n1.3.6 Defining Cohorts from Dates Other Than the First Date\nUsually time-based cohorts are defined from the entity’s first appearance in the time series or from some other earliest date, such as a registration date. However, cohorting on a different date can be useful and insightful. For example, we might want to look at retention across all customers using a service as of a particular date. This type of analysis can be used to understand whether product or marketing changes have had a long-term impact on existing customers.\nWhen using a date other than the first date, we need to take care to precisely define the criteria for inclusion in each cohort. One option is to pick entities present on a particular calendar date. This is relatively straightforward to put into SQL code, but it can be problematic if a large share of the regular user population doesn’t show up every day, causing retention to vary depending on the exact day chosen. One option to correct for this is to calculate retention for several starting dates and then average the results.\nAnother option is to use a window of time such as a week or month. Any entity that appears in the data set during that window is included in the cohort. While this approach is often more representative of the business or process, the trade-off is that the SQL code will become more complex, and the query time may be slower due to more intense database calculations. Finding the right balance between query performance and accuracy of results is something of an art.\nLet’s take a look at how to calculate such midstream analysis with the legislators data set by considering retention for legislators who were in office in the year 2000. We’ll cohort by the term_type, which has values of “sen” for senators and “rep” for representatives. The definition will include any legislator in office at any time during the year 2000: those who started prior to 2000 and whose terms ended during or after 2000 qualify, as do those who started a term in 2000. We can hardcode any date in 2000 as the first_term, since we will later check whether they were in office at some point during 2000. The min_start of the terms falling in this window is also calculated for use in a later step:\n\nSELECT distinct id_bioguide, term_type, date '2000-01-01' as first_term\n,min(term_start) as min_start\nFROM legislators_terms \nWHERE term_start &lt;= '2000-12-31' and term_end &gt;= '2000-01-01'\nGROUP BY 1,2,3\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nterm_type\nfirst_term\nmin_start\n\n\n\n\nK000146\nsen\n2000-01-01\n1995-01-04\n\n\nD000210\nrep\n2000-01-01\n1999-01-06\n\n\nH000636\nrep\n2000-01-01\n1999-01-06\n\n\nC000266\nrep\n2000-01-01\n1999-01-06\n\n\nT000238\nrep\n2000-01-01\n1999-01-06\n\n\nC000560\nrep\n2000-01-01\n1999-01-06\n\n\nH000621\nrep\n2000-01-01\n1999-01-06\n\n\nB000589\nrep\n2000-01-01\n1999-01-06\n\n\nR000409\nrep\n2000-01-01\n1999-01-06\n\n\nD000064\nsen\n2000-01-01\n1999-01-06\n\n\n\n\n\nWe can then plug this into our retention code, with two adjustments. First, an additional JOIN criterion between subquery a and the legislators_terms table is added in order to return only terms that started on or after the min_start date. Second, an additional filter is added to the date_dim so that it only returns dates in 2000 or later:\n\nSELECT term_type, period\n,first_value(cohort_retained) over (partition by term_type order by period) \n as cohort_size\n,cohort_retained\n,cohort_retained / \n first_value(cohort_retained) over (partition by term_type order by period) \n as pct_retained\nFROM\n(\n    SELECT a.term_type\n    ,coalesce(date_part('year',age(c.date,a.first_term)),0) as period\n    ,count(distinct a.id_bioguide) as cohort_retained\n    FROM\n    (\n        SELECT distinct id_bioguide, term_type\n        ,date '2000-01-01' as first_term\n        ,min(term_start) as min_start\n        FROM legislators_terms \n        WHERE term_start &lt;= '2000-12-31' and term_end &gt;= '2000-01-01'\n        GROUP BY 1,2,3\n    ) a\n    JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n    and b.term_start &gt;= a.min_start\n    LEFT JOIN date_dim c on c.date between b.term_start and b.term_end\n    and c.month_name = 'December' and c.day_of_month = 31 \n    and c.year &gt;= 2000\n    GROUP BY 1,2\n) aa\nORDER BY 2, 1\n\nFigure 3.8 shows that despite longer terms for senators, retention among the two cohorts was similar, and was actually worse for senators after 10 years. A further analysis comparing the different years they were first elected, or other cohort attributes, might yield some interesting insights.\n\n\n\n\n\n\n\n\nFigure 1.8: Retention by term type for legislators in office during the year 2000\n\n\n\n\n\nA common use case for cohorting on a value other than a starting value is when trying to analyze retention after an entity has reached a threshold, such as a certain number of purchases or a certain amount spent. As with any cohort, it’s important to take care in defining what qualifies an entity to be in a cohort and which date will be used as the starting date.\nCohort retention is a powerful way to understand the behavior of entities in a time series data set. We’ve seen how to calculate retention with SQL and how to cohort based on the time series itself or on other tables, and from points in the middle of entity life span. We also looked at how to use functions and JOINs to adjust dates within time series and compensate for sparse cohorts. There are several types of analyses that are related to cohort retention: analysis, survivorship, returnship, and cumulative calculations, all of which build off of the SQL code that we’ve developed for retention. Let’s turn to them next.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Cohort Analysis -- Original</span>"
    ]
  },
  {
    "objectID": "original_sql.html#related-cohort-analyses",
    "href": "original_sql.html#related-cohort-analyses",
    "title": "1  Cohort Analysis – Original",
    "section": "1.4 Related Cohort Analyses",
    "text": "1.4 Related Cohort Analyses\nIn the last section, we learned how to write SQL for cohort retention analysis. Retention captures whether an entity was in a time series data set on a specific date or window of time. In addition to presence on a specific date, analysis is often interested in questions of how long an entity lasted, whether an entity did multiple actions, and how many of those actions occurred. These can all be answered with code that is similar to retention and is well suited to just about any cohorting criteria you like. Let’s take a look at the first of these, survivorship.\n\n1.4.1 Survivorship\nSurvivorship, also called survival analysis, is concerned with questions about how long something lasts, or the duration of time until a particular event such as churn or death. Survivorship analysis can answer questions about the share of the population that is likely to remain past a certain amount of time. Cohorts can help identify or at least provide hypotheses about which characteristics or circumstances increase or decrease the survival likelihood.\nThis is similar to a retention analysis, but instead of calculating whether an entity was present in a certain period, we calculate whether the entity is present in that period or later in the time series. Then the share of the total cohort is calculated. Typically one or more periods are chosen depending on the nature of the data set analyzed. For example, if we want to know the share of game players who survive for a week or longer, we can check for actions that occur after a week from starting and consider those players still surviving. On the other hand, if we are concerned about the number of students who are still in school after a certain number of years, we could look for the absence of a graduation event in a data set. The number of periods can be SELECTed either by calculating an average or typical life span or by choosing time periods that are meaningful to the organization or process analyzed, such as a month, year, or longer time period.\nIn this example, we’ll look at the share of legislators who survived in office for a decade or more after their first term started. Since we don’t need to know the specific dates of each term, we can start by calculating the first and last term_start dates, using min and max aggregations:\n\nSELECT id_bioguide,\n  min(term_start) as first_term,\n  max(term_start) as last_term\nFROM legislators_terms\nGROUP BY 1\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nfirst_term\nlast_term\n\n\n\n\nK000367\n2007-01-04\n2019-01-03\n\n\nI000024\n1987-01-06\n2015-01-06\n\n\nR000307\n1981-01-05\n2015-01-06\n\n\nW000805\n2009-01-06\n2015-01-06\n\n\nA000055\n1997-01-07\n2019-01-03\n\n\nB000490\n1993-01-05\n2019-01-03\n\n\nB001277\n2011-01-05\n2017-01-03\n\n\nB000575\n1997-01-07\n2017-01-03\n\n\nB000755\n1997-01-07\n2019-01-03\n\n\nC000059\n1993-01-05\n2019-01-03\n\n\n\n\n\nNext, we add to the query a date_part function to find the century of the min term_start, and we calculate the tenure as the number of years between the min and max term_starts found with the age function:\n\nSELECT id_bioguide,\n  date_part('century', min(term_start)) as first_century,\n  min(term_start) as first_term,\n  max(term_start) as last_term,\n  date_part('year', age(max(term_start), min(term_start))) as tenure\nFROM legislators_terms\nGROUP BY 1\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nfirst_century\nfirst_term\nlast_term\ntenure\n\n\n\n\nB000944\n20\n1993-01-05\n2019-01-03\n25\n\n\nC000127\n20\n1993-01-05\n2019-01-03\n25\n\n\nC001070\n21\n2007-01-04\n2019-01-03\n11\n\n\nF000469\n21\n2019-01-03\n2019-01-03\n0\n\n\nS000770\n20\n1997-01-07\n2019-01-03\n21\n\n\nB001261\n21\n2007-06-25\n2019-01-03\n11\n\n\nM001183\n21\n2010-11-15\n2019-01-03\n8\n\n\nB001230\n20\n1999-01-06\n2019-01-03\n19\n\n\nB001270\n21\n2011-01-05\n2019-01-03\n7\n\n\nB001251\n21\n2004-07-21\n2019-01-03\n14\n\n\n\n\n\nFinally, we calculate the cohort_size with a count of all the legislators, as well as calculating the number who survived for at least 10 years by using a CASE statement and count aggregation. The percent who survived is found by dividing these two values:\n\nSELECT first_century\n,count(distinct id_bioguide) as cohort_size\n,count(distinct case when tenure &gt;= 10 then id_bioguide \n                     end) as survived_10\n,count(distinct case when tenure &gt;= 10 then id_bioguide end) \n / count(distinct id_bioguide) as pct_survived_10\nFROM\n(\n    SELECT id_bioguide\n    ,date_part('century',min(term_start)) as first_century\n    ,min(term_start) as first_term\n    ,max(term_start) as last_term\n    ,date_part('year',age(max(term_start),min(term_start))) as tenure\n    FROM legislators_terms\n    GROUP BY 1\n) a\nGROUP BY 1\n;\n\n\n4 records\n\n\nfirst_century\ncohort_size\nsurvived_10\npct_survived_10\n\n\n\n\n21\n760\n119\n0.1565789\n\n\n19\n6299\n892\n0.1416098\n\n\n20\n5091\n1853\n0.3639756\n\n\n18\n368\n83\n0.2255435\n\n\n\n\n\nSince terms may or may not be consecutive, we can also calculate the share of legislators in each century who survived for five or more total terms. In the subquery, add a count to find the total number of terms per legislator. Then in the outer query, divide the number of legislators with five or more terms by the total cohort size:\n\nSELECT first_century\n,count(distinct id_bioguide) as cohort_size\n,count(distinct case when total_terms &gt;= 5 then id_bioguide end) \n as survived_5\n,count(distinct case when total_terms &gt;= 5 then id_bioguide end)\n / count(distinct id_bioguide) as pct_survived_5_terms\nFROM\n(\n    SELECT id_bioguide\n    ,date_part('century',min(term_start)) as first_century\n    ,count(term_start) as total_terms\n    FROM legislators_terms\n    GROUP BY 1\n) a\nGROUP BY 1\nORDER BY 1\n\n\n4 records\n\n\nfirst_century\ncohort_size\nsurvived_5\npct_survived_5_terms\n\n\n\n\n18\n368\n63\n0.1711957\n\n\n19\n6299\n711\n0.1128751\n\n\n20\n5091\n2153\n0.4229032\n\n\n21\n760\n205\n0.2697368\n\n\n\n\n\nTen years or five terms is somewhat arbitrary. We can also calculate the survivorship for each number of years or periods and display the results in graph or table form. Here, we calculate the survivorship for each number of terms from 1 to 20. This is accomplished through a Cartesian JOIN to a subquery that contains those integers derived by the generate_series function:\n\nSELECT a.first_century, b.terms\n,count(distinct id_bioguide) as cohort\n,count(distinct case when a.total_terms &gt;= b.terms then id_bioguide \n                     end) as cohort_survived\n,count(distinct case when a.total_terms &gt;= b.terms then id_bioguide \n                     end)\n / count(distinct id_bioguide) as pct_survived\nFROM\n(\n    SELECT id_bioguide\n    ,date_part('century',min(term_start)) as first_century\n    ,count(term_start) as total_terms\n    FROM legislators_terms\n    GROUP BY 1\n) a\nJOIN\n(\n    SELECT generate_series as terms \n    FROM generate_series(1,20,1)\n) b on 1 = 1\nGROUP BY 1,2\nORDER BY 1, 2\n\nThe results are graphed in Figure 3.9. Survivorship was highest in the 20th century, a result that agrees with results we saw previously in which retention was also highest in the 20th century.\n\n\n\n\n\n\n\n\nFigure 1.9: Retention by term type for legislators in office during the year 2000\n\n\n\n\n\nSurvivorship is closely related to retention. While retention counts entities present in a specific number of periods from the start, survivorship considers only whether an entity was present as of a specific period or later. As a result, the code is simpler since it needs only the first and last dates in the time series, or a count of dates. Cohorting is done similar to cohorting for retention, and cohort definitions can come from within the time series or be derived from another table or subquery.\nNext we’ll consider another type of analysis that is in some ways the inverse of survivorship. Rather than calculating whether an entity is present in the data set at a certain time or later, we will calculate whether an entity returns or repeats an action at a certain period or earlier. This is called returnship or repeat purchase behavior.\n\n\n1.4.2 Returnship, or Repeat Purchase Behavior\nSurvivorship is useful for understanding how long a cohort is likely to stick around. Another useful type of cohort analysis seeks to understand whether a cohort member can be expected to return within a given window of time and the intensity of activity during that window. This is called returnship or repeat purchase behavior.\nFor example, an ecommerce site might want to know not only how many new buyers were acquired via a marketing campaign but also whether those buyers have become repeat buyers. One way to figure this out is to simply calculate total purchases per customer. However, comparing customers acquired two years ago with those acquired a month ago isn’t fair, since the former have had a much longer time in which to return. The older cohort would almost certainly appear more valuable than the newer one. Although this is true in a sense, it gives an incomplete picture of how the cohorts are likely to behave across their entire life span.\nTo make fair comparisons between cohorts with different starting dates, we need to create an analysis based on a time box, or a fixed window of time from the first date, and consider whether cohort members returned within that window. This way, every cohort has an equal amount of time under consideration, so long as we include only those cohorts for which the full window has elapsed. Returnship analysis is common for retail organizations, but it can also be applied in other domains. For example, a university might want to see how many students enrolled in a second course, or a hospital might be interested in how many patients need follow-up medical treatments after an initial incident.\nTo demonstrate returnship analysis, we can ask a new question of the legislators data set: how many legislators have more than one term type, and specifically, what share of them start as representatives and go on to become senators (some senators later become representatives, but that is much less common). Since relatively few make this transition, we’ll cohort legislators by the century in which they first became a representative.\nThe first step is to find the cohort size for each century, using the subquery and date_part calculations seen previously, for only those with term_type = 'rep':\n\nSELECT date_part('century',a.first_term) as cohort_century\n,count(id_bioguide) as reps\nFROM\n(\n    SELECT id_bioguide, min(term_start) as first_term\n    FROM legislators_terms\n    WHERE term_type = 'rep'\n    GROUP BY 1\n) a\nGROUP BY 1\nORDER BY 1\n\n\n4 records\n\n\ncohort_century\nreps\n\n\n\n\n18\n299\n\n\n19\n5773\n\n\n20\n4481\n\n\n21\n683\n\n\n\n\n\nNext we’ll perform a similar calculation, with a JOIN to the legislators_terms table, to find the representatives who later became senators. This is accomplished with the clauses b.term_type = 'sen' and b.term_start &gt; a.first_term:\n\nSELECT date_part('century',a.first_term) as cohort_century\n,count(distinct a.id_bioguide) as rep_and_sen\nFROM\n(\n    SELECT id_bioguide, min(term_start) as first_term\n    FROM legislators_terms\n    WHERE term_type = 'rep'\n    GROUP BY 1\n) a\nJOIN legislators_terms b on a.id_bioguide = b.id_bioguide\nand b.term_type = 'sen' and b.term_start &gt; a.first_term\nGROUP BY 1\nORDER BY 1\n\n\n4 records\n\n\ncohort_century\nrep_and_sen\n\n\n\n\n18\n57\n\n\n19\n329\n\n\n20\n254\n\n\n21\n25\n\n\n\n\n\nFinally, we JOIN these two subqueries together and calculate the percent of representatives who became senators. A LEFT JOIN is used; this clause is typically recommended to ensure that all cohorts are included whether or not the subsequent event happened. If there is a century in which no representatives became senators, we still want to include that century in the result set:\n\nSELECT aa.cohort_century\n,bb.rep_and_sen / aa.reps as pct_rep_and_sen\nFROM\n(\n        SELECT date_part('century',a.first_term) as cohort_century\n        ,count(id_bioguide) as reps\n        FROM\n        (\n                SELECT id_bioguide, min(term_start) as first_term\n                FROM legislators_terms\n                WHERE term_type = 'rep'\n                GROUP BY 1\n        ) a\n        GROUP BY 1\n) aa\nLEFT JOIN\n(\n        SELECT date_part('century',b.first_term) as cohort_century\n        ,count(distinct b.id_bioguide) as rep_and_sen\n        FROM\n        (\n                SELECT id_bioguide, min(term_start) as first_term\n                FROM legislators_terms\n                WHERE term_type = 'rep'\n                GROUP BY 1\n        ) b\n        JOIN legislators_terms c on b.id_bioguide = c.id_bioguide\n        and c.term_type = 'sen' and c.term_start &gt; b.first_term\n        GROUP BY 1\n) bb on aa.cohort_century = bb.cohort_century\nORDER BY 1\n\n\n4 records\n\n\ncohort_century\npct_rep_and_sen\n\n\n\n\n18\n0.1906355\n\n\n19\n0.0569894\n\n\n20\n0.0566838\n\n\n21\n0.0366032\n\n\n\n\n\nRepresentatives from the 18th century were most likely to become senators. However, we have not yet applied a time box to ensure a fair comparison. While we can safely assume that all legislators who served in the 18th and 19th centuries are no longer living, many of those who were first elected in the 20th and 21st centuries are still in the middle of their careers. Adding the filter WHERE age(c.term_start, b.first_term) &lt;= interval '10 years' to subquery bb creates a time box of 10 years. Note that the window can easily be made larger or smaller by changing the constant in the interval. An additional filter applied to subquery a, WHERE first_term &lt;= '2009-12-31', excludes those who were less than 10 years into their careers when the data set was assembled:\n\nSELECT aa.cohort_century\n,bb.rep_and_sen * 1.0 / aa.reps as pct_rep_and_sen\nFROM\n(\n        SELECT date_part('century',a.first_term) as cohort_century\n        ,count(id_bioguide) as reps\n        FROM\n        (\n                SELECT id_bioguide, min(term_start) as first_term\n                FROM legislators_terms\n                WHERE term_type = 'rep'\n                GROUP BY 1\n        ) a\n        WHERE first_term &lt;= '2009-12-31'\n        GROUP BY 1\n) aa\nLEFT JOIN\n(\n        SELECT date_part('century',b.first_term) as cohort_century\n        ,count(distinct b.id_bioguide) as rep_and_sen\n        FROM\n        (\n                SELECT id_bioguide, min(term_start) as first_term\n                FROM legislators_terms\n                WHERE term_type = 'rep'\n                GROUP BY 1\n        ) b\n        JOIN legislators_terms c on b.id_bioguide = c.id_bioguide\n        and c.term_type = 'sen' and c.term_start &gt; b.first_term\n        WHERE age(c.term_start, b.first_term) &lt;= interval '10 years'\n        GROUP BY 1\n) bb on aa.cohort_century = bb.cohort_century\nORDER BY 1\n\n\n4 records\n\n\ncohort_century\npct_rep_and_sen\n\n\n\n\n18\n0.0969900\n\n\n19\n0.0244240\n\n\n20\n0.0348137\n\n\n21\n0.0763636\n\n\n\n\n\nWith this new adjustment, the 18th century still had the highest share of representatives becoming senators within 10 years, but the 21st century has the second-highest share, and the 20th century had a higher share than the 19th.\nSince 10 years is somewhat arbitrary, we might also want to compare several time windows. One option is to run the query several times with different intervals and note the results. Another option is to calculate multiple windows in the same result set by using a set of CASE statements inside of count distinct aggregations to form the intervals, rather than specifying the interval in the WHERE clause:\n\nSELECT aa.cohort_century\n,bb.rep_and_sen_5_yrs * 1.0 / aa.reps as pct_5_yrs\n,bb.rep_and_sen_10_yrs * 1.0 / aa.reps as pct_10_yrs\n,bb.rep_and_sen_15_yrs * 1.0 / aa.reps as pct_15_yrs\nFROM\n(\n    SELECT date_part('century',a.first_term) as cohort_century\n    ,count(id_bioguide) as reps\n    FROM\n    (\n        SELECT id_bioguide, min(term_start) as first_term\n        FROM legislators_terms\n        WHERE term_type = 'rep'\n        GROUP BY 1\n    ) a\n    WHERE first_term &lt;= '2009-12-31'\n    GROUP BY 1\n) aa\nLEFT JOIN\n(\n    SELECT date_part('century',b.first_term) as cohort_century\n    ,count(distinct case when age(c.term_start,b.first_term) \n                              &lt;= interval '5 years' \n                         then b.id_bioguide end) as rep_and_sen_5_yrs\n    ,count(distinct case when age(c.term_start,b.first_term) \n                              &lt;= interval '10 years' \n                         then b.id_bioguide end) as rep_and_sen_10_yrs\n    ,count(distinct case when age(c.term_start,b.first_term) \n                              &lt;= interval '15 years' \n                         then b.id_bioguide end) as rep_and_sen_15_yrs\n    FROM\n    (\n        SELECT id_bioguide, min(term_start) as first_term\n        FROM legislators_terms\n        WHERE term_type = 'rep'\n        GROUP BY 1\n    ) b\n    JOIN legislators_terms c on b.id_bioguide = c.id_bioguide\n    and c.term_type = 'sen' and c.term_start &gt; b.first_term\n    GROUP BY 1\n) bb on aa.cohort_century = bb.cohort_century\nORDER BY 1\n\n\n4 records\n\n\ncohort_century\npct_5_yrs\npct_10_yrs\npct_15_yrs\n\n\n\n\n18\n0.0501672\n0.0969900\n0.1438127\n\n\n19\n0.0088342\n0.0244240\n0.0408800\n\n\n20\n0.0100424\n0.0348137\n0.0477572\n\n\n21\n0.0400000\n0.0763636\n0.0872727\n\n\n\n\n\nWith this output, we can see how the share of representatives who became senators evolved over time, both within each cohort and across cohorts. In addition to the table format, graphing the output often reveals interesting trends. In Figure 3.10, the cohorts based on century are replaced with cohorts based on the first decade, and the trends over 10 and 20 years are shown. Conversion of representatives to senators during the first few decades of the new US legislature was clearly different from patterns in the years since.\n\n\n\n\n\n\n\n\nFigure 1.10: Trend of the share of representatives for each cohort, defined by starting decade, who later became senators\n\n\n\n\n\nFinding the repeat behavior within a fixed time box is a useful tool for comparing cohorts. This is particularly true when the behaviors are intermittent in nature, such as purchase behavior or content or service consumption. In the next section, we’ll look at how to calculate not only whether an entity had a subsequent action but also how many subsequent actions they had, and we’ll aggregate them with cumulative calculations.\n\n\n1.4.3 Cumulative Calculations\nCumulative cohort analysis can be used to establish cumulative lifetime value, also called customer lifetime value (the acronyms CLTV and LTV are used interchangeably), and to monitor newer cohorts in order to be able to predict what their full LTV will be. This is possible because early behavior is often highly correlated with long-term behavior. Users of a service who return frequently in their first days or weeks of using it tend to be the most likely to stay around over the long term. Customers who buy a second or third time early on are likely to continue purchasing over a longer time period. Subscribers who renew after the first month or year are often likely to stick around over many subsequent months or years.\nIn this section, I’ll mainly talk about the revenue-generating activities of customers, but this analysis can also be applied to situations in which customers or entities incur costs, such as through product returns, support interactions, or use of health-care services.\nWith cumulative calculations, we’re less concerned about whether an entity did an action on a particular date and more about the total as of a particular date. The cumulative calculations used in this type of analysis are most often counts or sums. We will again use the time box concept to ensure apples-to-apples comparisons between cohorts. Let’s look at the number of terms started within 10 years of the first term_start, cohorting the legislators by century and type of first term:\n\nSELECT date_part('century',a.first_term) as century\n,first_type\n,count(distinct a.id_bioguide) as cohort\n,count(b.term_start) as terms\nFROM\n(\n    SELECT distinct id_bioguide\n    ,first_value(term_type) over (partition by id_bioguide \n                                  order by term_start) as first_type\n    ,min(term_start) over (partition by id_bioguide) as first_term\n    ,min(term_start) over (partition by id_bioguide) \n     + interval '10 years' as first_plus_10\n    FROM legislators_terms\n) a\nLEFT JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \nand b.term_start between a.first_term and a.first_plus_10\nGROUP BY 1,2\nORDER BY 1, 2\n\n\n8 records\n\n\ncentury\nfirst_type\ncohort\nterms\n\n\n\n\n18\nrep\n297\n760\n\n\n18\nsen\n71\n101\n\n\n19\nrep\n5744\n12165\n\n\n19\nsen\n555\n795\n\n\n20\nrep\n4473\n16203\n\n\n20\nsen\n618\n1008\n\n\n21\nrep\n683\n2203\n\n\n21\nsen\n77\n118\n\n\n\n\n\nThe largest cohort is that of representatives first elected in the 19th century, but the cohort with the largest number of terms started within 10 years is that of representatives first elected in the 20th century. This type of calculation can be useful for understanding the overall contribution of a cohort to an organization.T otal sales or total repeat purchases can be valuable metrics. Usually, though, we want to normalize to understand the contribution on a per-entity basis. Calculations we might want to make include average actions per person, average order value (AOV), items per order, and orders per customer. To normalize by the cohort size, simply divide by the starting cohort, which we’ve done previously with retention, survivorship, and returnship. Here we do that and also pivot the results into table form for easier comparisons:\n\nSELECT century\n,max(case when first_type = 'rep' then cohort end) as rep_cohort\n,max(case when first_type = 'rep' then terms_per_leg end) \n as avg_rep_terms\n,max(case when first_type = 'sen' then cohort end) as sen_cohort\n,max(case when first_type = 'sen' then terms_per_leg end) \n as avg_sen_terms\nFROM\n(\n    SELECT date_part('century',a.first_term) as century\n    ,first_type\n    ,count(distinct a.id_bioguide) as cohort\n    ,count(b.term_start) as terms\n    ,count(b.term_start) \n     / count(distinct a.id_bioguide) as terms_per_leg\n    FROM\n    (\n        SELECT distinct id_bioguide\n        ,first_value(term_type) over (partition by id_bioguide \n                                      order by term_start\n                                      ) as first_type\n        ,min(term_start) over (partition by id_bioguide) as first_term\n        ,min(term_start) over (partition by id_bioguide) \n         + interval '10 years' as first_plus_10\n        FROM legislators_terms\n    ) a\n    LEFT JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n    and b.term_start between a.first_term and a.first_plus_10\n    GROUP BY 1,2\n) aa\nGROUP BY 1\nORDER BY 1\n\n\n4 records\n\n\ncentury\nrep_cohort\navg_rep_terms\nsen_cohort\navg_sen_terms\n\n\n\n\n18\n297\n2.558923\n71\n1.422535\n\n\n19\n5744\n2.117862\n555\n1.432432\n\n\n20\n4473\n3.622401\n618\n1.631068\n\n\n21\n683\n3.225476\n77\n1.532468\n\n\n\n\n\nWith the cumulative terms normalized by the cohort size, we can now confirm that representatives first elected in the 20th century had the highest average number of terms, while those who started in the 19th century had the fewest number of terms on average. Senators have fewer but longer terms than their representative peers, and again those who started in the 20th century have had the highest number of terms on average.\nCumulative calculations are often used in customer lifetime value calculations. LTV is usually calculated using monetary measures, such as total dollars spent by a customer, or the gross margin (revenue minus costs) generated by a customer across their lifetime. To facilitate comparisons between cohorts, the “lifetime” is often chosen to reflect average customer lifetime, or periods that are convenient to analyze, such as 3, 5, or 10 years. The legislators data set doesn’t contain financial metrics, but swapping in dollar values in any of the preceding SQL code would be straightforward. Fortunately, SQL is a flexible enough language that we can adapt these templates to address a wide variety of analytical questions.\nCohort analysis includes a set of techniques that can be used to answer questions related to behavior over time and how various attributes may contribute to differences between groups. Survivorship, returnship, and cumulative calculations all shed light on these questions. With a good understanding of how cohorts behave, we often have to turn our attention back to the composition or mix of cohorts over time, understanding how that can impact total retention, survivorship, returnship, or cumulative values such that these measures differ surprisingly from the individual cohorts.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Cohort Analysis -- Original</span>"
    ]
  },
  {
    "objectID": "original_sql.html#cross-section-analysis-through-a-cohort-lens",
    "href": "original_sql.html#cross-section-analysis-through-a-cohort-lens",
    "title": "1  Cohort Analysis – Original",
    "section": "1.5 Cross-Section Analysis, through a Cohort Lens",
    "text": "1.5 Cross-Section Analysis, through a Cohort Lens\nSo far in this chapter, we’ve been looking at cohort analysis. We’ve followed the behavior of cohorts across time with retention, survivorship, returnship, and cumulative behavior analyses. One of the challenges with these analyses, however, is that even as they make changes within cohorts easy to spot, it can be difficult to spot changes in the overall composition of a customer or user base.\nMix shifts, which are changes in the composition of the customer or user base over time, can also occur, making later cohorts different from earlier ones. Mix shifts may be due to international expansion, shifting between organic and paid acquisition strategies, or moving from a niche enthusiast audience to a broader mass market one. Creating additional cohorts, or segments, along any of these suspected lines can help diagnose whether a mix shift is happening.\nCohort analysis can be contrasted with cross-sectional analysis, which compares individuals or groups at a single point in time. Cross-sectional studies can correlate years of education with current income, for example. On the positive side, collecting data sets for cross-sectional analysis is often easier since no time series is necessary. Cross-sectional analysis can be insightful, generating hypotheses for further investigation. On the negative side, a form of selection bias called survivorship bias usually exists, which can lead to false conclusions.\n\n\n\n\n\n\nSurvivorship bias\n\n\n\n“Let’s look at our best customers and see what they have in common.” This seemingly innocent and well-intentioned idea can lead to some very problematic conclusions. Survivorship bias is the logical error of focusing on the people or things that made it past some selection process, while ignoring those that did not. Commonly this is because the entities no longer exist in the data set at the time of selection, because they have failed, churned, or left the population for some other reason. Concentrating only on the remaining population can lead to overly optimistic conclusions, because failures are ignored.\nMuch has been written about a few people who dropped out of college and started wildly successful technology companies. This doesn’t mean you should immediately leave college, since the vast majority of people who drop out do not go on to be successful CEOs. That part of the population doesn’t make for nearly as sensational headlines, so it’s easy to forget about that reality.\nIn the successful customer context, survivorship bias might show up as an observation that the best customers tend to live in California or Texas and tend to be 18 to 30 years old. This is a large population to start with, and it may turn out that these characteristics are shared by many customers who churned prior to the analysis date. Going back to the original population might reveal that other demographics, such as 41-to-50-year-olds in Vermont, actually stick around and spend more over time, even though there are fewer of them in absolute terms. Cohort analysis helps distinguish and reduce survivorship bias.\n\n\nCohort analysis is a way to overcome survivorship bias by including all members of a starting cohort in the analysis. We can take a series of cross sections from a cohort analysis to understand how the mix of entities may have changed over time. On any given date, users from a variety of cohorts are present. We can use cross-sectional analysis to examine them, like layers of sediment, to reveal new insights. In the next example, we’ll create a time series of the share of legislators from each cohort for each year in the data set.\nThe first step is to find the number of legislators in office each year by JOINing the legislators table to the date_dim, WHERE the date from the date_dim is between the start and end dates of each term. Here we use December 31 for each year to find the legislators in office at each year’s end:\n\nSELECT b.date, count(distinct a.id_bioguide) as legislators\nFROM legislators_terms a\nJOIN date_dim b on b.date between a.term_start and a.term_end\nand b.month_name = 'December' and b.day_of_month = 31\nand b.year &lt;= 2019\nGROUP BY 1\nORDER BY 1\n\n\nDisplaying records 1 - 10\n\n\ndate\nlegislators\n\n\n\n\n1789-12-31\n89\n\n\n1790-12-31\n95\n\n\n1791-12-31\n99\n\n\n1792-12-31\n101\n\n\n1793-12-31\n141\n\n\n1794-12-31\n140\n\n\n1795-12-31\n145\n\n\n1796-12-31\n150\n\n\n1797-12-31\n152\n\n\n1798-12-31\n155\n\n\n\n\n\nNext, we add in the century cohorting criteria by JOINing to a subquery with the first_term calculated:\n\nSELECT b.date\n,date_part('century',first_term) as century\n,count(distinct a.id_bioguide) as legislators\nFROM legislators_terms a\nJOIN date_dim b on b.date between a.term_start and a.term_end\n and b.month_name = 'December' and b.day_of_month = 31\n and b.year &lt;= 2019\nJOIN\n(\n    SELECT id_bioguide, min(term_start) as first_term\n    FROM legislators_terms\n    GROUP BY 1\n) c on a.id_bioguide = c.id_bioguide        \nGROUP BY 1, 2\nORDER BY 1\n\n\nDisplaying records 1 - 10\n\n\ndate\ncentury\nlegislators\n\n\n\n\n1789-12-31\n18\n89\n\n\n1790-12-31\n18\n95\n\n\n1791-12-31\n18\n99\n\n\n1792-12-31\n18\n101\n\n\n1793-12-31\n18\n141\n\n\n1794-12-31\n18\n140\n\n\n1795-12-31\n18\n145\n\n\n1796-12-31\n18\n150\n\n\n1797-12-31\n18\n152\n\n\n1798-12-31\n18\n155\n\n\n\n\n\nFinally, we calculate the percent of total legislators in each year that the century cohort represents. This can be done in a couple of ways, depending on the shape of output desired. The first way is to keep a row for each date and century combination and use a sum window function in the denominator of the percentage calculation:\n\nSELECT date\n,century\n,legislators\n,sum(legislators) over (partition by date) as cohort\n,legislators / sum(legislators) over (partition by date) \n as pct_century\nFROM\n(\n    SELECT b.date\n    ,date_part('century',first_term) as century\n    ,count(distinct a.id_bioguide) as legislators\n    FROM legislators_terms a\n    JOIN date_dim b on b.date between a.term_start and a.term_end\n    and b.month_name = 'December' and b.day_of_month = 31\n    and b.year &lt;= 2019\n    JOIN\n    (\n        SELECT id_bioguide, min(term_start) as first_term\n        FROM legislators_terms\n        GROUP BY 1\n    ) c on a.id_bioguide = c.id_bioguide        \n    GROUP BY 1,2\n) a\nORDER BY 1 DESC\n\n\nDisplaying records 1 - 10\n\n\ndate\ncentury\nlegislators\ncohort\npct_century\n\n\n\n\n2019-12-31\n21\n440\n537\n0.8193669\n\n\n2019-12-31\n20\n97\n537\n0.1806331\n\n\n2018-12-31\n20\n122\n539\n0.2263451\n\n\n2018-12-31\n21\n417\n539\n0.7736549\n\n\n2017-12-31\n20\n124\n538\n0.2304833\n\n\n2017-12-31\n21\n414\n538\n0.7695167\n\n\n2016-12-31\n20\n142\n540\n0.2629630\n\n\n2016-12-31\n21\n398\n540\n0.7370370\n\n\n2015-12-31\n20\n144\n540\n0.2666667\n\n\n2015-12-31\n21\n396\n540\n0.7333333\n\n\n\n\n\nThe second approach results in one row per year, with a column for each century, a table format that may be easier to scan for trends:\n\nSELECT date\n,coalesce(sum(case when century = 18 then legislators end)\n          / sum(legislators),0) as pct_18\n,coalesce(sum(case when century = 19 then legislators end)\n          / sum(legislators),0) as pct_19\n,coalesce(sum(case when century = 20 then legislators end)\n          / sum(legislators),0) as pct_20\n,coalesce(sum(case when century = 21 then legislators end)\n          / sum(legislators),0) as pct_21\nFROM\n(\n    SELECT b.date\n    ,date_part('century',first_term) as century\n    ,count(distinct a.id_bioguide) as legislators\n    FROM legislators_terms a\n    JOIN date_dim b on b.date between a.term_start and a.term_end\n     and b.month_name = 'December' and b.day_of_month = 31\n     and b.year &lt;= 2019\n    JOIN\n    (\n        SELECT id_bioguide, min(term_start) as first_term\n        FROM legislators_terms\n        GROUP BY 1\n    ) c on a.id_bioguide = c.id_bioguide        \n    GROUP BY 1,2\n) aa\nGROUP BY 1\nORDER BY 1 DESC\n\n\n\n\n\n\n\n\n\nFigure 1.11: Percent of legislators each year, by century first elected\n\n\n\n\n\nWe can graph the output, as in Figure 3.11, to see how newer cohorts of legislators gradually overtake older cohorts, until they themselves are replaced by new cohorts.\nRather than cohorting on first_term, we can cohort on tenure instead. Finding the share of customers who are relatively new, are of medium tenure, or are long-term customers at various points in time can be insightful. Let’s take a look at how the tenure of legislators in Congress has changed over time.\nThe first step is to calculate, for each year, the cumulative number of years in office for each legislator. Since there can be gaps between terms when legislators are voted out or leave office for other reasons, we’ll first find each year in which the legislator was in office at the end of the year, in the subquery. Then we’ll use a count window function, with the window covering the rows unbounded preceding, or all prior rows for that legislator, and current row:\n\nSELECT id_bioguide, date\n,count(date) over (partition by id_bioguide \n                   order by date rows between \n                   unbounded preceding and current row\n                   ) as cume_years\nFROM\n(\n    SELECT distinct a.id_bioguide, b.date\n    FROM legislators_terms a\n    JOIN date_dim b on b.date between a.term_start and a.term_end\n     and b.month_name = 'December' and b.day_of_month = 31\n     and b.year &lt;= 2019\n) aa\nORDER BY 1, 2 DESC\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\ndate\ncume_years\n\n\n\n\nA000001\n1952-12-31\n2\n\n\nA000001\n1951-12-31\n1\n\n\nA000002\n1972-12-31\n26\n\n\nA000002\n1971-12-31\n25\n\n\nA000002\n1970-12-31\n24\n\n\nA000002\n1969-12-31\n23\n\n\nA000002\n1968-12-31\n22\n\n\nA000002\n1967-12-31\n21\n\n\nA000002\n1966-12-31\n20\n\n\nA000002\n1965-12-31\n19\n\n\n\n\n\nNext, count the number of legislators for each combination of date and cume_years to create a distribution:\n\nSELECT date, cume_years\n,count(distinct id_bioguide) as legislators\nFROM\n(\nSELECT id_bioguide, date\n,count(date) over (partition by id_bioguide \n                   order by date rows between \n                   unbounded preceding and current row\n                   ) as cume_years\nFROM\n(\n    SELECT distinct a.id_bioguide, b.date\n    FROM legislators_terms a\n    JOIN date_dim b on b.date between a.term_start and a.term_end\n     and b.month_name = 'December' and b.day_of_month = 31\n     and b.year &lt;= 2019\n    GROUP BY 1,2\n    ) aa\n) aaa\nGROUP BY 1, 2\nORDER BY 1\n\n\nDisplaying records 1 - 10\n\n\ndate\ncume_years\nlegislators\n\n\n\n\n1789-12-31\n1\n89\n\n\n1790-12-31\n2\n89\n\n\n1790-12-31\n1\n6\n\n\n1791-12-31\n3\n57\n\n\n1791-12-31\n1\n37\n\n\n1791-12-31\n2\n5\n\n\n1792-12-31\n2\n37\n\n\n1792-12-31\n3\n5\n\n\n1792-12-31\n4\n56\n\n\n1792-12-31\n1\n3\n\n\n\n\n\nBefore calculating the percentage for each tenure per year and adjusting the presentation format, we might want to consider grouping the tenures. A quick profiling of our results so far reveals that in some years, almost 40 different tenures are represented. This will likely be difficult to visualize and interpret:\n\nSELECT date, count(*) as tenures\nFROM \n(\n    SELECT date, cume_years\n    ,count(distinct id_bioguide) as legislators\n    FROM\n    (\n        SELECT id_bioguide, date\n        ,count(date) over (partition by id_bioguide \n                           order by date rows between \n                           unbounded preceding and current row\n                           ) as cume_years\n        FROM\n        (\n            SELECT distinct a.id_bioguide, b.date\n            FROM legislators_terms a\n            JOIN date_dim b \n             on b.date between a.term_start and a.term_end\n             and b.month_name = 'December' and b.day_of_month = 31\n             and b.year &lt;= 2019\n            GROUP BY 1,2\n        ) aa\n    ) aaa\n    GROUP BY 1,2\n) aaaa\nGROUP BY 1\nORDER BY 1 DESC\n\n\nDisplaying records 1 - 10\n\n\ndate\ntenures\n\n\n\n\n2019-12-31\n35\n\n\n2018-12-31\n36\n\n\n2017-12-31\n35\n\n\n2016-12-31\n36\n\n\n2015-12-31\n35\n\n\n2014-12-31\n35\n\n\n2013-12-31\n35\n\n\n2012-12-31\n36\n\n\n2011-12-31\n36\n\n\n2010-12-31\n36\n\n\n\n\n\nAs a result, we may want to group the values. There is no single right way to group tenures. If there are organizational definitions of tenure groups, go ahead and use them. Otherwise, I usually try to break them up into three to five groups of roughly equal size. Here we’ll group the tenures into four cohorts, where cume_years is less than or equal to 4 years, between 5 and 10 years, between 11 and 20 years, and equal to or more than 21 years:\n\nSELECT date, tenure\n,legislators / sum(legislators) over (partition by date) \n as pct_legislators \nFROM\n(\n    SELECT date,\n      case when cume_years &lt;= 4 then '1 to 4'\n           when cume_years &lt;= 10 then '5 to 10'\n           when cume_years &lt;= 20 then '11 to 20'\n           else '21+' end as tenure\n    ,count(distinct id_bioguide) as legislators\n    FROM\n    (\n        SELECT id_bioguide, date\n        ,count(date) over (partition by id_bioguide \n                           order by date rows between \n                           unbounded preceding and current row\n                           ) as cume_years\n        FROM\n        (\n            SELECT distinct a.id_bioguide, b.date\n            FROM legislators_terms a\n            JOIN date_dim b \n             on b.date between a.term_start and a.term_end\n             and b.month_name = 'December' and b.day_of_month = 31\n             and b.year &lt;= 2019\n            GROUP BY 1,2\n        ) a\n    ) aa\n    GROUP BY 1,2\n) aaa\nORDER BY 1 DESC, 2\n\nThe graphing of the results in Figure 4-14 shows that in the early years of the country, most legislators had very little tenure. In more recent years, the share of legislators with 21 or more years in office has been increasing. There are also interesting periodic increases in 1-to-4-year-tenure legislators that may reflect shifts in political trends.\n\n\n\n\n\n\n\n\nFigure 1.12: Percent of legislators by number of years in office\n\n\n\n\n\nA cross section of a population at any point in time is made up of members from multiple cohorts. Creating a time series of these cross sections is another interesting way of analyzing trends. Combining this with insights from retention can provide a more robust picture of trends in any organization.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Cohort Analysis -- Original</span>"
    ]
  },
  {
    "objectID": "original_sql.html#conclusion",
    "href": "original_sql.html#conclusion",
    "title": "1  Cohort Analysis – Original",
    "section": "1.6 Conclusion",
    "text": "1.6 Conclusion\nCohort analysis is a useful way to investigate how groups change over time, whether it be from the perspective of retention, repeat behavior, or cumulative actions. Cohort analysis is retrospective, looking back at populations using intrinsic attributes or attributes derived from behavior. Interesting and hopefully useful correlations can be found through this type of analysis. However, as the saying goes, correlation does not imply causation. To determine actual causality, randomized experiments are the gold standard. Chapter 7 will go into depth on experiment analysis.\nBefore we turn to experimentation, however, we have a few other types of analysis to cover. Next we’ll cover text analysis: components of text analysis often show up in other analyses, and it’s an interesting facet of analysis in itself.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Cohort Analysis -- Original</span>"
    ]
  },
  {
    "objectID": "original_sql.html#footnotes",
    "href": "original_sql.html#footnotes",
    "title": "1  Cohort Analysis – Original",
    "section": "",
    "text": "Well, actually the 18th century ran from 1701 to 1800. This can be confirmed by comparing output from SELECT date_part('century', '1700-12-31'::date) with that from SELECT date_part('century', '1701-01-01'::date).↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Cohort Analysis -- Original</span>"
    ]
  },
  {
    "objectID": "ctes_comments.html",
    "href": "ctes_comments.html",
    "title": "2  Cohort Analysis – CTE Version",
    "section": "",
    "text": "2.1 Cohorts: A Useful Analysis Framework\nBefore we get into the code, I will define what cohorts are, consider the types of questions we can answer with this type of analysis, and describe the components of any cohort analysis.\nA cohort is a group of individuals who share some characteristic of interest, described below, at the time we start observing them. Cohort members are often people but can be any type of entity we want to study: companies, products, or physical world phenomena. Individuals in a cohort may be aware of their membership, just as children in a first-grade class are aware they are part of a peer group of first graders, or participants in a drug trial are aware they are part of a group receiving a treatment. At other times, entities are grouped into cohorts virtually, as when a software company groups all customers acquired in a certain year to study how long they remain customers. It’s always important to consider the ethical implications of cohorting entities without their awareness, if any different treatment is to be applied to them.\nCohort analysis is a useful way to compare groups of entities over time. Many important behaviors take weeks, months, or years to occur or evolve, and cohort analysis is a way to understand these changes. Cohort analysis provides a framework for detecting correlations between cohort characteristics and these long-term trends, which can lead to hypotheses about the causal drivers. For example, customers acquired through a marketing campaign may have different long-term purchase patterns than those who were persuaded by a friend to try a company’s products. Cohort analysis can be used to monitor new cohorts of users or customers and assess how they compare to previous cohorts. Such monitoring can provide an early alert signal that something has gone wrong (or right) for new customers. Cohort analysis is also used to mine historical data. A/B tests, discussed in Chapter 7, are the gold standard for determining causality, but we can’t go back in time and run every test for every question about the past in which we are interested. We should of course be cautious about attaching causal meaning to cohort analysis and instead use cohort analysis as a way to understand customers and generate hypotheses that can be tested rigorously in the future.\nCohort analyses have three components: the cohort grouping, a time series of data over which the cohort is observed, and an aggregate metric that measures an action done by cohort members.\nCohort grouping is often based on a start date: the customer’s first purchase or subscription date, the date a student started school, and so on. However, cohorts can also be formed around other characteristics that are either innate or changing over time. Innate qualities include birth year and country of origin, or the year a company was founded. Characteristics that can change over time include city of residence and marital status. When these are used, we need to be careful to cohort only on the value on the starting date, or else entities can jump between cohort groups.\nThe second component of any cohort analysis is the time series. This is a series of purchases, logins, interactions, or other actions that are taken by the customers or entities to be cohorted. It’s important that the time series covers the entire life span of the entities, or there will be survivorship bias in early cohorts. Survivorship bias occurs when only customers who have stayed are in the data set; churned customers are excluded because they are no longer around, so the rest of the customers appear to be of higher quality or fit in comparison to newer cohorts (see “Survivorship Bias”). It’s also important to have a time series that is long enough for the entities to complete the action of interest. For example, if customers tend to purchase once a month, a time series of several months is needed. If, on the other hand, purchases happen only once a year, a time series of several years would be preferable. Inevitably, more recently acquired customers will not have had as long to complete actions as those customers who were acquired further in the past. In order to normalize, cohort analysis usually measures the number of periods that have elapsed from a starting date, rather than calendar months. In this way, cohorts can be compared in period 1, period 2, and so on to see how they evolve over time, regardless of which month the action actually occurred. The intervals may be days, weeks, months, or years.\nThe aggregate metric should be related to the actions that matter to the health of the organization, such as customers continuing to use or purchase the product. Metric values are aggregated across the cohort, usually with sum, count, or average, though any relevant aggregation works. The result is a time series that can then be used to understand changes in behavior over time.\nIn this chapter, I’ll cover four types of cohort analysis: retention, survivorship, returnship or repeat purchase behavior, and cumulative behavior.\nThe four types of cohort analysis allow us to compare subgroups and understand how they differ over time in order to make better product, marketing, and financial decisions. The calculations for the different types are similar, so we will set the stage with retention, and then I’ll show how to modify retention code to calculate the other types. Before we dive into constructing our cohort analysis, let’s take a look at the data set we’ll be using for the examples in this chapter.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Cohort Analysis -- CTE Version</span>"
    ]
  },
  {
    "objectID": "ctes_comments.html#cohorts-a-useful-analysis-framework",
    "href": "ctes_comments.html#cohorts-a-useful-analysis-framework",
    "title": "2  Cohort Analysis – CTE Version",
    "section": "",
    "text": "Cohort or Segment?\n\n\n\nThese two terms are often used in similar ways, or even interchangeably, but it’s worth drawing a distinction between them for the sake of clarity. A cohort is a group of users (or other entities) who have a common starting date and are followed over time. A segment is a grouping of users who share a common characteristic or set of characteristics at a point in time, regardless of their starting date. Similar to cohorts, segments can be based on innate factors such as age or on behavioral characteristics. A segment of users that signs up in the same month can be put into a cohort and followed over time. Or different groupings of users can be explored with cohort analysis so that you can see which ones have the most valuable characteristics. The analyses we’ll cover in this chapter, such as retention, can help put concrete data behind marketing segments.\n\n\n\n\n\n\nRetention\n\nRetention is concerned with whether the cohort member has a record in the time series on a particular date, expressed as a number of periods from the starting date. This is useful in any kind of organization in which repeated actions are expected, from playing an online game to using a product or renewing a subscription, and it helps to answer questions about how sticky or engaging a product is and how many entities can be expected to appear on future dates.\n\nSurvivorship\n\nSurvivorship is concerned with how many entities remained in the data set for a certain length of time or longer, regardless of the number or frequency of actions up to that time. Survivorship is useful for answering questions about the proportion of the population that can be expected to remain—either in a positive sense by not churning or passing away, or in a negative sense by not graduating or fulfilling some requirement.\n\nReturnship\n\nReturnship or repeat purchase behavior is concerned with whether an action has happened more than some minimum threshold of times—often simply more than once—during a fixed window of time. This type of analysis is useful in situations in which the behavior is intermittent and unpredictable, such as in retail, where it characterizes the share of repeat purchasers in each cohort within a fixed time window.\n\nCumulative\n\nCumulative calculations are concerned with the total number or amounts measured at one or more fixed time windows, regardless of when they happened during that window. Cumulative calculations are often used in calculations of customer lifetime value (LTV or CLTV).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Cohort Analysis -- CTE Version</span>"
    ]
  },
  {
    "objectID": "ctes_comments.html#the-legislators-data-set",
    "href": "ctes_comments.html#the-legislators-data-set",
    "title": "2  Cohort Analysis – CTE Version",
    "section": "2.2 The Legislators Data Set",
    "text": "2.2 The Legislators Data Set\nThe SQL examples in this chapter will use a data set of past and present members of the United States Congress maintained in a GitHub repository. In the US, Congress is responsible for writing laws or legislation, so its members are also known as legislators. Since the data set is a JSON file, I have applied some transformations to produce a more suitable data model for analysis, and I have posted data in a format suitable for following along with the examples in the book’s GitHub legislators folder.\nThe source repository has an excellent data dictionary, so I won’t repeat all the details here. I will provide a few details, however, that should help those who aren’t familiar with the US government to follow along with the analyses in this chapter.\nCongress has two chambers, the Senate (“sen” in the data set) and the House of Representatives (“rep”). Each state has two senators, and they are elected for six-year terms. Representatives are allocated to states based on population; each representative has a district that they alone represent. Representatives are elected for two-year terms. Actual terms in either chamber can be shorter in the event that the legislator dies or is elected or appointed to a higher office. Legislators accumulate power and influence via leadership positions the longer they are in office, and thus standing for re-election is common. Finally, a legislator may belong to a political party, or they may be an “independent”. In the modern era, the vast majority of legislators are Democrats or Republicans, and the rivalry between the two parties is well known. Legislators occasionally change parties while in office.\nFor the analyses, we’ll make use of two tables: legislators and legislators_terms. The legislators table contains a list of all the people included in the data set, with birthday, gender, and a set of ID fields that can be used to look up the person in other data sets. The legislators_terms table contains a record for each term in office for each legislator, with start and end date, and other attributes such as chamber and id_bioguide field is used as the unique identifier of a legislator and appears in each table. Table 3.1 shows a sample of the legislators data. Table 3.2 shows a sample of the legislators_terms data.\n\n\n\n\nTable 2.1: Sample of the legislators table\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                full_name\n                first_name\n                last_name\n                birthday\n                gender\n                id_bioguide\n                id_govtrack\n              \n        \n        \n        \n                \n                  Sherrod Brown        \n                  Sherrod \n                  Brown     \n                  1952-11-09\n                  M\n                  B000944\n                  400050\n                \n                \n                  Maria Cantwell       \n                  Maria   \n                  Cantwell  \n                  1958-10-13\n                  F\n                  C000127\n                  300018\n                \n                \n                  Benjamin L. Cardin   \n                  Benjamin\n                  Cardin    \n                  1943-10-05\n                  M\n                  C000141\n                  400064\n                \n                \n                  Thomas R. Carper     \n                  Thomas  \n                  Carper    \n                  1947-01-23\n                  M\n                  C000174\n                  300019\n                \n                \n                  Robert P. Casey, Jr. \n                  Robert  \n                  Casey     \n                  1960-04-13\n                  M\n                  C001070\n                  412246\n                \n                \n                  Dianne Feinstein     \n                  Dianne  \n                  Feinstein \n                  1933-06-22\n                  F\n                  F000062\n                  300043\n                \n                \n                  Russ Fulcher         \n                  Russ    \n                  Fulcher   \n                  1973-07-19\n                  M\n                  F000469\n                  412773\n                \n                \n                  Amy Klobuchar        \n                  Amy     \n                  Klobuchar \n                  1960-05-25\n                  F\n                  K000367\n                  412242\n                \n                \n                  Robert Menendez      \n                  Robert  \n                  Menendez  \n                  1954-01-01\n                  M\n                  M000639\n                  400272\n                \n                \n                  Bernard Sanders      \n                  Bernard \n                  Sanders   \n                  1941-09-08\n                  M\n                  S000033\n                  400357\n                \n                \n                  Debbie Stabenow      \n                  Debbie  \n                  Stabenow  \n                  1950-04-29\n                  F\n                  S000770\n                  300093\n                \n                \n                  Jon Tester           \n                  Jon     \n                  Tester    \n                  1956-08-21\n                  M\n                  T000464\n                  412244\n                \n                \n                  Sheldon Whitehouse   \n                  Sheldon \n                  Whitehouse\n                  1955-10-20\n                  M\n                  W000802\n                  412247\n                \n                \n                  Nanette Diaz Barragán\n                  Nanette \n                  Barragán  \n                  1976-09-15\n                  F\n                  B001300\n                  412687\n                \n                \n                  John Barrasso        \n                  John    \n                  Barrasso  \n                  1952-07-21\n                  M\n                  B001261\n                  412251\n                \n                \n                  Roger F. Wicker      \n                  Roger   \n                  Wicker    \n                  1951-07-05\n                  M\n                  W000437\n                  400432\n                \n                \n                  Lamar Alexander      \n                  Lamar   \n                  Alexander \n                  1940-07-03\n                  M\n                  A000360\n                  300002\n                \n                \n                  Susan M. Collins     \n                  Susan   \n                  Collins   \n                  1952-12-07\n                  F\n                  C001035\n                  300025\n                \n                \n                  John Cornyn          \n                  John    \n                  Cornyn    \n                  1952-02-02\n                  M\n                  C001056\n                  300027\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n\n\nTable 2.2: Sample of the legislators_terms table\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                id_bioguide\n                term_id\n                term_type\n                term_start\n                term_end\n                state\n                district\n                party\n              \n        \n        \n        \n                \n                  B000944\n                  B000944-0\n                  rep\n                  1993-01-05\n                  1995-01-03\n                  OH\n                  13\n                  Democrat   \n                \n                \n                  C000127\n                  C000127-0\n                  rep\n                  1993-01-05\n                  1995-01-03\n                  WA\n                   1\n                  Democrat   \n                \n                \n                  C000141\n                  C000141-0\n                  rep\n                  1987-01-06\n                  1989-01-03\n                  MD\n                   3\n                  Democrat   \n                \n                \n                  C000174\n                  C000174-0\n                  rep\n                  1983-01-03\n                  1985-01-03\n                  DE\n                   0\n                  Democrat   \n                \n                \n                  C001070\n                  C001070-0\n                  sen\n                  2007-01-04\n                  2013-01-03\n                  PA\n                  NA\n                  Democrat   \n                \n                \n                  F000062\n                  F000062-0\n                  sen\n                  1992-11-10\n                  1995-01-03\n                  CA\n                  NA\n                  Democrat   \n                \n                \n                  F000469\n                  F000469-0\n                  rep\n                  2019-01-03\n                  2021-01-03\n                  ID\n                   1\n                  Republican \n                \n                \n                  K000367\n                  K000367-0\n                  sen\n                  2007-01-04\n                  2013-01-03\n                  MN\n                  NA\n                  Democrat   \n                \n                \n                  M000639\n                  M000639-0\n                  rep\n                  1993-01-05\n                  1995-01-03\n                  NJ\n                  13\n                  Democrat   \n                \n                \n                  S000033\n                  S000033-0\n                  rep\n                  1991-01-03\n                  1993-01-03\n                  VT\n                   0\n                  Independent\n                \n                \n                  S000770\n                  S000770-0\n                  rep\n                  1997-01-07\n                  1999-01-03\n                  MI\n                   8\n                  Democrat   \n                \n                \n                  T000464\n                  T000464-0\n                  sen\n                  2007-01-04\n                  2013-01-03\n                  MT\n                  NA\n                  Democrat   \n                \n                \n                  W000802\n                  W000802-0\n                  sen\n                  2007-01-04\n                  2013-01-03\n                  RI\n                  NA\n                  Democrat   \n                \n                \n                  B001300\n                  B001300-0\n                  rep\n                  2017-01-03\n                  2019-01-03\n                  CA\n                  44\n                  Democrat   \n                \n                \n                  B001261\n                  B001261-0\n                  sen\n                  2007-06-25\n                  2013-01-03\n                  WY\n                  NA\n                  Republican \n                \n                \n                  W000437\n                  W000437-0\n                  rep\n                  1995-01-04\n                  1997-01-03\n                  MS\n                   1\n                  Republican \n                \n                \n                  A000360\n                  A000360-0\n                  sen\n                  2003-01-07\n                  2009-01-03\n                  TN\n                  NA\n                  Republican \n                \n                \n                  C001035\n                  C001035-0\n                  sen\n                  1997-01-07\n                  2003-01-03\n                  ME\n                  NA\n                  Republican \n                \n                \n                  C001056\n                  C001056-0\n                  sen\n                  2002-11-30\n                  2003-01-03\n                  TX\n                  NA\n                  Republican \n                \n        \n      \n    \n\n\n\n\n\n\nNow that we have an understanding of what cohort analysis is and of the data set we’ll be using for examples, let’s get into how to write SQL for retention analysis. The key question SQL will help us answer is: once representatives take office, how long do they keep their jobs?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Cohort Analysis -- CTE Version</span>"
    ]
  },
  {
    "objectID": "ctes_comments.html#retention",
    "href": "ctes_comments.html#retention",
    "title": "2  Cohort Analysis – CTE Version",
    "section": "2.3 Retention",
    "text": "2.3 Retention\nOne of the most common types of cohort analysis is retention analysis. To retain is to keep or continue something. Many skills need to be practiced to be retained. Businesses usually want their customers to keep purchasing their products or using their services, since retaining customers is more profitable than acquiring new ones. Employers want to retain their employees, because recruiting replacements is expensive and time consuming. Elected officials seek reelection in order to continue working on the priorities of their constituents.\nThe main question in retention analysis is whether the starting size of the cohort—number of subscribers or employees, amount spent, or another key metric—will remain constant, decay, or increase over time. When there is an increase or a decrease, the amount and speed of change are also interesting questions. In most retention analyses, the starting size will tend to decay over time, since a cohort can lose but cannot gain new members once it is formed. Revenue is an interesting exception, since a cohort of customers can spend more in subsequent months than they did in the first month collectively, even if some of them churn.\nRetention analysis uses the count of entities or sum of money or actions present in the data set for each period from the starting date, and it normalizes by dividing this number by the count or sum of entities, money, or actions in the first time period. The result is expressed as a percentage, and retention in the starting period is always 100%. Over time, retention based on counts generally declines and can never exceed 100%, whereas money- or action-based retention, while often declining, can increase and be greater than 100% in a time period. Retention analysis output is typically displayed in either table or graph form, which is referred to as a retention curve. We’ll see a number of examples of retention curves later in this chapter.\nGraphs of retention curves can be used to compare cohorts. The first characteristic to pay attention to is the shape of the curve in the initial few periods, where there is often an initial steep drop. For many consumer apps, losing half a cohort in the first few months is common. A cohort with a curve that is either more or less steep than others can indicate changes in the product or customer acquisition source that merit further investigation. A second characteristic to look for is whether the curve flattens after some number of periods or continues declining rapidly to zero. A flattening curve indicates that there is a point in time from which most of the cohort that remains stays indefinitely. A retention curve that inflects upward, sometimes called a smile curve, can occur if cohort members return or reactivate after falling out of the data set for some period. Finally, retention curves that measure subscription revenue are monitored for signs of increasing revenue per customer over time, a sign of a healthy SaaS software business.\nThis section will show how to create a retention analysis, add cohort groupings from the time series itself and other tables, and handle missing and sparse data that can occur in time series data. With this framework in hand, you’ll learn in the subsequent section how to make modifications to create the other related types of cohort analysis. As a result, this section on retention will be the longest one in the chapter, as you build up code and develop your intuition about the calculations.\n\n2.3.1 SQL for a Basic Retention Curve\n\nSELECT id_bioguide, min(term_start) AS first_term\nFROM legislators_terms \nGROUP BY 1;\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nfirst_term\n\n\n\n\nB000944\n1993-01-05\n\n\nC000127\n1993-01-05\n\n\nC001070\n2007-01-04\n\n\nF000469\n2019-01-03\n\n\nS000770\n1997-01-07\n\n\nB001261\n2007-06-25\n\n\nM001183\n2010-11-15\n\n\nB001230\n1999-01-06\n\n\nB001270\n2011-01-05\n\n\nB001251\n2004-07-21\n\n\n\n\n\nThe next step is to put this code into a CTE and JOIN it to the time series. The age() function is applied to calculate the intervals between each term_start and the first_term for each legislator. Applying year() to the result transforms this into the number of yearly periods. Since elections happen every two or six years, we’ll use years as the time interval to calculate the periods. We could use a shorter interval, but in this data set there is little fluctuation daily or weekly. The count of legislators with records for that period is the number retained:\n\n\n\n\n\n\nOur first CTEs\n\n\n\nI put the query above in a CTE named first_terms. I also put the “main query” in a CTE that I query at the end. My reason for doing this is that this faciltates building on the CTEs in later queries.\nI use the year() function made available by DuckDB to replace date_part('year', x).\nI also use USING (id_bioguide) to replace ON a.id_bioguide = b.id_bioguide.\n\n\n\nWITH first_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1),\n  \ncohorts AS (\n  SELECT year(age(term_start, first_term)) AS period,\n    count(DISTINCT id_bioguide) AS cohort_retained\n  FROM first_terms\n  JOIN legislators_terms\n  USING (id_bioguide)\n  GROUP BY 1)\n\nSELECT * \nFROM cohorts\nORDER BY 1;\n\n\nDisplaying records 1 - 10\n\n\nperiod\ncohort_retained\n\n\n\n\n0\n12518\n\n\n1\n3600\n\n\n2\n3619\n\n\n3\n1831\n\n\n4\n3210\n\n\n5\n1744\n\n\n6\n2385\n\n\n7\n1360\n\n\n8\n1607\n\n\n9\n1028\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn databases that support the datediff function, the date_part-and-age construction can be replaced by this simpler function:\ndatediff('year', first_term, term_start)\nSome databases, such as Oracle, place the date_part last:\ndatediff(first_term, term_start, 'year')\n\n\nNow that we have the periods and the number of legislators retained in each, the final step is to calculate the total cohort_size and populate it in each row so that the cohort_retained can be divided by it. The first_value window function returns the first record in the PARTITION BY clause, according to the ordering set in the ORDER BY, a convenient way to get the cohort size in each row. In this case, the cohort_size comes from the first record in the entire data set, so the PARTITION BY is omitted:\nfirst_value(cohort_retained) over (order by period) as cohort_size\n\n\n\n\n\n\nWindow aliases\n\n\n\nUsing CTEs, adding to a query becomes much cleaner. Again I put the “main query” in a CTE (here cohort_stats), as this will facilitate later queries.\nNote that I put the window specification from the original query in a window alias w. This means I only have to write the window once, saving text and reducing errors.\n\n\nTo find the percent retained, divide the cohort_retained value by this same calculation:\n\nWITH \n\nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1),\n  \ncohorts AS (\n  SELECT year(age(term_start, first_term)) AS period,\n    count(DISTINCT id_bioguide) AS cohort_retained\n  FROM first_terms\n  JOIN legislators_terms\n  USING (id_bioguide)\n  GROUP BY 1),\n\ncohort_stats AS (\n  SELECT period,\n    first_value(cohort_retained) OVER w AS cohort_size,\n    cohort_retained,\n    cohort_retained / first_value(cohort_retained) OVER w AS pct_retained\n  FROM cohorts\n  WINDOW w AS (ORDER BY period))\n\nSELECT *\nFROM cohort_stats\nORDER BY 1\n\nWe now have a retention calculation, and we can see that there is a big drop-off between the 100% of legislators retained in period 0, or on their start date, and the share with another term record that starts a year later. Graphing the results, as in Figure 3.1, demonstrates how the curve flattens and eventually goes to zero, as even the longest-serving legislators eventually retire or die.\n\n\n\n\n\n\n\n\nFigure 2.1: Retention from start of first term for US legislators\n\n\n\n\n\nWe can take the cohort retention result and reshape the data to show it in table format. Pivot and flatten the results using an aggregate function with a CASE statement; max is used in this example, but other aggregations such as min or avg would return the same result. Retention is calculated for years 0 through 4, but additional years can be added by following the same pattern:\n\nWITH \n\nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1),\n  \ncohorts AS (\n  SELECT year(age(term_start, first_term)) AS period,\n    count(DISTINCT id_bioguide) AS cohort_retained\n  FROM first_terms\n  JOIN legislators_terms\n  USING (id_bioguide)\n  GROUP BY 1),\n\ncohort_stats AS (\n  SELECT period,\n    first_value(cohort_retained) OVER w AS cohort_size,\n    cohort_retained,\n    cohort_retained / first_value(cohort_retained) OVER w AS pct_retained\n  FROM cohorts\n  WINDOW w AS (ORDER BY period))\n\nSELECT cohort_size,\n  max(CASE WHEN period = 0 THEN pct_retained END) AS yr0,\n  max(CASE WHEN period = 1 THEN pct_retained END) AS yr1,\n  max(CASE WHEN period = 2 THEN pct_retained END) AS yr2,\n  max(CASE WHEN period = 3 THEN pct_retained END) AS yr3,\n  max(CASE WHEN period = 4 THEN pct_retained END) AS yr4\nFROM cohort_stats\nGROUP BY 1\nORDER BY 1\n\n\n1 records\n\n\ncohort_size\nyr0\nyr1\nyr2\nyr3\nyr4\n\n\n\n\n12518\n1\n0.2875859\n0.2891037\n0.1462694\n0.2564307\n\n\n\n\n\nRetention appears to be quite low, and from the graph we can see that it is jagged in the first few years. One reason for this is that a representative’s term lasts two years, and senators’ terms last six years, but the data set only contains records for the start of new terms; thus we are missing data for years in which a legislator was still in office but did not start a new term. Measuring retention each year is misleading in this case. One option is to measure retention only on a two- or six-year cycle, but there is also another strategy we can employ to fill in the “missing” data. I will cover this next before returning to the topic of forming cohort groups.\n\n\n2.3.2 Adjusting Time Series to Increase Retention Accuracy\nWe discussed techniques for cleaning “missing” data in Chapter 2, and we will turn to those techniques in this section in order to arrive at a smoother and more truthful retention curve for the legislators. When working with time series data, such as in cohort analysis, it’s important to consider not only the data that is present but also whether that data accurately reflects the presence or absence of entities at each time period. This is particularly a problem in contexts in which an event captured in the data leads to the entity persisting for some period of time that is not captured in the data. For example, a customer buying a software subscription is represented in the data at the time of the transaction, but that customer is entitled to use the software for months or years and is not necessarily represented in the data over that span. To correct for this, we need a way to derive the span of time in which the entity is still present, either with an explicit end date or with knowledge of the length of the subscription or term. Then we can say that the entity was present at any date in between those start and end dates.\nIn the legislators data set, we have a record for a term’s start date, but we are missing the notion that this “entitles” a legislator to serve for two or six years, depending on the chamber. To correct for this and smooth out the curve, we need to fill in the “missing” values for the years that legislators are still in office between new terms. Since this data set includes a term_end value for each term, I’ll show how to create a more accurate cohort retention analysis by filling in dates between the start and end values. Then I’ll show how you can impute end dates when the data set does not include an end date.\nCalculating retention using a start and end date defined in the data is the most accurate approach. For the following examples, we will consider legislators retained in a particular year if they were still in office as of the last day of the year, December 31. Prior to the Twentieth Amendment to the US Constitution, terms began on March 4, but afterward the start date moved to January 3, or to a subsequent weekday if the third falls on a weekend. Legislators can be sworn in on other days of the year due to special off-cycle elections or appointments to fill vacant seats. As a result, term_start dates cluster in January but are spread across the year. While we could pick another day, December 31 is a strategy for normalizing around these varying start dates.\nThe first step is to create a data set that contains a record for each December 31 that each legislator was in office. This can be accomplished by JOINing the first_terms CTE to the legislators_terms table to find the term_start and term_end for each term. A second JOIN to the date_dim retrieves the dates that fall between the start and end dates, restricting the returned values to c.month_name = 'December' and c.day_of_month = 31. The period is calculated as the years between the date from the date_dim and the first_term. Note that even though more than 11 months may have elapsed between being sworn in in January and December 31, the first year still appears as 0:\n\n\n\n\n\n\nReplacing date_dim\n\n\n\nIn almost all the queries in this chapter, the only rows of date_dim that are used are those where month_name = 'December' AND day_of_month = 31. So I create a CTE year_ends that I use over and over again.\nNote that there is a dramatic reduction in the number of meaningless aliases (e.g., a or bb) in the rewritten queries.\n\n\n\nWITH \n\nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1),\n  \nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31),\n \ncohorts AS (\n  SELECT id_bioguide, first_term,\n    term_start, term_end, date,\n    year(age(date, first_term)) AS period\n  FROM first_terms\n  JOIN legislators_terms \n  USING (id_bioguide)\n  LEFT JOIN year_ends\n  ON date BETWEEN term_start AND term_end)\n  \nSELECT *\nFROM cohorts\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nfirst_term\nterm_start\nterm_end\ndate\nperiod\n\n\n\n\nM000031\n1789-03-04\n1789-03-04\n1791-03-03\n1789-12-31\n0\n\n\nM000031\n1789-03-04\n1789-03-04\n1791-03-03\n1790-12-31\n1\n\n\nG000500\n1789-03-04\n1789-03-04\n1791-03-03\n1789-12-31\n0\n\n\nG000500\n1789-03-04\n1789-03-04\n1791-03-03\n1790-12-31\n1\n\n\nH000995\n1789-03-04\n1789-03-04\n1791-03-03\n1789-12-31\n0\n\n\nH000995\n1789-03-04\n1789-03-04\n1791-03-03\n1790-12-31\n1\n\n\nB000546\n1789-03-04\n1789-03-04\n1791-03-03\n1789-12-31\n0\n\n\nB000546\n1789-03-04\n1789-03-04\n1791-03-03\n1790-12-31\n1\n\n\nB001086\n1789-03-04\n1789-03-04\n1791-03-03\n1789-12-31\n0\n\n\nB001086\n1789-03-04\n1789-03-04\n1791-03-03\n1790-12-31\n1\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf a date dimension is not available, you can create a subquery with the necessary dates in a couple of ways. If your database supports generate_series, you can create a subquery that returns the desired dates:\n\nSELECT generate_series::date as date\nFROM generate_series('1770-12-31'::date,\n                     '2020-12-31'::date,\n                     interval '1 year')\n\nYou may want to save this as a table or view for later use. Alternatively, you can query the data set or any other table in the database that has a full set of dates. In this case, the table has all of the necessary years, but we will make a December 31 date for each year using the make_date function:\n\nSELECT DISTINCT\n  make_date(date_part('year',term_start)::int, 12, 31) AS date\nFROM legislators_terms\nORDER BY date\n\nThere are a number of creative ways to get the series of dates needed. Use whichever method is available and simplest within your queries.\n\n\nWe now have a row for each date (year END) for which we would like to calculate retention. The next step is to calculate the cohort_retained for each period, which is done with a count of id_bioguide. A coalesce function is used on period to set a default value of 0 when null. This handles the cases in which a legislator’s term starts and ends in the same year, giving credit for serving in that year:\n\nWITH \n\nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1),\n  \nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31\n)\n  \nSELECT coalesce(year(age(date, first_term)), 0) AS period,\n  count(DISTINCT id_bioguide) AS cohort_retained\nFROM first_terms a\nJOIN legislators_terms b \nUSING (id_bioguide)\nLEFT JOIN year_ends\nON date BETWEEN term_start and term_end\nGROUP BY 1\nORDER BY 1\n\n\nDisplaying records 1 - 10\n\n\nperiod\ncohort_retained\n\n\n\n\n0\n12518\n\n\n1\n12328\n\n\n2\n8166\n\n\n3\n8069\n\n\n4\n5862\n\n\n5\n5795\n\n\n6\n4361\n\n\n7\n4339\n\n\n8\n3521\n\n\n9\n3485\n\n\n\n\n\nThe final step is to calculate the cohort_size and pct_retained as we did previously using first_value window functions:\n\nWITH \n\nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1),\n  \nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31),\n  \ncohorts AS (\n  SELECT year(age(term_start, first_term)) AS period,\n    count(DISTINCT id_bioguide) AS cohort_retained\n  FROM first_terms\n  JOIN legislators_terms \n  USING (id_bioguide)\n  LEFT JOIN year_ends\n  ON date BETWEEN term_start AND term_end\n  GROUP BY 1),\n\ncohort_stats AS (\n  SELECT period,\n    first_value(cohort_retained) OVER w AS cohort_size,\n    cohort_retained,\n    cohort_retained / first_value(cohort_retained) OVER w AS pct_retained\n  FROM cohorts\n  WINDOW w AS (ORDER BY period))\n\nSELECT *\nFROM cohort_stats\nORDER BY 1\n\nThe results, graphed in Figure 3.2, are now much more accurate. Almost all legislators are still in office in year 1, and the first big drop-off occurs in year 2, when some representatives will fail to be reelected.\n\n\n\n\n\n\n\n\nFigure 2.2: Legislator retention after adjusting for actual years in office\n\n\n\n\n\nIf the data set does not contain an end date, there are a couple of options for imputing one. One option is to add a fixed interval to the start date, when the length of a subscription or term is known. This can be done with date math by adding a constant interval to the term_start. Here, a CASE statement handles the addition for the two term_types:\n\nWITH \n\nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1)\n  \nSELECT id_bioguide, first_term, term_start,\n  CASE\n      WHEN term_type = 'rep' THEN term_start + INTERVAL '2 years'\n      WHEN term_type = 'sen' THEN term_start + INTERVAL '6 years'\n      END AS term_end\nFROM first_terms\nJOIN legislators_terms\nUSING (id_bioguide)\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nfirst_term\nterm_start\nterm_end\n\n\n\n\nB000944\n1993-01-05\n1993-01-05\n1995-01-05\n\n\nC000127\n1993-01-05\n1993-01-05\n1995-01-05\n\n\nC000141\n1987-01-06\n1987-01-06\n1989-01-06\n\n\nC000174\n1983-01-03\n1983-01-03\n1985-01-03\n\n\nC001070\n2007-01-04\n2007-01-04\n2013-01-04\n\n\nF000062\n1992-11-10\n1992-11-10\n1998-11-10\n\n\nF000469\n2019-01-03\n2019-01-03\n2021-01-03\n\n\nK000367\n2007-01-04\n2007-01-04\n2013-01-04\n\n\nM000639\n1993-01-05\n1993-01-05\n1995-01-05\n\n\nS000033\n1991-01-03\n1991-01-03\n1993-01-03\n\n\n\n\n\nThis block of code can then be plugged into the retention code to derive the period and pct_retained. The drawback to this method is that it fails to capture instances in which a legislator did not complete a full term, which can happen in the event of death or appointment to a higher office.\nA second option is to use the subsequent starting date, minus one day, as the term_end date. This can be calculated with the lead window function. This function is similar to the lag function we’ve used previously, but rather than returning a value from a row earlier in the partition, it returns a value from a row later in the partition, as determined in the ORDER BY clause. The default is one row, which we will use here, but the function has an optional argument indicating a different number of rows. Here we find the term_start date of the subsequent term using lead and then subtract the interval '1 day' to derive the term_end:\n\nWITH \n\nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1)\n\nSELECT id_bioguide, first_term, term_start,\n  lead(term_start) OVER w - INTERVAL '1 day' AS term_end\nFROM first_terms a\nJOIN legislators_terms b \nUSING (id_bioguide)\nWINDOW w AS (PARTITION BY id_bioguide ORDER BY term_start)\nORDER BY id_bioguide\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nfirst_term\nterm_start\nterm_end\n\n\n\n\nA000001\n1951-01-03\n1951-01-03\nNA\n\n\nA000002\n1947-01-03\n1947-01-03\n1949-01-02\n\n\nA000002\n1947-01-03\n1949-01-03\n1951-01-02\n\n\nA000002\n1947-01-03\n1951-01-03\n1953-01-02\n\n\nA000002\n1947-01-03\n1953-01-03\n1955-01-04\n\n\nA000002\n1947-01-03\n1955-01-05\n1957-01-02\n\n\nA000002\n1947-01-03\n1957-01-03\n1959-01-06\n\n\nA000002\n1947-01-03\n1959-01-07\n1961-01-02\n\n\nA000002\n1947-01-03\n1961-01-03\n1963-01-08\n\n\nA000002\n1947-01-03\n1963-01-09\n1965-01-03\n\n\n\n\n\nThis code block can then be plugged into the retention code. This method has a couple of drawbacks. First, when there is no subsequent term, the lead function returns null, leaving that term without a term_end. A default value, such as a default interval shown in the last example, could be used in such cases. The second drawback is that this method assumes that terms are always consecutive, with no time spent out of office. Although most legislators tend to serve continuously until their congressional careers end, there are certainly examples of gaps between terms spanning several years.\nAny time we make adjustments to fill in missing data, we need to be careful about the assumptions we make. In subscription- or term-based contexts, explicit start and end dates tend to be most accurate. Either of the two other methods shown—adding a fixed interval or setting the end date relative to the next start date—can be used when no end date is present and we have a reasonable expectation that most customers or users will stay for the duration assumed.\nNow that we’ve seen how to calculate a basic retention curve and correct for missing dates, we can start adding in cohort groups. Comparing retention between different groups is one of the main reasons to do cohort analysis. Next, I’ll discuss forming groups from the time series itself, and after that, I’ll discuss forming cohort groups from data in other tables.\n\n\n2.3.3 Cohorts Derived from the Time Series Itself\nNow that we have SQL code to calculate retention, we can start to split the entities into cohorts. In this section, I will show how to derive cohort groupings from the time series itself. First I’ll discuss time-based cohorts based on the first date, and I’ll explain how to make cohorts based on other attributes from the time series.\nThe most common way to create the cohorts is based on the first or minimum date or time that the entity appears in the time series. This means that only one table is necessary for the cohort retention analysis: the time series itself. Cohorting by the first appearance or action is interesting because often groups that start at different times behave differently. For consumer services, early adopters are often more enthusiastic and retain differently than later adopters, whereas in SaaS software, later adopters may retain better because the product is more mature. Time-based cohorts can be grouped by any time granularity that is meaningful to the organization, though weekly, monthly, or yearly cohorts are common. If you’re not sure what grouping to use, try running the cohort analysis with different groupings, without making the cohort sizes too small, to see where meaningful patterns emerge. Fortunately, once you know how to construct the cohorts and retention analysis, substituting different time granularities is straightforward.\nThe first example will use yearly cohorts, and then I will demonstrate swapping in centuries. The key question we will consider is whether the era in which a legislator first took office has any correlation with their retention. Political trends and the public mood do change over time, but by how much?\nTo calculate yearly cohorts, we first add the year of the first_term calculated previously to cohorts_retained, the CTE that finds period and cohort_retained:\n\nWITH \n\nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1),\n  \nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31),\n  \ncohorts_retained AS (\n  SELECT year(first_term) AS first_year,\n    coalesce(year(age(date, first_term)), 0) AS period,\n    count(DISTINCT id_bioguide) AS cohort_retained\n  FROM first_terms\n  JOIN legislators_terms\n  USING (id_bioguide)\n  LEFT JOIN year_ends\n  ON date BETWEEN term_start AND term_end\n  GROUP BY 1, 2)\n  \nSELECT *\nFROM cohorts_retained\nORDER BY 1, 2\n\n\nDisplaying records 1 - 10\n\n\nfirst_year\nperiod\ncohort_retained\n\n\n\n\n1789\n0\n89\n\n\n1789\n1\n89\n\n\n1789\n2\n57\n\n\n1789\n3\n56\n\n\n1789\n4\n42\n\n\n1789\n5\n40\n\n\n1789\n6\n31\n\n\n1789\n7\n32\n\n\n1789\n8\n20\n\n\n1789\n9\n19\n\n\n\n\n\nData returned by the cohorts_retained CTE are then used to calculate cohort_size and pct_retained. In this case, however, we need a PARTITION BY clause that includes first_year so that the first_value is calculated only within the set of rows for that first_year, rather than across the whole result set from the subquery:\n\nWITH \n\nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1),\n  \nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31),\n  \ncohorts AS (\n  SELECT year(first_term) AS first_year,\n    coalesce(year(age(date, first_term)), 0) AS period,\n    count(DISTINCT id_bioguide) AS cohort_retained\n  FROM first_terms\n  JOIN legislators_terms\n  USING (id_bioguide)\n  LEFT JOIN year_ends\n  ON date BETWEEN term_start AND term_end\n  GROUP BY 1, 2)\n\nSELECT first_year, period,\n  first_value(cohort_retained) OVER w AS cohort_size,\n  cohort_retained,\n  cohort_retained / first_value(cohort_retained) OVER w AS pct_retained\nFROM cohorts\nWINDOW w AS (PARTITION BY 1 ORDER BY 2)\nORDER BY 1, 2\n\n\nDisplaying records 1 - 10\n\n\nfirst_year\nperiod\ncohort_size\ncohort_retained\npct_retained\n\n\n\n\n1789\n0\n89\n89\n1.0000000\n\n\n1789\n1\n89\n89\n1.0000000\n\n\n1789\n2\n89\n57\n0.6404494\n\n\n1789\n3\n89\n56\n0.6292135\n\n\n1789\n4\n89\n42\n0.4719101\n\n\n1789\n5\n89\n40\n0.4494382\n\n\n1789\n6\n89\n31\n0.3483146\n\n\n1789\n7\n89\n32\n0.3595506\n\n\n1789\n8\n89\n20\n0.2247191\n\n\n1789\n9\n89\n19\n0.2134831\n\n\n\n\n\nThis data set includes over two hundred starting years, too many to easily graph or examine in a table. Next we’ll look at a less granular interval and cohort the legislators by the century of the first_term. This change is easily made by substituting century() for year() in the cohorts CTE.\n\n\n\n\n\n\nCenturies\n\n\n\nThe original text says:\n\nRecall that century names are offset from the years they represent, so that the 18th century lasted from 1700 to 1799, the 19th century lasted from 1800 to 1899, and so on.\n\nActually the 18th century ran from 1701 to 1800 and the 19th century from 1801 to 1900. This can be confirmed by comparing output from\n\nSELECT century('1700-12-31'::date) AS century\n\n\n1 records\n\n\ncentury\n\n\n\n\n17\n\n\n\n\n\n\nSELECT century('1701-01-01'::date) AS century\n\n\n1 records\n\n\ncentury\n\n\n\n\n18\n\n\n\n\n\n\n\nThe partitioning in the first_value function changes to the first_century field:\n\nWITH \n\nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1),\n  \nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31),\n  \ncohorts AS (\n  SELECT century(first_term) AS first_century,\n    coalesce(year(age(date, first_term)), 0) AS period,\n    count(DISTINCT id_bioguide) AS cohort_retained\n  FROM first_terms\n  JOIN legislators_terms\n  USING (id_bioguide)\n  LEFT JOIN year_ends\n  ON date BETWEEN term_start AND term_end\n  GROUP BY 1, 2)\n  \nSELECT first_century, period,\n  first_value(cohort_retained) OVER w AS cohort_size,\n  cohort_retained,\n  cohort_retained / first_value(cohort_retained) OVER w AS pct_retained\nFROM cohorts\nWINDOW w AS (PARTITION BY 1 ORDER BY 2)\nORDER BY 1, 2\n\nThe results are graphed in Figure 3.3. Retention in the early years has been higher for those first elected in the 20th or 21st century. The 21st century is still under way, and thus many of those legislators have not had the opportunity to stay in office for five or more years, though they are still included in the denominator. We might want to consider removing the 21st century from the analysis, but I’ve left it here to demonstrate how the retention curve drops artificially due to this circumstance.\n\n\n\n\n\n\n\n\nFigure 2.3: Legislator retention by century in which first term began\n\n\n\n\n\nCohorts can be defined from other attributes in a time series besides the first date, with options depending on the values in the table. The legislators_terms table has a state field, indicating which state the person is representing for that term. We can use this to create cohorts, and we will base them on the first state in order to ensure that anyone who has represented multiple states appears in the data only once.\n\n\n\n\n\n\nWarning\n\n\n\nWhen cohorting on an attribute that can change over time, it’s important to ensure that each entity is assigned only one value. Otherwise the entity may be represented in multiple cohorts, introducing bias into the analysis. Usually the value from the earliest record in the data set is used.\n\n\nTo find the first state for each legislator, we can use the first_value window function. In this example, we’ll also turn the min function into a window function to avoid a lengthy GROUP BY clause:\n\nSELECT DISTINCT id_bioguide,\n  min(term_start) OVER w AS first_term,\n  first_value(state) OVER w AS first_state\nFROM legislators_terms\nWINDOW w AS (PARTITION BY id_bioguide ORDER BY term_start)\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nfirst_term\nfirst_state\n\n\n\n\nS000946\n1931-12-07\nPA\n\n\nT000014\n1915-12-06\nMA\n\n\nT000296\n1837-09-04\nPA\n\n\nT000418\n1827-12-03\nNC\n\n\nT000424\n1997-01-07\nTX\n\n\nT000466\n2009-01-06\nNM\n\n\nT000467\n2009-01-06\nPA\n\n\nW000171\n1905-12-04\nMA\n\n\nW000209\n1875-12-06\nKY\n\n\nW000410\n1957-01-03\nNC\n\n\n\n\n\n\n\n\n\n\n\nReplacing windows\n\n\n\nThe original SQL had two window definitions: one for first_term and another for first_state. However, the value returned by min() is unaffected by the addition of ORDER BY term_start, so I just use the same window for both functions.\n\n\nWe can then plug this code into our retention code to find the retention by first_state:\n\nWITH \nfirst_term_states AS (\n  SELECT distinct id_bioguide,\n    min(term_start) OVER w AS first_term,\n    first_value(state) OVER w AS first_state\n  FROM legislators_terms\n  WINDOW w AS (PARTITION BY id_bioguide ORDER BY term_start)),\n  \nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31),\n  \ncohorts AS (\n  SELECT first_state,\n    coalesce(year(age(date, first_term)), 0) AS period,\n    count(DISTINCT id_bioguide) AS cohort_retained\n  FROM first_term_states\n  JOIN legislators_terms\n  USING (id_bioguide)\n  LEFT JOIN year_ends\n  ON date BETWEEN term_start AND term_end\n  GROUP BY 1, 2),\n  \ncohort_sizes AS (\n  SELECT first_state, period, \n    first_value(cohort_retained) OVER w AS cohort_size,\n    cohort_retained\n  FROM cohorts\n  WINDOW w AS (PARTITION BY first_state ORDER BY period))\n\nSELECT first_state, period, cohort_size, cohort_retained,\n  cohort_retained / cohort_size AS pct_retained\nFROM cohort_sizes\nORDER BY 1, 2\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                first_state\n                period\n                cohort_size\n                cohort_retained\n                pct_retained\n              \n        \n        \n        \n                \n                  AK\n                  0\n                  19\n                  19\n                  1.0000000\n                \n                \n                  AK\n                  1\n                  19\n                  19\n                  1.0000000\n                \n                \n                  AK\n                  2\n                  19\n                  15\n                  0.7894737\n                \n                \n                  AK\n                  3\n                  19\n                  15\n                  0.7894737\n                \n                \n                  AK\n                  4\n                  19\n                  13\n                  0.6842105\n                \n                \n                  AK\n                  5\n                  19\n                  13\n                  0.6842105\n                \n        \n      \n    \n\n\n\nThe retention curves for the five states with the highest total number of legislators are graphed in Figure 3.4. Those elected in Illinois and Massachusetts have the highest retention, while New Yorkers have the lowest retention. Determining the reasons why would be an interesting offshoot of this analysis.\n\n\n\n\n\n\n\n\nFigure 2.4: Legislator retention by first state: top five states by total legislators\n\n\n\n\n\nDefining cohorts from the time series is relatively straightforward using a min date for each entity and then converting that date into a month, year, or century as appropriate for the analysis. Switching between month and year or other levels of granularity also is straightforward, allowing for multiple options to be tested in order to find a grouping that is meaningful for the organization. Other attributes can be used for cohorting with the first_value window function. Next, we’ll turn to cases in which the cohorting attribute comes from a table other than that of the time series.\n\n\n2.3.4 Defining the Cohort from a Separate Table\nOften the characteristics that define a cohort exist in a table separate from the one that contains the time series. For example, a database might have a customer table with information such as acquisition source or registration date by which customers can be cohorted. Adding in attributes from other tables, or even subqueries, is relatively straightforward and can be done in retention analysis and related analyses discussed later in the chapter.\nFor this example, we’ll consider whether the gender of the legislator has any impact on their retention. The legislators table has a gender field, where F means female and M means male, that we can use to cohort the legislators. To do this, we’ll JOIN the legislators table in as alias to add gender to cohorts, in place of year or century:\n\nWITH\n\nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1),\n  \nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31),\n  \ncohorts AS (\n  SELECT gender,\n    coalesce(year(age(date, first_term)), 0) AS period,\n    count(distinct id_bioguide) AS cohort_retained\n  FROM first_terms\n  JOIN legislators_terms\n  USING (id_bioguide)\n  LEFT JOIN year_ends \n  ON date BETWEEN term_start AND term_end\n  JOIN legislators\n  USING (id_bioguide)\n  GROUP BY 1, 2),\n  \ncohort_sizes AS (\n  SELECT gender, period, \n    first_value(cohort_retained) OVER w AS cohort_size,\n    cohort_retained\n  FROM cohorts\n  WINDOW w AS (PARTITION BY gender ORDER BY period))\n\nSELECT gender, period, cohort_size, cohort_retained,\n   cohort_retained / cohort_size AS pct_retained\nFROM cohort_sizes\nORDER BY 1, 2\n\n\nDisplaying records 1 - 10\n\n\ngender\nperiod\ncohort_size\ncohort_retained\npct_retained\n\n\n\n\nF\n0\n366\n366\n1.0000000\n\n\nF\n1\n366\n349\n0.9535519\n\n\nF\n2\n366\n261\n0.7131148\n\n\nF\n3\n366\n256\n0.6994536\n\n\nF\n4\n366\n223\n0.6092896\n\n\nF\n5\n366\n222\n0.6065574\n\n\nF\n6\n366\n178\n0.4863388\n\n\nF\n7\n366\n174\n0.4754098\n\n\nF\n8\n366\n143\n0.3907104\n\n\nF\n9\n366\n139\n0.3797814\n\n\n\n\n\nIt’s immediately clear that many more males than females have served legislative terms. We can now calculate the percent_retained so we can compare the retention for these groups:\n\nWITH\n\nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1),\n  \nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31),\n  \ncohorts AS (\n  SELECT gender,\n    coalesce(year(age(date, first_term)), 0) AS period,\n    count(DISTINCT id_bioguide) AS cohort_retained\n  FROM first_terms\n  JOIN legislators_terms\n  USING (id_bioguide)\n  LEFT JOIN year_ends \n  ON date BETWEEN term_start AND term_end\n  JOIN legislators\n  USING (id_bioguide)\n  GROUP BY 1, 2),\n  \ncohort_sizes AS (\n  SELECT gender, period, \n    first_value(cohort_retained) OVER w AS cohort_size,\n    cohort_retained\n  FROM cohorts\n  WINDOW w AS (PARTITION BY gender ORDER BY period))\n\nSELECT gender, period, cohort_size, cohort_retained,\n  cohort_retained / cohort_size AS pct_retained\nFROM cohort_sizes\nORDER BY 2, 1\n\nWe can see from the results graphed in Figure 3.5 that retention is higher for female legislators than for their male counterparts for periods 2 through 29. The first female legislator did not take office until 1917, when Jeannette Rankin joined the House as a Republican representative from Montana. As we saw earlier, retention has increased in more recent centuries.\n\n\n\n\n\n\n\n\nFigure 2.5: Legislator retention by gender\n\n\n\n\n\nTo make a fairer comparison, we might restrict the legislators included in the analysis to only those whose first_term started since there have been women in Congress. We can do this by adding a WHERE filter to the cohorts CTE. Here the results are also restricted to those who started before 2000, to ensure the cohorts have had at least 20 possible years to stay in office:\n\nWITH\n\nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1),\n  \nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31),\n  \ncohorts AS (\n  SELECT gender,\n    coalesce(year(age(date, first_term)), 0) AS period,\n    count(DISTINCT id_bioguide) AS cohort_retained\n  FROM first_terms\n  JOIN legislators_terms\n  USING (id_bioguide)\n  LEFT JOIN year_ends\n  ON date BETWEEN term_start AND term_end\n  JOIN legislators\n  USING (id_bioguide)\n  WHERE first_term BETWEEN '1917-01-01' AND '1999-12-31'\n  GROUP BY 1, 2),\n  \ncohort_sizes AS (\n  SELECT gender, period, cohort_retained,\n    first_value(cohort_retained) OVER w AS cohort_size\n  FROM cohorts\n  WINDOW w AS (PARTITION BY gender ORDER BY period))\n\nSELECT gender, period, cohort_size, cohort_retained,\n  cohort_retained / cohort_size AS pct_retained\nFROM cohort_sizes\nORDER BY 2, 1\n\nMale legislators still outnumber female legislators, but by a smaller margin. The retention for the cohorts is graphed in Figure 3.6. With the revised cohorts, male legislators have higher retention through year 7, but starting in year 12, female legislators have higher retention. The difference between the two gender-based cohort analyses underscores the importance of setting up appropriate cohorts and ensuring that they have comparable amounts of time to be present or complete other actions of interest. To further improve this analysis, we could cohort by both starting year or decade and gender, in order to control for additional changes in retention through the 20th century and into the 21st century.\n\n\n\n\n\n\n\n\nFigure 2.6: Legislator retention by gender: cohorts from 1917 to 1999\n\n\n\n\n\nCohorts can be defined in multiple ways, from the time series and from other tables. With the framework we’ve developed, subqueries, views, or other derived tables can be swapped in, opening up a whole range of calculations to be the basis of a cohort. Multiple criteria, such as starting year and gender, can be used. One caution when dividing populations into cohorts based on multiple criteria is that this can lead to sparse cohorts, where some of the defined groups are too small and are not represented in the data set for all time periods. The next section will discuss methods for overcoming this challenge.\n\n\n2.3.5 Dealing with Sparse Cohorts\nIn the ideal data set, every cohort has some action or record in the time series for every period of interest. We’ve already seen how “missing” dates can occur due to subscriptions or terms lasting over multiple periods, and we looked at how to correct for them using a date dimension to infer intermediate dates. Another issue can arise when, due to grouping criteria, the cohort becomes too small and as a result is represented only sporadically in the data. A cohort may disappear from the result set, when we would prefer it to appear with a zero retention value. This problem is called sparse cohorts, and it can be worked around with the careful use of LEFT JOINs.\nTo demonstrate this, let’s attempt to cohort female legislators by the first state they represented to see if there are any differences in retention. We’ve already seen that there have been relatively few female legislators. Cohorting them further by state is highly likely to create some sparse cohorts in which there are very few members. Before making code adjustments, let’s add first_state (calculated in the section on deriving cohorts from the time series) into our previous gender example and look at the results:\n\nWITH\n\nfirst_term_states AS (\n  SELECT distinct id_bioguide,\n    min(term_start) OVER w AS first_term,\n    first_value(state) OVER w AS first_state\n  FROM legislators_terms\n  WINDOW w AS (PARTITION BY id_bioguide ORDER BY term_start)),\n  \nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31),\n  \ncohorts AS (\n  SELECT gender, first_state,\n    coalesce(year(age(date, first_term)), 0) AS period,\n    count(distinct id_bioguide) AS cohort_retained\n  FROM first_term_states\n  JOIN legislators_terms\n  USING (id_bioguide)\n  LEFT JOIN year_ends\n  ON date BETWEEN term_start AND term_end\n  JOIN legislators\n  USING (id_bioguide)\n  WHERE first_term BETWEEN '1917-01-01' AND '1999-12-31'\n  GROUP BY 1, 2, 3),\n  \ncohort_sizes AS (\n  SELECT gender, first_state, period, cohort_retained,\n    first_value(cohort_retained) OVER w AS cohort_size\n  FROM cohorts\n  WINDOW w AS (PARTITION BY gender, first_state ORDER BY period))\n\nSELECT first_state, gender, period, cohort_size, cohort_retained,\n  cohort_retained / cohort_size AS pct_retained\nFROM cohort_sizes\nORDER BY 1, 3, 2\n\nGraphing the results for the first 20 periods, as in Figure 3.7, reveals the sparse cohorts. Alaska did not have any female legislators, while Arizona’s female retention curve disappears after year 3. Only California, a large state with many legislators, has complete retention curves for both genders. This pattern repeats for other small and large states.\n\n\n\n\n\n\n\n\nFigure 2.7: Legislator retention by gender and first state\n\n\n\n\n\nNow let’s look at how to ensure a record for every period so that the query returns zero values for retention instead of nulls. The first step is to query for all combinations of periods and cohort attributes, in this case first_state and gender, with the starting cohort_size for each combination. This can be done by JOINing CTE cohort_sizes with periods, a CTE using generate_series() to generate all integers from 0 to 20.\n\n\n\n\n\n\nCross joins\n\n\n\nIn place of JOIN ON 1 = 1 (this could be JOIN ON (TRUE)), I use CROSS JOIN.\n\n\nThis is a handy way to force a Cartesian JOIN when the two subqueries don’t have any fields in common:\n\nWITH\n\nfirst_term_states AS (\n  SELECT distinct id_bioguide,\n    min(term_start) OVER w AS first_term,\n    first_value(state) OVER w AS first_state\n  FROM legislators_terms\n  WINDOW w AS (PARTITION BY id_bioguide ORDER BY term_start)),\n  \nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31),\n\ncohorts AS (\n  SELECT gender, first_state,\n    coalesce(year(age(date, first_term)), 0) AS period,\n    count(distinct id_bioguide) AS cohort_retained\n  FROM first_term_states\n  JOIN legislators_terms\n  USING (id_bioguide)\n  LEFT JOIN year_ends \n  ON date BETWEEN term_start AND term_end\n  JOIN legislators\n  USING (id_bioguide)\n  WHERE first_term BETWEEN '1917-01-01' AND '1999-12-31'\n  GROUP BY 1, 2, 3),\n\ncohort_sizes AS (\n  SELECT DISTINCT gender, first_state,\n    first_value(cohort_retained) OVER w AS cohort_size\n  FROM cohorts\n  WINDOW w AS (PARTITION BY gender, first_state ORDER BY period)),\n\nperiods AS (\n  SELECT generate_series AS period \n  FROM generate_series(0, 20, 1)),\n\ncohort_sizes_filled AS (\n  SELECT DISTINCT gender, first_state, period, cohort_size\n  FROM cohort_sizes\n  CROSS JOIN periods)\n  \nSELECT gender, first_state, period, cohort_size,\n  coalesce(cohort_retained, 0) AS cohort_retained,\n  coalesce(cohort_retained, 0) / cohort_size AS pct_retained\nFROM cohort_sizes_filled\nLEFT JOIN cohorts\nUSING (gender, first_state, period)\nORDER BY 1, 3, 2\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\ngender\nfirst_state\nperiod\ncohort_size\ncohort_retained\npct_retained\n\n\n\n\nF\nAL\n0\n3\n3\n1\n\n\nF\nAR\n0\n5\n5\n1\n\n\nF\nAZ\n0\n2\n2\n1\n\n\nF\nCA\n0\n25\n25\n1\n\n\nF\nCO\n0\n2\n2\n1\n\n\nF\nCT\n0\n6\n6\n1\n\n\nF\nDC\n0\n1\n1\n1\n\n\nF\nFL\n0\n7\n7\n1\n\n\nF\nGA\n0\n5\n5\n1\n\n\nF\nHI\n0\n3\n3\n1\n\n\n\n\n\nThe next step is to JOIN this back to the actual periods in office, with a LEFT JOIN to ensure all the time periods remain in the final result:\nWe can then pivot the results and confirm that a value exists for each cohort for each period:\n\n\n\n\n\n\nMissing query\n\n\n\nIn the original text, the query used to generate the following is omitted.\nI create the table below by replacing the main query above with the following:\nSELECT gender, first_state,\n  max(CASE WHEN period = 0 THEN pct_retained END) as yr0,\n  max(CASE WHEN period = 2 THEN pct_retained END) as yr2,\n  max(CASE WHEN period = 4 THEN pct_retained END) as yr4,\n  max(CASE WHEN period = 6 THEN pct_retained END) as yr6,\n  max(CASE WHEN period = 8 THEN pct_retained END) as yr8,\n  max(CASE WHEN period = 10 THEN pct_retained END) as yr10\nFROM pct_retained\nWHERE first_state IN ('AL', 'AR', 'CA') AND gender IN ('F')\nGROUP BY 1, 2\nORDER BY 1, 2\n\n\n\n\n\n3 records\n\n\ngender\nfirst_state\nyr0\nyr2\nyr4\nyr6\nyr8\nyr10\n\n\n\n\nF\nAL\n1\n0.00\n0.0\n0.00\n0.00\n0.00\n\n\nF\nAR\n1\n0.80\n0.2\n0.40\n0.40\n0.40\n\n\nF\nCA\n1\n0.92\n0.8\n0.64\n0.68\n0.68\n\n\n\n\n\nNotice that at this point, the SQL code has gotten quite long. One of the harder parts of writing SQL for cohort retention analysis is keeping all of the logic straight and the code organized, a topic I’ll discuss more in Chapter 8. When building up retention code, I find it helpful to go step-by-step, checking results along the way. I also spot-check individual cohorts to validate that the final result is accurate.\n\n\n\n\n\n\nLong queries and CTEs\n\n\n\nIndeed the query is getting long. The CTE version is a little shorter because first_term_states is defined just once here, but twice in the original query (once as a and once as d). Also, because we can query any of the CTEs, it is much easier to keep the logic straight here than it is with the subqueries.\n\n\nCohorts can be defined in many ways. So far, we’ve normalized all our cohorts to the first date they appear in the time series data. This isn’t the only option, however, and interesting analysis can be done starting in the middle of an entity’s life span. Before concluding our work on retention analysis, let’s take a look at this additional way to define cohorts.\n\n\n2.3.6 Defining Cohorts from Dates Other Than the First Date\nUsually time-based cohorts are defined from the entity’s first appearance in the time series or from some other earliest date, such as a registration date. However, cohorting on a different date can be useful and insightful. For example, we might want to look at retention across all customers using a service as of a particular date. This type of analysis can be used to understand whether product or marketing changes have had a long-term impact on existing customers.\nWhen using a date other than the first date, we need to take care to precisely define the criteria for inclusion in each cohort. One option is to pick entities present on a particular calendar date. This is relatively straightforward to put into SQL code, but it can be problematic if a large share of the regular user population doesn’t show up every day, causing retention to vary depending on the exact day chosen. One option to correct for this is to calculate retention for several starting dates and then average the results.\nAnother option is to use a window of time such as a week or month. Any entity that appears in the data set during that window is included in the cohort. While this approach is often more representative of the business or process, the trade-off is that the SQL code will become more complex, and the query time may be slower due to more intense database calculations. Finding the right balance between query performance and accuracy of results is something of an art.\nLet’s take a look at how to calculate such midstream analysis with the legislators data set by considering retention for legislators who were in office in the year 2000. We’ll cohort by the term_type, which has values of “sen” for senators and “rep” for representatives. The definition will include any legislator in office at any time during the year 2000: those who started prior to 2000 and whose terms ended during or after 2000 qualify, as do those who started a term in 2000. We can hardcode any date in 2000 as the first_term, since we will later check whether they were in office at some point during 2000. The min_start of the terms falling in this window is also calculated for use in a later step:\n\nSELECT DISTINCT id_bioguide, term_type, \n  DATE '2000-01-01' AS first_term,\n  min(term_start) AS min_start\nFROM legislators_terms \nWHERE term_start &lt;= '2000-12-31' AND term_end &gt;= '2000-01-01'\nGROUP BY 1, 2, 3\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nterm_type\nfirst_term\nmin_start\n\n\n\n\nF000441\nrep\n2000-01-01\n1999-01-06\n\n\nM000355\nsen\n2000-01-01\n1997-01-07\n\n\nB000287\nrep\n2000-01-01\n1999-01-06\n\n\nI000024\nsen\n2000-01-01\n1997-01-07\n\n\nH000725\nsen\n2000-01-01\n1999-01-06\n\n\nC000846\nrep\n2000-01-01\n1999-01-06\n\n\nB000518\nrep\n2000-01-01\n1999-01-06\n\n\nC000735\nrep\n2000-01-01\n1999-01-06\n\n\nT000424\nrep\n2000-01-01\n1999-01-06\n\n\nR000486\nrep\n2000-01-01\n1999-01-06\n\n\n\n\n\nWe can then plug this into our retention code, with two adjustments. First, an additional JOIN criterion between first_terms and the legislators_terms table is added in order to return only terms that started on or after the min_start date. Second, an additional filter is added to year_ends so that it only returns dates in 2000 or later:\n\nWITH\n\nfirst_terms AS (\n  SELECT DISTINCT id_bioguide, term_type,\n    DATE '2000-01-01' AS first_term,\n    min(term_start) AS min_start\n  FROM legislators_terms \n  WHERE term_start &lt;= '2000-12-31' AND term_end &gt;= '2000-01-01'\n  GROUP BY 1, 2, 3),\n  \nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31 AND year &gt;= 2000),\n  \ncohorts AS (\n  SELECT a.term_type,\n    coalesce(year(age(date, first_term)), 0) AS period,\n    count(DISTINCT a.id_bioguide) AS cohort_retained\n  FROM first_terms a\n  JOIN legislators_terms b\n  ON a.id_bioguide = b.id_bioguide AND b.term_start &gt;= a.min_start\n  LEFT JOIN year_ends  \n  ON date BETWEEN term_start AND term_end\n  GROUP BY 1,2)\n  \nSELECT term_type, period,\n  first_value(cohort_retained) OVER w AS cohort_size,\n  cohort_retained,\n  cohort_retained / first_value(cohort_retained) OVER w AS pct_retained\nFROM cohorts\nWINDOW w AS (PARTITION BY term_type ORDER BY period) \nORDER BY 2, 1\n\nFigure 3.8 shows that despite longer terms for senators, retention among the two cohorts was similar, and was actually worse for senators after 10 years. A further analysis comparing the different years they were first elected, or other cohort attributes, might yield some interesting insights.\n\n\n\n\n\n\n\n\nFigure 2.8: Retention by term type for legislators in office during the year 2000\n\n\n\n\n\nA common use case for cohorting on a value other than a starting value is when trying to analyze retention after an entity has reached a threshold, such as a certain number of purchases or a certain amount spent. As with any cohort, it’s important to take care in defining what qualifies an entity to be in a cohort and which date will be used as the starting date.\nCohort retention is a powerful way to understand the behavior of entities in a time series data set. We’ve seen how to calculate retention with SQL and how to cohort based on the time series itself or on other tables, and from points in the middle of entity life span. We also looked at how to use functions and JOINs to adjust dates within time series and compensate for sparse cohorts. There are several types of analyses that are related to cohort retention: analysis, survivorship, returnship, and cumulative calculations, all of which build off of the SQL code that we’ve developed for retention. Let’s turn to them next.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Cohort Analysis -- CTE Version</span>"
    ]
  },
  {
    "objectID": "ctes_comments.html#related-cohort-analyses",
    "href": "ctes_comments.html#related-cohort-analyses",
    "title": "2  Cohort Analysis – CTE Version",
    "section": "2.4 Related Cohort Analyses",
    "text": "2.4 Related Cohort Analyses\nIn the last section, we learned how to write SQL for cohort retention analysis. Retention captures whether an entity was in a time series data set on a specific date or window of time. In addition to presence on a specific date, analysis is often interested in questions of how long an entity lasted, whether an entity did multiple actions, and how many of those actions occurred. These can all be answered with code that is similar to retention and is well suited to just about any cohorting criteria you like. Let’s take a look at the first of these, survivorship.\n\n2.4.1 Survivorship\nSurvivorship, also called survival analysis, is concerned with questions about how long something lasts, or the duration of time until a particular event such as churn or death. Survivorship analysis can answer questions about the share of the population that is likely to remain past a certain amount of time. Cohorts can help identify or at least provide hypotheses about which characteristics or circumstances increase or decrease the survival likelihood.\nThis is similar to a retention analysis, but instead of calculating whether an entity was present in a certain period, we calculate whether the entity is present in that period or later in the time series. Then the share of the total cohort is calculated. Typically one or more periods are chosen depending on the nature of the data set analyzed. For example, if we want to know the share of game players who survive for a week or longer, we can check for actions that occur after a week from starting and consider those players still surviving. On the other hand, if we are concerned about the number of students who are still in school after a certain number of years, we could look for the absence of a graduation event in a data set. The number of periods can be SELECTed either by calculating an average or typical life span or by choosing time periods that are meaningful to the organization or process analyzed, such as a month, year, or longer time period.\nIn this example, we’ll look at the share of legislators who survived in office for a decade or more after their first term started. Since we don’t need to know the specific dates of each term, we can start by calculating the first and last term_start dates, using min and max aggregations:\n\nSELECT id_bioguide,\n  min(term_start) AS first_term,\n  max(term_start) AS last_term\nFROM legislators_terms\nGROUP BY 1\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nfirst_term\nlast_term\n\n\n\n\nA000360\n2003-01-07\n2015-01-06\n\n\nC001035\n1997-01-07\n2015-01-06\n\n\nD000563\n1983-01-03\n2015-01-06\n\n\nS001194\n2012-12-27\n2017-01-03\n\n\nM001176\n2009-01-06\n2015-01-06\n\n\nR000122\n1991-01-03\n2015-01-06\n\n\nB001257\n2007-01-04\n2019-01-03\n\n\nC001075\n2009-01-06\n2015-01-06\n\n\nC001067\n2007-01-04\n2019-01-03\n\n\nD000598\n2001-01-03\n2019-01-03\n\n\n\n\n\nNext, we add century() to find the century of min(term_start), and we calculate the tenure as the number of years between the min and max term_starts found with the age function:\n\nSELECT id_bioguide,\n  century(min(term_start)) AS first_century,\n  min(term_start) AS first_term,\n  max(term_start) AS last_term,\n  year(age(max(term_start), min(term_start))) AS tenure\nFROM legislators_terms\nGROUP BY 1\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nfirst_century\nfirst_term\nlast_term\ntenure\n\n\n\n\nB000944\n20\n1993-01-05\n2019-01-03\n25\n\n\nC000127\n20\n1993-01-05\n2019-01-03\n25\n\n\nC001070\n21\n2007-01-04\n2019-01-03\n11\n\n\nF000469\n21\n2019-01-03\n2019-01-03\n0\n\n\nS000770\n20\n1997-01-07\n2019-01-03\n21\n\n\nB001261\n21\n2007-06-25\n2019-01-03\n11\n\n\nM001183\n21\n2010-11-15\n2019-01-03\n8\n\n\nB001230\n20\n1999-01-06\n2019-01-03\n19\n\n\nB001270\n21\n2011-01-05\n2019-01-03\n7\n\n\nB001251\n21\n2004-07-21\n2019-01-03\n14\n\n\n\n\n\nFinally, we calculate the cohort_size with a count of all the legislators, as well as calculating the number who survived for at least 10 years by using a CASE statement and count aggregation. The percent who survived is found by dividing these two values:\n\nWITH first_terms AS (\n  SELECT id_bioguide,\n    century(min(term_start)) AS first_century,\n    min(term_start) AS first_term,\n    max(term_start) AS last_term,\n    year(age(max(term_start), min(term_start))) AS tenure\n  FROM legislators_terms\n  GROUP BY 1)\n\nSELECT first_century,\n  count(DISTINCT id_bioguide) AS cohort_size,\n  count(DISTINCT CASE WHEN tenure &gt;= 10 THEN id_bioguide END) AS survived_10,\n  count(DISTINCT CASE WHEN tenure &gt;= 10 THEN id_bioguide END) / \n    count(DISTINCT id_bioguide) AS pct_survived_10\nFROM first_terms a\nGROUP BY 1\nORDER BY 1\n\n\n4 records\n\n\nfirst_century\ncohort_size\nsurvived_10\npct_survived_10\n\n\n\n\n18\n368\n83\n0.2255435\n\n\n19\n6299\n892\n0.1416098\n\n\n20\n5091\n1853\n0.3639756\n\n\n21\n760\n119\n0.1565789\n\n\n\n\n\nSince terms may or may not be consecutive, we can also calculate the share of legislators in each century who survived for five or more total terms. In the subquery, add a count to find the total number of terms per legislator. Then in the outer query, divide the number of legislators with five or more terms by the total cohort size:\n\nWITH total_terms AS (\n  SELECT id_bioguide,\n    century(min(term_start)) AS first_century,\n    count(term_start) AS total_terms,\n    FROM legislators_terms\n  GROUP BY 1)\n\nSELECT first_century,\n  count(DISTINCT id_bioguide) AS cohort_size,\n  count(DISTINCT CASE WHEN total_terms &gt;= 5 THEN id_bioguide END) AS survived_5,\n  count(DISTINCT CASE WHEN total_terms &gt;= 5 THEN id_bioguide END) / \n    count(DISTINCT id_bioguide) AS pct_survived_5_terms\nFROM total_terms\nGROUP BY 1\nORDER BY 1\n\n\n4 records\n\n\nfirst_century\ncohort_size\nsurvived_5\npct_survived_5_terms\n\n\n\n\n18\n368\n63\n0.1711957\n\n\n19\n6299\n711\n0.1128751\n\n\n20\n5091\n2153\n0.4229032\n\n\n21\n760\n205\n0.2697368\n\n\n\n\n\nTen years or five terms is somewhat arbitrary. We can also calculate the survivorship for each number of years or periods and display the results in graph or table form. Here, we calculate the survivorship for each number of terms from 1 to 20. This is accomplished through a Cartesian JOIN to a subquery that contains those integers derived by the generate_series function:\n\nWITH total_terms AS (\n  SELECT id_bioguide,\n    century(min(term_start)) AS first_century,\n    count(term_start) AS total_terms,\n  FROM legislators_terms\n  GROUP BY 1),\n\nperiods AS (\n  SELECT generate_series AS terms \n  FROM generate_series(0, 20, 1))\n  \nSELECT first_century, terms,\n  count(DISTINCT id_bioguide) AS cohort,\n  count(DISTINCT CASE WHEN total_terms &gt;= terms THEN id_bioguide \n                     END) AS cohort_survived,\n  count(DISTINCT CASE WHEN total_terms &gt;= terms THEN id_bioguide END) /\n    count(DISTINCT id_bioguide) AS pct_survived\nFROM total_terms\nCROSS JOIN periods\nGROUP BY 1, 2\nORDER BY 1, 2\n\nThe results are graphed in Figure 3.9. Survivorship was highest in the 20th century, a result that agrees with results we saw previously in which retention was also highest in the 20th century.\n\n\n\n\n\n\n\n\nFigure 2.9: Retention by term type for legislators in office during the year 2000\n\n\n\n\n\nSurvivorship is closely related to retention. While retention counts entities present in a specific number of periods from the start, survivorship considers only whether an entity was present as of a specific period or later. As a result, the code is simpler since it needs only the first and last dates in the time series, or a count of dates. Cohorting is done similar to cohorting for retention, and cohort definitions can come from within the time series or be derived from another table or subquery.\nNext we’ll consider another type of analysis that is in some ways the inverse of survivorship. Rather than calculating whether an entity is present in the data set at a certain time or later, we will calculate whether an entity returns or repeats an action at a certain period or earlier. This is called returnship or repeat purchase behavior.\n\n\n2.4.2 Returnship, or Repeat Purchase Behavior\nSurvivorship is useful for understanding how long a cohort is likely to stick around. Another useful type of cohort analysis seeks to understand whether a cohort member can be expected to return within a given window of time and the intensity of activity during that window. This is called returnship or repeat purchase behavior.\nFor example, an ecommerce site might want to know not only how many new buyers were acquired via a marketing campaign but also whether those buyers have become repeat buyers. One way to figure this out is to simply calculate total purchases per customer. However, comparing customers acquired two years ago with those acquired a month ago isn’t fair, since the former have had a much longer time in which to return. The older cohort would almost certainly appear more valuable than the newer one. Although this is true in a sense, it gives an incomplete picture of how the cohorts are likely to behave across their entire life span.\nTo make fair comparisons between cohorts with different starting dates, we need to create an analysis based on a time box, or a fixed window of time from the first date, and consider whether cohort members returned within that window. This way, every cohort has an equal amount of time under consideration, so long as we include only those cohorts for which the full window has elapsed. Returnship analysis is common for retail organizations, but it can also be applied in other domains. For example, a university might want to see how many students enrolled in a second course, or a hospital might be interested in how many patients need follow-up medical treatments after an initial incident.\nTo demonstrate returnship analysis, we can ask a new question of the legislators data set: how many legislators have more than one term type, and specifically, what share of them start as representatives and go on to become senators (some senators later become representatives, but that is much less common). Since relatively few make this transition, we’ll cohort legislators by the century in which they first became a representative.\nThe first step is to find the cohort size for each century, using the CTE and century() calculations seen previously, for only those with term_type = 'rep':\n\nWITH \nrep_first_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms\n  WHERE term_type = 'rep'\n  GROUP BY 1)\nSELECT century(first_term) AS cohort_century,\n  count(id_bioguide) AS reps\nFROM rep_first_terms\nGROUP BY 1\nORDER BY 1\n\n\n4 records\n\n\ncohort_century\nreps\n\n\n\n\n18\n299\n\n\n19\n5773\n\n\n20\n4481\n\n\n21\n683\n\n\n\n\n\nNext we’ll perform a similar calculation, with a JOIN to the legislators_terms table, to find the representatives who later became senators. This is accomplished with the clauses term_type = 'sen' and term_start &gt; first_term:\n\nWITH \nrep_first_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms\n  WHERE term_type = 'rep'\n  GROUP BY 1)\n  \nSELECT century(first_term) AS cohort_century,\n  count(DISTINCT id_bioguide) AS rep_and_sen\nFROM rep_first_terms\nJOIN legislators_terms\nUSING (id_bioguide)\nWHERE term_type = 'sen' and term_start &gt; first_term\nGROUP BY 1\nORDER BY 1\n\n\n4 records\n\n\ncohort_century\nrep_and_sen\n\n\n\n\n18\n57\n\n\n19\n329\n\n\n20\n254\n\n\n21\n25\n\n\n\n\n\nFinally, we JOIN these two subqueries together and calculate the percent of representatives who became senators. A LEFT JOIN is used; this clause is typically recommended to ensure that all cohorts are included whether or not the subsequent event happened. If there is a century in which no representatives became senators, we still want to include that century in the result set:\n\nWITH \nrep_first_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms\n  WHERE term_type = 'rep'\n  GROUP BY 1),\n  \nrep_centuries AS (\n  SELECT century(first_term) AS cohort_century,\n    count(id_bioguide) AS reps\n  FROM rep_first_terms\n  GROUP BY 1),\n    \nrep_sen_centuries AS (\n  SELECT date_part('century', first_term) AS cohort_century,\n    count(DISTINCT id_bioguide) AS rep_and_sen\n  FROM rep_first_terms\n  JOIN legislators_terms\n  USING (id_bioguide)\n  WHERE term_type = 'sen' AND term_start &gt; first_term\n  GROUP BY 1)\n  \nSELECT cohort_century, rep_and_sen / reps AS pct_rep_and_sen\nFROM rep_centuries\nLEFT JOIN rep_sen_centuries\nUSING (cohort_century)\nORDER BY 1\n\n\n4 records\n\n\ncohort_century\npct_rep_and_sen\n\n\n\n\n18\n0.1906355\n\n\n19\n0.0569894\n\n\n20\n0.0566838\n\n\n21\n0.0366032\n\n\n\n\n\nRepresentatives from the 18th century were most likely to become senators. However, we have not yet applied a time box to ensure a fair comparison. While we can safely assume that all legislators who served in the 18th and 19th centuries are no longer living, many of those who were first elected in the 20th and 21st centuries are still in the middle of their careers. Adding the filter WHERE age(term_start, first_term) &lt;= INTERVAL '10 years' to CTE rep_sen_centuries creates a time box of 10 years. Note that the window can easily be made larger or smaller by changing the constant in the interval. An additional filter applied to CTE rep_centuries, WHERE first_term &lt;= '2009-12-31', excludes those who were less than 10 years into their careers when the data set was assembled:\n\nWITH \nrep_first_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms\n  WHERE term_type = 'rep'\n  GROUP BY 1),\n  \nrep_centuries AS (\n  SELECT century(first_term) AS cohort_century,\n      count(id_bioguide) as reps\n    FROM rep_first_terms\n    WHERE first_term &lt;= '2009-12-31'\n    GROUP BY 1),\n    \nrep_sen_centuries AS (\n  SELECT century(first_term) AS cohort_century,\n    count(DISTINCT id_bioguide) AS rep_and_sen\n  FROM rep_first_terms\n  JOIN legislators_terms\n  USING (id_bioguide)\n  WHERE term_type = 'sen' \n    AND term_start &gt; first_term\n    AND age(term_start, first_term) &lt;= INTERVAL '10 years'\n  GROUP BY 1)\n\nSELECT cohort_century, \n  rep_and_sen / reps AS pct_rep_and_sen\nFROM rep_centuries\nLEFT JOIN rep_sen_centuries\nUSING (cohort_century)\nORDER BY 1\n\n\n4 records\n\n\ncohort_century\npct_rep_and_sen\n\n\n\n\n18\n0.0969900\n\n\n19\n0.0244240\n\n\n20\n0.0348137\n\n\n21\n0.0763636\n\n\n\n\n\nWith this new adjustment, the 18th century still had the highest share of representatives becoming senators within 10 years, but the 21st century has the second-highest share, and the 20th century had a higher share than the 19th.\nSince 10 years is somewhat arbitrary, we might also want to compare several time windows. One option is to run the query several times with different intervals and note the results. Another option is to calculate multiple windows in the same result set by using a set of CASE statements inside of count(DISTINCT x) aggregations to form the intervals, rather than specifying the interval in the WHERE clause:\n\nWITH \nrep_first_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms\n  WHERE term_type = 'rep'\n  GROUP BY 1),\n  \nrep_centuries AS (\n  SELECT century(first_term) AS cohort_century,\n      count(id_bioguide) AS reps\n    FROM rep_first_terms\n    WHERE first_term &lt;= '2009-12-31'\n    GROUP BY 1),\n    \nrep_sen_centuries AS (\n  SELECT century(first_term) AS cohort_century,\n    count(DISTINCT CASE WHEN age(term_start, first_term) \n                              &lt;= interval '5 years' \n                         THEN id_bioguide END) AS rep_and_sen_5_yrs,\n    count(DISTINCT CASE WHEN age(term_start, first_term) \n                              &lt;= interval '10 years' \n                         THEN id_bioguide END) AS rep_and_sen_10_yrs,\n    count(DISTINCT CASE WHEN age(term_start, first_term) \n                              &lt;= interval '15 years' \n                         THEN id_bioguide END) AS rep_and_sen_15_yrs\n  FROM rep_first_terms\n  JOIN legislators_terms\n  USING (id_bioguide)\n  WHERE term_type = 'sen' AND term_start &gt; first_term\n  GROUP BY 1)\n\nSELECT cohort_century,\n  rep_and_sen_5_yrs / reps as pct_5_yrs,\n  rep_and_sen_10_yrs / reps as pct_10_yrs,\n  rep_and_sen_15_yrs / reps as pct_15_yrs\nFROM rep_centuries\nLEFT JOIN rep_sen_centuries\nUSING (cohort_century)\nORDER BY 1\n\n\n4 records\n\n\ncohort_century\npct_5_yrs\npct_10_yrs\npct_15_yrs\n\n\n\n\n18\n0.0501672\n0.0969900\n0.1438127\n\n\n19\n0.0088342\n0.0244240\n0.0408800\n\n\n20\n0.0100424\n0.0348137\n0.0477572\n\n\n21\n0.0400000\n0.0763636\n0.0872727\n\n\n\n\n\nWith this output, we can see how the share of representatives who became senators evolved over time, both within each cohort and across cohorts. In addition to the table format, graphing the output often reveals interesting trends. In Figure 3.10, the cohorts based on century are replaced with cohorts based on the first decade, and the trends over 10 and 20 years are shown. Conversion of representatives to senators during the first few decades of the new US legislature was clearly different from patterns in the years since.\n\n\n\n\n\n\n\n\nFigure 2.10: Trend of the share of representatives for each cohort, defined by starting decade, who later became senators\n\n\n\n\n\nFinding the repeat behavior within a fixed time box is a useful tool for comparing cohorts. This is particularly true when the behaviors are intermittent in nature, such as purchase behavior or content or service consumption. In the next section, we’ll look at how to calculate not only whether an entity had a subsequent action but also how many subsequent actions they had, and we’ll aggregate them with cumulative calculations.\n\n\n2.4.3 Cumulative Calculations\nCumulative cohort analysis can be used to establish cumulative lifetime value, also called customer lifetime value (the acronyms CLTV and LTV are used interchangeably), and to monitor newer cohorts in order to be able to predict what their full LTV will be. This is possible because early behavior is often highly correlated with long-term behavior. Users of a service who return frequently in their first days or weeks of using it tend to be the most likely to stay around over the long term. Customers who buy a second or third time early on are likely to continue purchasing over a longer time period. Subscribers who renew after the first month or year are often likely to stick around over many subsequent months or years.\nIn this section, I’ll mainly talk about the revenue-generating activities of customers, but this analysis can also be applied to situations in which customers or entities incur costs, such as through product returns, support interactions, or use of health-care services.\nWith cumulative calculations, we’re less concerned about whether an entity did an action on a particular date and more about the total as of a particular date. The cumulative calculations used in this type of analysis are most often counts or sums. We will again use the time box concept to ensure apples-to-apples comparisons between cohorts. Let’s look at the number of terms started within 10 years of the first term_start, cohorting the legislators by century and type of first term:\n\nWITH first_terms AS (\n  SELECT DISTINCT id_bioguide,\n    first_value(term_type) OVER w AS first_type,\n    min(term_start) OVER w AS first_term,\n    min(term_start) OVER w + INTERVAL '10 years' AS first_plus_10\n  FROM legislators_terms\n  WINDOW w AS (PARTITION BY id_bioguide ORDER BY term_start))\n\nSELECT century(first_term) AS century,\n  first_type,\n  count(DISTINCT a.id_bioguide) AS cohort,\n  count(term_start) AS terms\nFROM first_terms a\nLEFT JOIN legislators_terms b\nON a.id_bioguide = b.id_bioguide \n  AND term_start BETWEEN first_term AND first_plus_10\nGROUP BY 1, 2\nORDER BY 1, 2\n\n\n8 records\n\n\ncentury\nfirst_type\ncohort\nterms\n\n\n\n\n18\nrep\n297\n760\n\n\n18\nsen\n71\n101\n\n\n19\nrep\n5744\n12165\n\n\n19\nsen\n555\n795\n\n\n20\nrep\n4473\n16203\n\n\n20\nsen\n618\n1008\n\n\n21\nrep\n683\n2203\n\n\n21\nsen\n77\n118\n\n\n\n\n\n\n\n\n\n\n\nInequalities and LEFT JOINs\n\n\n\nYou will notice that I used a.id_bioguide = b.id_bioguide in place of USING(id_bioguide) in the query above. This is because we have to choose between a USING join clause or an ON join clause; we can’t mix within a single join. As we want to join on term_start BETWEEN first_term AND first_plus_10, we cannot use a USING join.\nIt might be tempting to specify USING (id_bioguide) and use WHERE term_start BETWEEN first_term AND first_plus_10, but this approach will not be equivalent if we’re using a LEFT JOIN, as the WHERE will effectively make the join an INNER JOIN.\nIn this case it turns out that the LEFT JOIN is not having any effect, as can be seen from the following query using INNER JOIN, USING and WHERE:\n\nWITH first_terms AS (\n  SELECT DISTINCT id_bioguide,\n    first_value(term_type) OVER w AS first_type,\n    min(term_start) OVER w AS first_term,\n    min(term_start) OVER w + INTERVAL '10 years' AS first_plus_10\n  FROM legislators_terms\n  WINDOW w AS (PARTITION BY id_bioguide ORDER BY term_start))\n\nSELECT century(first_term) AS century,\n  first_type,\n  count(DISTINCT id_bioguide) AS cohort,\n  count(term_start) AS terms\nFROM first_terms\nINNER JOIN legislators_terms\nUSING (id_bioguide)\nWHERE term_start BETWEEN first_term AND first_plus_10\nGROUP BY 1, 2\nORDER BY 1, 2\n\n\n8 records\n\n\ncentury\nfirst_type\ncohort\nterms\n\n\n\n\n18\nrep\n297\n760\n\n\n18\nsen\n71\n101\n\n\n19\nrep\n5744\n12165\n\n\n19\nsen\n555\n795\n\n\n20\nrep\n4473\n16203\n\n\n20\nsen\n618\n1008\n\n\n21\nrep\n683\n2203\n\n\n21\nsen\n77\n118\n\n\n\n\n\n\n\nThe largest cohort is that of representatives first elected in the 19th century, but the cohort with the largest number of terms started within 10 years is that of representatives first elected in the 20th century. This type of calculation can be useful for understanding the overall contribution of a cohort to an organization.T otal sales or total repeat purchases can be valuable metrics. Usually, though, we want to normalize to understand the contribution on a per-entity basis. Calculations we might want to make include average actions per person, average order value (AOV), items per order, and orders per customer. To normalize by the cohort size, simply divide by the starting cohort, which we’ve done previously with retention, survivorship, and returnship. Here we do that and also pivot the results into table form for easier comparisons:\n\nWITH \nfirst_terms AS (\n  SELECT DISTINCT id_bioguide,\n    first_value(term_type) OVER w AS first_type,\n    min(term_start) OVER w AS first_term,\n    min(term_start) OVER w + interval '10 years' AS first_plus_10\n  FROM legislators_terms\n  WINDOW w AS (PARTITION BY id_bioguide ORDER BY term_start)),\n\ncohort_data AS (\n  SELECT century(first_term) AS century,\n      first_type,\n      count(DISTINCT a.id_bioguide) AS cohort,\n      count(term_start) AS terms,\n      count(term_start) / count(distinct a.id_bioguide) AS terms_per_leg\n    FROM first_terms a\n    LEFT JOIN legislators_terms b \n    ON a.id_bioguide = b.id_bioguide \n      AND term_start BETWEEN first_term AND first_plus_10\n    GROUP BY 1, 2)\n    \nSELECT century,\n  max(CASE WHEN first_type = 'rep' THEN cohort END) AS rep_cohort,\n  max(CASE WHEN first_type = 'rep' THEN terms_per_leg END) AS avg_rep_terms,\n  max(CASE WHEN first_type = 'sen' THEN cohort END) AS sen_cohort,\n  max(CASE WHEN first_type = 'sen' THEN terms_per_leg END) AS avg_sen_terms\nFROM cohort_data\nGROUP BY 1\nORDER BY 1\n\n\n4 records\n\n\ncentury\nrep_cohort\navg_rep_terms\nsen_cohort\navg_sen_terms\n\n\n\n\n18\n297\n2.558923\n71\n1.422535\n\n\n19\n5744\n2.117862\n555\n1.432432\n\n\n20\n4473\n3.622401\n618\n1.631068\n\n\n21\n683\n3.225476\n77\n1.532468\n\n\n\n\n\nWith the cumulative terms normalized by the cohort size, we can now confirm that representatives first elected in the 20th century had the highest average number of terms, while those who started in the 19th century had the fewest number of terms on average. Senators have fewer but longer terms than their representative peers, and again those who started in the 20th century have had the highest number of terms on average.\nCumulative calculations are often used in customer lifetime value calculations. LTV is usually calculated using monetary measures, such as total dollars spent by a customer, or the gross margin (revenue minus costs) generated by a customer across their lifetime. To facilitate comparisons between cohorts, the “lifetime” is often chosen to reflect average customer lifetime, or periods that are convenient to analyze, such as 3, 5, or 10 years. The legislators data set doesn’t contain financial metrics, but swapping in dollar values in any of the preceding SQL code would be straightforward. Fortunately, SQL is a flexible enough language that we can adapt these templates to address a wide variety of analytical questions.\nCohort analysis includes a set of techniques that can be used to answer questions related to behavior over time and how various attributes may contribute to differences between groups. Survivorship, returnship, and cumulative calculations all shed light on these questions. With a good understanding of how cohorts behave, we often have to turn our attention back to the composition or mix of cohorts over time, understanding how that can impact total retention, survivorship, returnship, or cumulative values such that these measures differ surprisingly from the individual cohorts.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Cohort Analysis -- CTE Version</span>"
    ]
  },
  {
    "objectID": "ctes_comments.html#cross-section-analysis-through-a-cohort-lens",
    "href": "ctes_comments.html#cross-section-analysis-through-a-cohort-lens",
    "title": "2  Cohort Analysis – CTE Version",
    "section": "2.5 Cross-Section Analysis, through a Cohort Lens",
    "text": "2.5 Cross-Section Analysis, through a Cohort Lens\nSo far in this chapter, we’ve been looking at cohort analysis. We’ve followed the behavior of cohorts across time with retention, survivorship, returnship, and cumulative behavior analyses. One of the challenges with these analyses, however, is that even as they make changes within cohorts easy to spot, it can be difficult to spot changes in the overall composition of a customer or user base.\nMix shifts, which are changes in the composition of the customer or user base over time, can also occur, making later cohorts different from earlier ones. Mix shifts may be due to international expansion, shifting between organic and paid acquisition strategies, or moving from a niche enthusiast audience to a broader mass market one. Creating additional cohorts, or segments, along any of these suspected lines can help diagnose whether a mix shift is happening.\nCohort analysis can be contrasted with cross-sectional analysis, which compares individuals or groups at a single point in time. Cross-sectional studies can correlate years of education with current income, for example. On the positive side, collecting data sets for cross-sectional analysis is often easier since no time series is necessary. Cross-sectional analysis can be insightful, generating hypotheses for further investigation. On the negative side, a form of selection bias called survivorship bias usually exists, which can lead to false conclusions.\n\n\n\n\n\n\nSurvivorship bias\n\n\n\nThe note on survivorship bias in the original text is problematic because the second and third paragraphs do not provide examples that clearly illustrate the phenomenon of survivorship bias.\nThe paragraph on college dropouts probably illustrates a mix of availability bias and the base rate fallacy. it is easy to recall examples of people who have dropped out of college before going onto successful careers in business. Classic examples include Bill Gates, Steve Jobs, and Mark Zuckerberg. I suspect that it is much easier to recall examples of successful dropouts because it’s a more salient fact for those cases. If Mark Zuckerberg had completed his undergraduate studies at Harvard, it would hardly merit a mention in any story about him; that he dropped out is an interesting fact.\nThe third paragraph is more clearly an illustration of the base rate fallacy. If we compare the proportion of best customers who live in California or Texas and are 18 to 30 years old with the number of people in the population who live in California or Texas and are 18 to 30 years old, we can adjust for the underlying base rate problem. Of course, it the people entering into the customer pool do not reflect the underlying populations, then only correcting for this base rate issue would not produce valid survival rates. In this case, we could characterize the issue as a survivorship bias that could be addressed by a proper cohort analysis.\n\n\n\n\n\n\n\n\nSurvivorship bias\n\n\n\n“Let’s look at our best customers and see what they have in common.” This seemingly innocent and well-intentioned idea can lead to some very problematic conclusions. Survivorship bias is the logical error of focusing on the people or things that made it past some selection process, while ignoring those that did not. Commonly this is because the entities no longer exist in the data set at the time of selection, because they have failed, churned, or left the population for some other reason. Concentrating only on the remaining population can lead to overly optimistic conclusions, because failures are ignored.\nMuch has been written about a few people who dropped out of college and started wildly successful technology companies. This doesn’t mean you should immediately leave college, since the vast majority of people who drop out do not go on to be successful CEOs. That part of the population doesn’t make for nearly as sensational headlines, so it’s easy to forget about that reality.\nIn the successful customer context, survivorship bias might show up as an observation that the best customers tend to live in California or Texas and tend to be 18 to 30 years old. This is a large population to start with, and it may turn out that these characteristics are shared by many customers who churned prior to the analysis date. Going back to the original population might reveal that other demographics, such as 41-to-50-year-olds in Vermont, actually stick around and spend more over time, even though there are fewer of them in absolute terms. Cohort analysis helps distinguish and reduce survivorship bias.\n\n\nCohort analysis is a way to overcome survivorship bias by including all members of a starting cohort in the analysis. We can take a series of cross sections from a cohort analysis to understand how the mix of entities may have changed over time. On any given date, users from a variety of cohorts are present. We can use cross-sectional analysis to examine them, like layers of sediment, to reveal new insights. In the next example, we’ll create a time series of the share of legislators from each cohort for each year in the data set.\nThe first step is to find the number of legislators in office each year by JOINing the legislators table to the date_dim, WHERE the date from the date_dim is between the start and end dates of each term. Here we use December 31 for each year to find the legislators in office at each year’s end:\n\nWITH \nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31 AND year &lt;= 2019)\n\nSELECT date, count(DISTINCT id_bioguide) AS legislators\nFROM legislators_terms\nJOIN year_ends\nON date BETWEEN term_start AND term_end\nGROUP BY 1\nORDER BY 1\n\n\nDisplaying records 1 - 10\n\n\ndate\nlegislators\n\n\n\n\n1789-12-31\n89\n\n\n1790-12-31\n95\n\n\n1791-12-31\n99\n\n\n1792-12-31\n101\n\n\n1793-12-31\n141\n\n\n1794-12-31\n140\n\n\n1795-12-31\n145\n\n\n1796-12-31\n150\n\n\n1797-12-31\n152\n\n\n1798-12-31\n155\n\n\n\n\n\nNext, we add in the century cohorting criterion by JOINing to first_terms:\n\nWITH \nfirst_terms AS (\n   SELECT id_bioguide, min(term_start) as first_term\n    FROM legislators_terms\n    GROUP BY 1),\n\nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31 AND year &lt;= 2019),\n    \ncohorts AS (\n  SELECT date,\n    century(first_term) AS century,\n    count(DISTINCT id_bioguide) AS legislators\n  FROM legislators_terms\n  JOIN year_ends\n  ON date BETWEEN term_start AND term_end\n  JOIN first_terms\n  USING (id_bioguide)\n  GROUP BY 1, 2)\n  \nSELECT *\nFROM cohorts\nORDER BY 1\n\n\nDisplaying records 1 - 10\n\n\ndate\ncentury\nlegislators\n\n\n\n\n1789-12-31\n18\n89\n\n\n1790-12-31\n18\n95\n\n\n1791-12-31\n18\n99\n\n\n1792-12-31\n18\n101\n\n\n1793-12-31\n18\n141\n\n\n1794-12-31\n18\n140\n\n\n1795-12-31\n18\n145\n\n\n1796-12-31\n18\n150\n\n\n1797-12-31\n18\n152\n\n\n1798-12-31\n18\n155\n\n\n\n\n\nFinally, we calculate the percent of total legislators in each year that the century cohort represents. This can be done in a couple of ways, depending on the shape of output desired. The first way is to keep a row for each date and century combination and use a sum window function in the denominator of the percentage calculation:\n\nWITH \nfirst_terms AS (\n   SELECT id_bioguide, min(term_start) as first_term\n    FROM legislators_terms\n    GROUP BY 1),\n\nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31 AND year &lt;= 2019),\n    \ncohorts AS (\n  SELECT date,\n    century(first_term) AS century,\n    count(DISTINCT id_bioguide) AS legislators\n  FROM legislators_terms\n  JOIN year_ends\n  ON date BETWEEN term_start AND term_end\n  JOIN first_terms\n  USING (id_bioguide)\n  GROUP BY 1, 2)\n  \nSELECT date, century,\n  legislators,\n  sum(legislators) OVER w AS cohort,\n  legislators / sum(legislators) OVER w AS pct_century\nFROM cohorts\nWINDOW w AS (PARTITION BY date)\nORDER BY 1 DESC\n\n\nDisplaying records 1 - 10\n\n\ndate\ncentury\nlegislators\ncohort\npct_century\n\n\n\n\n2019-12-31\n21\n440\n537\n0.8193669\n\n\n2019-12-31\n20\n97\n537\n0.1806331\n\n\n2018-12-31\n21\n417\n539\n0.7736549\n\n\n2018-12-31\n20\n122\n539\n0.2263451\n\n\n2017-12-31\n21\n414\n538\n0.7695167\n\n\n2017-12-31\n20\n124\n538\n0.2304833\n\n\n2016-12-31\n20\n142\n540\n0.2629630\n\n\n2016-12-31\n21\n398\n540\n0.7370370\n\n\n2015-12-31\n21\n396\n540\n0.7333333\n\n\n2015-12-31\n20\n144\n540\n0.2666667\n\n\n\n\n\nThe second approach results in one row per year, with a column for each century, a table format that may be easier to scan for trends:\n\nWITH \nfirst_terms AS (\n   SELECT id_bioguide, min(term_start) as first_term\n    FROM legislators_terms\n    GROUP BY 1),\n\nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31 AND year &lt;= 2019),\n    \ncohorts AS (\n  SELECT date,\n    century(first_term) AS century,\n    count(DISTINCT id_bioguide) AS legislators\n  FROM legislators_terms\n  JOIN year_ends\n  ON date BETWEEN term_start AND term_end\n  JOIN first_terms\n  USING (id_bioguide)\n  GROUP BY 1, 2)\n\nSELECT date,\n  coalesce(sum(CASE WHEN century = 18 THEN legislators END)\n          / sum(legislators), 0) as pct_18,\n  coalesce(sum(CASE WHEN century = 19 THEN legislators END)\n          / sum(legislators), 0) as pct_19,\n  coalesce(sum(CASE WHEN century = 20 THEN legislators END)\n          / sum(legislators), 0) as pct_20,\n  coalesce(sum(CASE WHEN century = 21 THEN legislators END)\n          / sum(legislators), 0) as pct_21\nFROM cohorts\nGROUP BY 1\nORDER BY 1 DESC\n\n\n\n\n\n\n\n\n\nFigure 2.11: Percent of legislators each year, by century first elected\n\n\n\n\n\nWe can graph the output, as in Figure 3.11, to see how newer cohorts of legislators gradually overtake older cohorts, until they themselves are replaced by new cohorts.\nRather than cohorting on first_term, we can cohort on tenure instead. Finding the share of customers who are relatively new, are of medium tenure, or are long-term customers at various points in time can be insightful. Let’s take a look at how the tenure of legislators in Congress has changed over time.\nThe first step is to calculate, for each year, the cumulative number of years in office for each legislator. Since there can be gaps between terms when legislators are voted out or leave office for other reasons, we’ll first find each year in which the legislator was in office at the end of the year in cohort_data. Then we’ll use a count window function, with the window covering the rows unbounded preceding, or all prior rows for that legislator, and CURRENT ROW:\n\nWITH \n\nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31 AND year &lt;= 2019),\n  \ncohort_data AS (\n  SELECT DISTINCT id_bioguide, date\n  FROM legislators_terms\n  JOIN year_ends\n  ON date BETWEEN term_start AND term_end),\n\ncohorts AS (\n  SELECT id_bioguide, date, count(date) OVER w AS cume_years\n  FROM cohort_data\n  WINDOW w AS (PARTITION BY id_bioguide \n               ORDER BY date\n               ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW))\nSELECT *\nFROM cohorts\nORDER BY 1, 2 DESC\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\ndate\ncume_years\n\n\n\n\nA000001\n1952-12-31\n2\n\n\nA000001\n1951-12-31\n1\n\n\nA000002\n1972-12-31\n26\n\n\nA000002\n1971-12-31\n25\n\n\nA000002\n1970-12-31\n24\n\n\nA000002\n1969-12-31\n23\n\n\nA000002\n1968-12-31\n22\n\n\nA000002\n1967-12-31\n21\n\n\nA000002\n1966-12-31\n20\n\n\nA000002\n1965-12-31\n19\n\n\n\n\n\nNext, count the number of legislators for each combination of date and cume_years to create a distribution:\n\nWITH \n\nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31 AND year &lt;= 2019),\n  \ncohort_data AS (\n  SELECT DISTINCT id_bioguide, date\n  FROM legislators_terms\n  JOIN year_ends\n  ON date BETWEEN term_start AND term_end),\n\ncohorts AS (\n  SELECT id_bioguide, date, count(date) OVER w AS cume_years\n  FROM cohort_data\n  WINDOW w AS (PARTITION BY id_bioguide \n               ORDER BY date\n               ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW))\n\nSELECT date, cume_years,\n  count(DISTINCT id_bioguide) AS legislators\nFROM cohorts\nGROUP BY 1, 2\nORDER BY 1\n\n\nDisplaying records 1 - 10\n\n\ndate\ncume_years\nlegislators\n\n\n\n\n1789-12-31\n1\n89\n\n\n1790-12-31\n1\n6\n\n\n1790-12-31\n2\n89\n\n\n1791-12-31\n1\n37\n\n\n1791-12-31\n3\n57\n\n\n1791-12-31\n2\n5\n\n\n1792-12-31\n1\n3\n\n\n1792-12-31\n2\n37\n\n\n1792-12-31\n4\n56\n\n\n1792-12-31\n3\n5\n\n\n\n\n\nBefore calculating the percentage for each tenure per year and adjusting the presentation format, we might want to consider grouping the tenures. A quick profiling of our results so far reveals that in some years, almost 40 different tenures are represented. This will likely be difficult to visualize and interpret:\n\nWITH \n\nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31 AND year &lt;= 2019),\n  \ncohort_data AS (\n  SELECT DISTINCT id_bioguide, date\n  FROM legislators_terms\n  JOIN year_ends\n  ON date BETWEEN term_start AND term_end),\n\ncohorts AS (\n  SELECT id_bioguide, date, count(date) OVER w AS cume_years\n  FROM cohort_data\n  WINDOW w AS (PARTITION BY id_bioguide \n               ORDER BY date\n               ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)),\n               \ncohort_stats AS (\n  SELECT date, cume_years, count(DISTINCT id_bioguide) AS legislators\n  FROM cohorts\n  GROUP BY 1, 2)            \n\nSELECT date, count(*) AS tenures\nFROM cohort_stats\nGROUP BY 1\nORDER BY 1 DESC\n\n\nDisplaying records 1 - 10\n\n\ndate\ntenures\n\n\n\n\n2019-12-31\n35\n\n\n2018-12-31\n36\n\n\n2017-12-31\n35\n\n\n2016-12-31\n36\n\n\n2015-12-31\n35\n\n\n2014-12-31\n35\n\n\n2013-12-31\n35\n\n\n2012-12-31\n36\n\n\n2011-12-31\n36\n\n\n2010-12-31\n36\n\n\n\n\n\nAs a result, we may want to group the values. There is no single right way to group tenures. If there are organizational definitions of tenure groups, go ahead and use them. Otherwise, I usually try to break them up into three to five groups of roughly equal size. Here we’ll group the tenures into four cohorts, where cume_years is less than or equal to 4 years, between 5 and 10 years, between 11 and 20 years, and equal to or more than 21 years:\n\nWITH \n\nyear_ends AS (\n  SELECT *  \n  FROM date_dim\n  WHERE month_name = 'December' AND day_of_month = 31 AND year &lt;= 2019),\n  \ncohort_data AS (\n  SELECT DISTINCT id_bioguide, date\n  FROM legislators_terms\n  JOIN year_ends\n  ON date BETWEEN term_start AND term_end),\n\ncohorts AS (\n  SELECT id_bioguide, date, count(date) OVER w AS cume_years\n  FROM cohort_data\n  WINDOW w AS (PARTITION BY id_bioguide \n               ORDER BY date\n               ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)),\n               \ncohort_stats AS (\n  SELECT date,\n    CASE WHEN cume_years &lt;= 4 THEN '1 to 4'\n         WHEN cume_years &lt;= 10 THEN '5 to 10'\n         WHEN cume_years &lt;= 20 THEN '11 to 20'\n         ELSE '21+' END AS tenure,\n    count(DISTINCT id_bioguide) AS legislators\n  FROM cohorts\n  GROUP BY 1, 2) \n  \nSELECT date, tenure,\n  legislators / sum(legislators) OVER w AS pct_legislators \nFROM cohort_stats\nWINDOW w AS (PARTITION BY date) \nORDER BY 1 DESC, 2\n\nThe graphing of the results in Figure 4-14 shows that in the early years of the country, most legislators had very little tenure. In more recent years, the share of legislators with 21 or more years in office has been increasing. There are also interesting periodic increases in 1-to-4-year-tenure legislators that may reflect shifts in political trends.\n\n\n\n\n\n\n\n\nFigure 2.12: Percent of legislators by number of years in office\n\n\n\n\n\nA cross section of a population at any point in time is made up of members from multiple cohorts. Creating a time series of these cross sections is another interesting way of analyzing trends. Combining this with insights from retention can provide a more robust picture of trends in any organization.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Cohort Analysis -- CTE Version</span>"
    ]
  },
  {
    "objectID": "ctes_comments.html#conclusion",
    "href": "ctes_comments.html#conclusion",
    "title": "2  Cohort Analysis – CTE Version",
    "section": "2.6 Conclusion",
    "text": "2.6 Conclusion\nCohort analysis is a useful way to investigate how groups change over time, whether it be from the perspective of retention, repeat behavior, or cumulative actions. Cohort analysis is retrospective, looking back at populations using intrinsic attributes or attributes derived from behavior. Interesting and hopefully useful correlations can be found through this type of analysis. However, as the saying goes, correlation does not imply causation. To determine actual causality, randomized experiments are the gold standard. Chapter 7 will go into depth on experiment analysis.\nBefore we turn to experimentation, however, we have a few other types of analysis to cover. Next we’ll cover text analysis: components of text analysis often show up in other analyses, and it’s an interesting facet of analysis in itself.\n\n\n\n\nTanimura, C. 2021. SQL for Data Analysis. O’Reilly Media. https://books.google.com.au/books?id=ojhCEAAAQBAJ.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Cohort Analysis -- CTE Version</span>"
    ]
  },
  {
    "objectID": "dbplyr.html",
    "href": "dbplyr.html",
    "title": "3  Cohort Analysis – dbplyr version",
    "section": "",
    "text": "3.1 Cohorts: A Useful Analysis Framework\nBefore we get into the code, I will define what cohorts are, consider the types of questions we can answer with this type of analysis, and describe the components of any cohort analysis.\nA cohort is a group of individuals who share some characteristic of interest, described below, at the time we start observing them. Cohort members are often people but can be any type of entity we want to study: companies, products, or physical world phenomena. Individuals in a cohort may be aware of their membership, just as children in a first-grade class are aware they are part of a peer group of first graders, or participants in a drug trial are aware they are part of a group receiving a treatment. At other times, entities are grouped into cohorts virtually, as when a software company groups all customers acquired in a certain year to study how long they remain customers. It’s always important to consider the ethical implications of cohorting entities without their awareness, if any different treatment is to be applied to them.\nCohort analysis is a useful way to compare groups of entities over time. Many important behaviors take weeks, months, or years to occur or evolve, and cohort analysis is a way to understand these changes. Cohort analysis provides a framework for detecting correlations between cohort characteristics and these long-term trends, which can lead to hypotheses about the causal drivers. For example, customers acquired through a marketing campaign may have different long-term purchase patterns than those who were persuaded by a friend to try a company’s products. Cohort analysis can be used to monitor new cohorts of users or customers and assess how they compare to previous cohorts. Such monitoring can provide an early alert signal that something has gone wrong (or right) for new customers. Cohort analysis is also used to mine historical data. A/B tests, discussed in Chapter 7, are the gold standard for determining causality, but we can’t go back in time and run every test for every question about the past in which we are interested. We should of course be cautious about attaching causal meaning to cohort analysis and instead use cohort analysis as a way to understand customers and generate hypotheses that can be tested rigorously in the future.\nCohort analyses have three components: the cohort grouping, a time series of data over which the cohort is observed, and an aggregate metric that measures an action done by cohort members.\nCohort grouping is often based on a start date: the customer’s first purchase or subscription date, the date a student started school, and so on. However, cohorts can also be formed around other characteristics that are either innate or changing over time. Innate qualities include birth year and country of origin, or the year a company was founded. Characteristics that can change over time include city of residence and marital status. When these are used, we need to be careful to cohort only on the value on the starting date, or else entities can jump between cohort groups.\nThe second component of any cohort analysis is the time series. This is a series of purchases, logins, interactions, or other actions that are taken by the customers or entities to be cohorted. It’s important that the time series covers the entire life span of the entities, or there will be survivorship bias in early cohorts. Survivorship bias occurs when only customers who have stayed are in the data set; churned customers are excluded because they are no longer around, so the rest of the customers appear to be of higher quality or fit in comparison to newer cohorts (see “Survivorship Bias”). It’s also important to have a time series that is long enough for the entities to complete the action of interest. For example, if customers tend to purchase once a month, a time series of several months is needed. If, on the other hand, purchases happen only once a year, a time series of several years would be preferable. Inevitably, more recently acquired customers will not have had as long to complete actions as those customers who were acquired further in the past. In order to normalize, cohort analysis usually measures the number of periods that have elapsed from a starting date, rather than calendar months. In this way, cohorts can be compared in period 1, period 2, and so on to see how they evolve over time, regardless of which month the action actually occurred. The intervals may be days, weeks, months, or years.\nThe aggregate metric should be related to the actions that matter to the health of the organization, such as customers continuing to use or purchase the product. Metric values are aggregated across the cohort, usually with sum, count, or average, though any relevant aggregation works. The result is a time series that can then be used to understand changes in behavior over time.\nIn this chapter, I’ll cover four types of cohort analysis: retention, survivorship, returnship or repeat purchase behavior, and cumulative behavior.\nThe four types of cohort analysis allow us to compare subgroups and understand how they differ over time in order to make better product, marketing, and financial decisions. The calculations for the different types are similar, so we will set the stage with retention, and then I’ll show how to modify retention code to calculate the other types. Before we dive into constructing our cohort analysis, let’s take a look at the data set we’ll be using for the examples in this chapter.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Cohort Analysis -- `dbplyr` version</span>"
    ]
  },
  {
    "objectID": "dbplyr.html#cohorts-a-useful-analysis-framework",
    "href": "dbplyr.html#cohorts-a-useful-analysis-framework",
    "title": "3  Cohort Analysis – dbplyr version",
    "section": "",
    "text": "Cohort or Segment?\n\n\n\nThese two terms are often used in similar ways, or even interchangeably, but it’s worth drawing a distinction between them for the sake of clarity. A cohort is a group of users (or other entities) who have a common starting date and are followed over time. A segment is a grouping of users who share a common characteristic or set of characteristics at a point in time, regardless of their starting date. Similar to cohorts, segments can be based on innate factors such as age or on behavioral characteristics. A segment of users that signs up in the same month can be put into a cohort and followed over time. Or different groupings of users can be explored with cohort analysis so that you can see which ones have the most valuable characteristics. The analyses we’ll cover in this chapter, such as retention, can help put concrete data behind marketing segments.\n\n\n\n\n\n\nRetention\n\nRetention is concerned with whether the cohort member has a record in the time series on a particular date, expressed as a number of periods from the starting date. This is useful in any kind of organization in which repeated actions are expected, from playing an online game to using a product or renewing a subscription, and it helps to answer questions about how sticky or engaging a product is and how many entities can be expected to appear on future dates.\n\nSurvivorship\n\nSurvivorship is concerned with how many entities remained in the data set for a certain length of time or longer, regardless of the number or frequency of actions up to that time. Survivorship is useful for answering questions about the proportion of the population that can be expected to remain—either in a positive sense by not churning or passing away, or in a negative sense by not graduating or fulfilling some requirement.\n\nReturnship\n\nReturnship or repeat purchase behavior is concerned with whether an action has happened more than some minimum threshold of times—often simply more than once—during a fixed window of time. This type of analysis is useful in situations in which the behavior is intermittent and unpredictable, such as in retail, where it characterizes the share of repeat purchasers in each cohort within a fixed time window.\n\nCumulative\n\nCumulative calculations are concerned with the total number or amounts measured at one or more fixed time windows, regardless of when they happened during that window. Cumulative calculations are often used in calculations of customer lifetime value (LTV or CLTV).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Cohort Analysis -- `dbplyr` version</span>"
    ]
  },
  {
    "objectID": "dbplyr.html#the-legislators-data-set",
    "href": "dbplyr.html#the-legislators-data-set",
    "title": "3  Cohort Analysis – dbplyr version",
    "section": "3.2 The Legislators Data Set",
    "text": "3.2 The Legislators Data Set\n\nlibrary(DBI)\nlibrary(tidyverse)\nlibrary(dbplyr)\nlibrary(ggplot2)\nlibrary(knitr)\n\n\ndb &lt;- dbConnect(duckdb::duckdb())\n\n\n\n\n\n\n\nLoading parquet files\n\n\n\nThe small function load_parquet() loads data from a parquet file into DuckDB. A similar function was used (behind the scenes) in Chapter 1 and Chapter 2.\n\n\n\nload_parquet &lt;- function (conn, table, data_dir = \"data\") {\n    file_path &lt;- file.path(data_dir, paste0(table, \".parquet\"))\n    df_sql &lt;- paste0(\"SELECT * FROM read_parquet('\", file_path, \"')\")\n    dplyr::tbl(conn, dplyr::sql(df_sql)) \n}\n\n\nlegislators_terms &lt;- load_parquet(db, \"legislators_terms\")\nlegislators &lt;- load_parquet(db, \"legislators\")\n\nThe SQL examples in this chapter will use a data set of past and present members of the United States Congress maintained in a GitHub repository. In the US, Congress is responsible for writing laws or legislation, so its members are also known as legislators. Since the data set is a JSON file, I have applied some transformations to produce a more suitable data model for analysis, and I have posted data in a format suitable for following along with the examples in the book’s GitHub legislators folder.\nThe source repository has an excellent data dictionary, so I won’t repeat all the details here. I will provide a few details, however, that should help those who aren’t familiar with the US government to follow along with the analyses in this chapter.\nCongress has two chambers, the Senate (“sen” in the data set) and the House of Representatives (“rep”). Each state has two senators, and they are elected for six-year terms. Representatives are allocated to states based on population; each representative has a district that they alone represent. Representatives are elected for two-year terms. Actual terms in either chamber can be shorter in the event that the legislator dies or is elected or appointed to a higher office. Legislators accumulate power and influence via leadership positions the longer they are in office, and thus standing for re-election is common. Finally, a legislator may belong to a political party, or they may be an “independent”. In the modern era, the vast majority of legislators are Democrats or Republicans, and the rivalry between the two parties is well known. Legislators occasionally change parties while in office.\nFor the analyses, we’ll make use of two tables: legislators and legislators_terms. The legislators table contains a list of all the people included in the data set, with birthday, gender, and a set of ID fields that can be used to look up the person in other data sets. The legislators_terms table contains a record for each term in office for each legislator, with start and end date, and other attributes such as chamber and id_bioguide field is used as the unique identifier of a legislator and appears in each table. Table 3.1 shows a sample of the legislators data. Table 3.2 shows a sample of the legislators_terms data.\n\n\n\n\nTable 3.1: Sample of the legislators table\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                full_name\n                first_name\n                last_name\n                birthday\n                gender\n                id_bioguide\n                id_govtrack\n              \n        \n        \n        \n                \n                  Sherrod Brown        \n                  Sherrod \n                  Brown     \n                  1952-11-09\n                  M\n                  B000944\n                  400050\n                \n                \n                  Maria Cantwell       \n                  Maria   \n                  Cantwell  \n                  1958-10-13\n                  F\n                  C000127\n                  300018\n                \n                \n                  Benjamin L. Cardin   \n                  Benjamin\n                  Cardin    \n                  1943-10-05\n                  M\n                  C000141\n                  400064\n                \n                \n                  Thomas R. Carper     \n                  Thomas  \n                  Carper    \n                  1947-01-23\n                  M\n                  C000174\n                  300019\n                \n                \n                  Robert P. Casey, Jr. \n                  Robert  \n                  Casey     \n                  1960-04-13\n                  M\n                  C001070\n                  412246\n                \n                \n                  Dianne Feinstein     \n                  Dianne  \n                  Feinstein \n                  1933-06-22\n                  F\n                  F000062\n                  300043\n                \n                \n                  Russ Fulcher         \n                  Russ    \n                  Fulcher   \n                  1973-07-19\n                  M\n                  F000469\n                  412773\n                \n                \n                  Amy Klobuchar        \n                  Amy     \n                  Klobuchar \n                  1960-05-25\n                  F\n                  K000367\n                  412242\n                \n                \n                  Robert Menendez      \n                  Robert  \n                  Menendez  \n                  1954-01-01\n                  M\n                  M000639\n                  400272\n                \n                \n                  Bernard Sanders      \n                  Bernard \n                  Sanders   \n                  1941-09-08\n                  M\n                  S000033\n                  400357\n                \n                \n                  Debbie Stabenow      \n                  Debbie  \n                  Stabenow  \n                  1950-04-29\n                  F\n                  S000770\n                  300093\n                \n                \n                  Jon Tester           \n                  Jon     \n                  Tester    \n                  1956-08-21\n                  M\n                  T000464\n                  412244\n                \n                \n                  Sheldon Whitehouse   \n                  Sheldon \n                  Whitehouse\n                  1955-10-20\n                  M\n                  W000802\n                  412247\n                \n                \n                  Nanette Diaz Barragán\n                  Nanette \n                  Barragán  \n                  1976-09-15\n                  F\n                  B001300\n                  412687\n                \n                \n                  John Barrasso        \n                  John    \n                  Barrasso  \n                  1952-07-21\n                  M\n                  B001261\n                  412251\n                \n                \n                  Roger F. Wicker      \n                  Roger   \n                  Wicker    \n                  1951-07-05\n                  M\n                  W000437\n                  400432\n                \n                \n                  Lamar Alexander      \n                  Lamar   \n                  Alexander \n                  1940-07-03\n                  M\n                  A000360\n                  300002\n                \n                \n                  Susan M. Collins     \n                  Susan   \n                  Collins   \n                  1952-12-07\n                  F\n                  C001035\n                  300025\n                \n                \n                  John Cornyn          \n                  John    \n                  Cornyn    \n                  1952-02-02\n                  M\n                  C001056\n                  300027\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n\n\nTable 3.2: Sample of the legislators_terms table\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                id_bioguide\n                term_id\n                term_type\n                term_start\n                term_end\n                state\n                district\n                party\n              \n        \n        \n        \n                \n                  B000944\n                  B000944-0\n                  rep\n                  1993-01-05\n                  1995-01-03\n                  OH\n                  13\n                  Democrat   \n                \n                \n                  C000127\n                  C000127-0\n                  rep\n                  1993-01-05\n                  1995-01-03\n                  WA\n                   1\n                  Democrat   \n                \n                \n                  C000141\n                  C000141-0\n                  rep\n                  1987-01-06\n                  1989-01-03\n                  MD\n                   3\n                  Democrat   \n                \n                \n                  C000174\n                  C000174-0\n                  rep\n                  1983-01-03\n                  1985-01-03\n                  DE\n                   0\n                  Democrat   \n                \n                \n                  C001070\n                  C001070-0\n                  sen\n                  2007-01-04\n                  2013-01-03\n                  PA\n                  NA\n                  Democrat   \n                \n                \n                  F000062\n                  F000062-0\n                  sen\n                  1992-11-10\n                  1995-01-03\n                  CA\n                  NA\n                  Democrat   \n                \n                \n                  F000469\n                  F000469-0\n                  rep\n                  2019-01-03\n                  2021-01-03\n                  ID\n                   1\n                  Republican \n                \n                \n                  K000367\n                  K000367-0\n                  sen\n                  2007-01-04\n                  2013-01-03\n                  MN\n                  NA\n                  Democrat   \n                \n                \n                  M000639\n                  M000639-0\n                  rep\n                  1993-01-05\n                  1995-01-03\n                  NJ\n                  13\n                  Democrat   \n                \n                \n                  S000033\n                  S000033-0\n                  rep\n                  1991-01-03\n                  1993-01-03\n                  VT\n                   0\n                  Independent\n                \n                \n                  S000770\n                  S000770-0\n                  rep\n                  1997-01-07\n                  1999-01-03\n                  MI\n                   8\n                  Democrat   \n                \n                \n                  T000464\n                  T000464-0\n                  sen\n                  2007-01-04\n                  2013-01-03\n                  MT\n                  NA\n                  Democrat   \n                \n                \n                  W000802\n                  W000802-0\n                  sen\n                  2007-01-04\n                  2013-01-03\n                  RI\n                  NA\n                  Democrat   \n                \n                \n                  B001300\n                  B001300-0\n                  rep\n                  2017-01-03\n                  2019-01-03\n                  CA\n                  44\n                  Democrat   \n                \n                \n                  B001261\n                  B001261-0\n                  sen\n                  2007-06-25\n                  2013-01-03\n                  WY\n                  NA\n                  Republican \n                \n                \n                  W000437\n                  W000437-0\n                  rep\n                  1995-01-04\n                  1997-01-03\n                  MS\n                   1\n                  Republican \n                \n                \n                  A000360\n                  A000360-0\n                  sen\n                  2003-01-07\n                  2009-01-03\n                  TN\n                  NA\n                  Republican \n                \n                \n                  C001035\n                  C001035-0\n                  sen\n                  1997-01-07\n                  2003-01-03\n                  ME\n                  NA\n                  Republican \n                \n                \n                  C001056\n                  C001056-0\n                  sen\n                  2002-11-30\n                  2003-01-03\n                  TX\n                  NA\n                  Republican \n                \n        \n      \n    \n\n\n\n\n\n\nNow that we have an understanding of what cohort analysis is and of the data set we’ll be using for examples, let’s get into how to write SQL for retention analysis. The key question SQL will help us answer is: once representatives take office, how long do they keep their jobs?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Cohort Analysis -- `dbplyr` version</span>"
    ]
  },
  {
    "objectID": "dbplyr.html#retention",
    "href": "dbplyr.html#retention",
    "title": "3  Cohort Analysis – dbplyr version",
    "section": "3.3 Retention",
    "text": "3.3 Retention\nOne of the most common types of cohort analysis is retention analysis. To retain is to keep or continue something. Many skills need to be practiced to be retained. Businesses usually want their customers to keep purchasing their products or using their services, since retaining customers is more profitable than acquiring new ones. Employers want to retain their employees, because recruiting replacements is expensive and time consuming. Elected officials seek reelection in order to continue working on the priorities of their constituents.\nThe main question in retention analysis is whether the starting size of the cohort—number of subscribers or employees, amount spent, or another key metric—will remain constant, decay, or increase over time. When there is an increase or a decrease, the amount and speed of change are also interesting questions. In most retention analyses, the starting size will tend to decay over time, since a cohort can lose but cannot gain new members once it is formed. Revenue is an interesting exception, since a cohort of customers can spend more in subsequent months than they did in the first month collectively, even if some of them churn.\nRetention analysis uses the count of entities or sum of money or actions present in the data set for each period from the starting date, and it normalizes by dividing this number by the count or sum of entities, money, or actions in the first time period. The result is expressed as a percentage, and retention in the starting period is always 100%. Over time, retention based on counts generally declines and can never exceed 100%, whereas money- or action-based retention, while often declining, can increase and be greater than 100% in a time period. Retention analysis output is typically displayed in either table or graph form, which is referred to as a retention curve. We’ll see a number of examples of retention curves later in this chapter.\nGraphs of retention curves can be used to compare cohorts. The first characteristic to pay attention to is the shape of the curve in the initial few periods, where there is often an initial steep drop. For many consumer apps, losing half a cohort in the first few months is common. A cohort with a curve that is either more or less steep than others can indicate changes in the product or customer acquisition source that merit further investigation. A second characteristic to look for is whether the curve flattens after some number of periods or continues declining rapidly to zero. A flattening curve indicates that there is a point in time from which most of the cohort that remains stays indefinitely. A retention curve that inflects upward, sometimes called a smile curve, can occur if cohort members return or reactivate after falling out of the data set for some period. Finally, retention curves that measure subscription revenue are monitored for signs of increasing revenue per customer over time, a sign of a healthy SaaS software business.\nThis section will show how to create a retention analysis, add cohort groupings from the time series itself and other tables, and handle missing and sparse data that can occur in time series data. With this framework in hand, you’ll learn in the subsequent section how to make modifications to create the other related types of cohort analysis. As a result, this section on retention will be the longest one in the chapter, as you build up code and develop your intuition about the calculations.\n\n3.3.1 SQL for a Basic Retention Curve\n\n\n\n\n\n\nConverting code to dbplyr\n\n\n\nIt is generally straightforward to convert SQL code to equivalent dbplyr code. Note that dbplyr code generally looks quite similar to dplyr code, so we will occasion refer to dbplyr code as simply dplyr.\nOne noticeable difference between SQL and dplyr is the order in which the code is written is different. In the code below, the legislators_terms function as FROM legislators_terms in SQL, which typically comes after the SELECT statement. In many ways, the dplyr code matches both our intuition and the order of operation.\nOther differences here include the na.rm = TRUE argument to min() and the .groups = \"drop\" argument to summarize(). While this is not strictly necessary, it serves as a reminder to users coming from R that SQL always excludes NULL or NA values, which is equivalent to na.rm = TRUE. The .groups = \"drop\" ensures that the resulting data frame has no groups attribute.\nFinally, we can see that the result of the code below is a remote data frame, of which just the first 10 rows are shown below. In effect, the code below can be treated much like a subquery.\n\n\n\nlegislators_terms |&gt;\n  group_by(id_bioguide) |&gt;\n  summarize(first_term = min(term_start, na.rm = TRUE),\n            .groups = \"drop\")\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                id_bioguide\n                first_term\n              \n        \n        \n        \n                \n                  C000127\n                  1993-01-05\n                \n                \n                  C000174\n                  1983-01-03\n                \n                \n                  B001248\n                  2003-01-07\n                \n                \n                  C001072\n                  2008-03-13\n                \n        \n      \n    \n\n\n\nThe next step is to put this code into variable so we can join it to the time series.\n\nfirst_terms &lt;-\n  legislators_terms |&gt;\n  group_by(id_bioguide) |&gt;\n  summarize(first_term = min(term_start, na.rm = TRUE),\n            .groups = \"drop\")\n\nThe age() function is applied to calculate the intervals between each term_start and the first_term for each legislator. Applying year() to the result transforms this into the number of yearly periods. Since elections happen every two or six years, we’ll use years as the time interval to calculate the periods. We could use a shorter interval, but in this data set there is little fluctuation daily or weekly.\n\ncohorts &lt;-\n  first_terms |&gt;\n  inner_join(legislators_terms, by = \"id_bioguide\") |&gt;\n  mutate(period = year(age(term_start, first_term))) |&gt;\n  group_by(period) |&gt;\n  summarize(cohort_retained = n_distinct(id_bioguide)) \n\n\n\n\n\n\n\nHandling functions\n\n\n\nSome functions are recognized by dbplyr and translated to their SQL equivalents. For example n_distinct(x) is translated to count(DISTINCT x)\nFunctions that are not recognized by dbplyr are passed along as is to SQL. For example, if there were no year() recognized by dbplyr, then it would be passed long to DuckDB for handling. In fact, age() is handled in this way, as will be seen below.\nWe can use show_query() to see the actual translated SQL. Here we can see that year() is translated to EXTRACT(year FROM age(term_start, first_term)).\n\n\n\ncohorts |&gt;\n  show_query()\n\n&lt;SQL&gt;\nSELECT period, COUNT(DISTINCT row(id_bioguide)) AS cohort_retained\nFROM (\n  SELECT q01.*, EXTRACT(year FROM age(term_start, first_term)) AS period\n  FROM (\n    SELECT\n      LHS.*,\n      term_number,\n      term_id,\n      term_type,\n      term_start,\n      term_end,\n      state,\n      district,\n      \"class\",\n      party,\n      how,\n      url,\n      address,\n      phone,\n      fax,\n      contact_form,\n      office,\n      state_rank,\n      rss_url,\n      caucus\n    FROM (\n      SELECT id_bioguide, MIN(term_start) AS first_term\n      FROM (SELECT * FROM read_parquet('data/legislators_terms.parquet')) q01\n      GROUP BY id_bioguide\n    ) LHS\n    INNER JOIN (SELECT * FROM read_parquet('data/legislators_terms.parquet')) RHS\n      ON (LHS.id_bioguide = RHS.id_bioguide)\n  ) q01\n) q01\nGROUP BY period\n\n\n\n\n\n\n\n\nUsing collect()\n\n\n\n\n\n\nThe count of legislators with records for that period is the number retained:\n\ncohorts |&gt;\n  arrange(period)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                period\n                cohort_retained\n              \n        \n        \n        \n                \n                  0\n                  12518\n                \n                \n                  1\n                   3600\n                \n                \n                  2\n                   3619\n                \n                \n                  3\n                   1831\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn databases that support the datediff function, the date_part-and-age construction can be replaced by this simpler function:\ndatediff('year', first_term, term_start)\nSome databases, such as Oracle, place the date_part last:\ndatediff(first_term, term_start, 'year')\n\n\nNow that we have the periods and the number of legislators retained in each, the final step is to calculate the total cohort_size and populate it in each row so that the cohort_retained can be divided by it. The first_value window function returns the first record in the PARTITION BY clause, according to the ordering set in the ORDER BY, a convenient way to get the cohort size in each row. In this case, the cohort_size comes from the first record in the entire data set, so the PARTITION BY is omitted:\nfirst_value(cohort_retained) over (order by period) as cohort_size\n\n\n\n\n\n\nAccessing variables\n\n\n\nMuch simpler!\n\n\nTo find the percent retained, divide the cohort_retained value by this same calculation:\n\ncohort_stats &lt;-\n  cohorts |&gt;\n  window_order(period) |&gt;\n  mutate(cohort_size = first(cohort_retained),\n         pct_retained = cohort_retained / cohort_size)\n\n\ncohort_stats |&gt;\n  arrange(period)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                period\n                cohort_retained\n                cohort_size\n                pct_retained\n              \n        \n        \n        \n                \n                  0\n                  12518\n                  12518\n                  1.0000000\n                \n                \n                  1\n                   3600\n                  12518\n                  0.2875859\n                \n                \n                  2\n                   3619\n                  12518\n                  0.2891037\n                \n                \n                  3\n                   1831\n                  12518\n                  0.1462694\n                \n        \n      \n    \n\n\n\nWe now have a retention calculation, and we can see that there is a big drop-off between the 100% of legislators retained in period 0, or on their start date, and the share with another term record that starts a year later. Graphing the results, as in Figure 3.1, demonstrates how the curve flattens and eventually goes to zero, as even the longest-serving legislators eventually retire or die.\n\ncohort_stats |&gt;\n  ggplot(aes(x = period, y = pct_retained)) +\n  geom_line() +\n  ylab(\"Percent retained\") +\n  xlab(\"Years from start\")\n\n\n\n\n\n\n\nFigure 3.1: Retention from start of first term for US legislators\n\n\n\n\n\nWe can take the cohort retention result and reshape the data to show it in table format. Pivot and flatten the results using an aggregate function with a CASE statement; max is used in this example, but other aggregations such as min or avg would return the same result. Retention is calculated for years 0 through 4, but additional years can be added by following the same pattern:\n\ncohort_stats |&gt;\n  select(cohort_size, period, pct_retained) |&gt;\n  filter(period &lt;= 4) |&gt;\n  pivot_wider(names_from = period,\n              values_from = pct_retained,\n              names_prefix = \"yr\",\n              names_sort = TRUE)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                cohort_size\n                yr0\n                yr1\n                yr2\n                yr3\n                yr4\n              \n        \n        \n        \n                \n                  12518\n                  1\n                  0.2875859\n                  0.2891037\n                  0.1462694\n                  0.2564307\n                \n        \n      \n    \n\n\n\nRetention appears to be quite low, and from the graph we can see that it is jagged in the first few years. One reason for this is that a representative’s term lasts two years, and senators’ terms last six years, but the data set only contains records for the start of new terms; thus we are missing data for years in which a legislator was still in office but did not start a new term. Measuring retention each year is misleading in this case. One option is to measure retention only on a two- or six-year cycle, but there is also another strategy we can employ to fill in the “missing” data. I will cover this next before returning to the topic of forming cohort groups.\n\n\n3.3.2 Adjusting Time Series to Increase Retention Accuracy\nWe discussed techniques for cleaning “missing” data in Chapter 2, and we will turn to those techniques in this section in order to arrive at a smoother and more truthful retention curve for the legislators. When working with time series data, such as in cohort analysis, it’s important to consider not only the data that is present but also whether that data accurately reflects the presence or absence of entities at each time period. This is particularly a problem in contexts in which an event captured in the data leads to the entity persisting for some period of time that is not captured in the data. For example, a customer buying a software subscription is represented in the data at the time of the transaction, but that customer is entitled to use the software for months or years and is not necessarily represented in the data over that span. To correct for this, we need a way to derive the span of time in which the entity is still present, either with an explicit end date or with knowledge of the length of the subscription or term. Then we can say that the entity was present at any date in between those start and end dates.\nIn the legislators data set, we have a record for a term’s start date, but we are missing the notion that this “entitles” a legislator to serve for two or six years, depending on the chamber. To correct for this and smooth out the curve, we need to fill in the “missing” values for the years that legislators are still in office between new terms. Since this data set includes a term_end value for each term, I’ll show how to create a more accurate cohort retention analysis by filling in dates between the start and end values. Then I’ll show how you can impute end dates when the data set does not include an end date.\nCalculating retention using a start and end date defined in the data is the most accurate approach. For the following examples, we will consider legislators retained in a particular year if they were still in office as of the last day of the year, December 31. Prior to the Twentieth Amendment to the US Constitution, terms began on March 4, but afterward the start date moved to January 3, or to a subsequent weekday if the third falls on a weekend. Legislators can be sworn in on other days of the year due to special off-cycle elections or appointments to fill vacant seats. As a result, term_start dates cluster in January but are spread across the year. While we could pick another day, December 31 is a strategy for normalizing around these varying start dates.\nThe first step is to create a data set that contains a record for each December 31 that each legislator was in office. This can be accomplished by JOINing the first_terms CTE to the legislators_terms table to find the term_start and term_end for each term. A second JOIN to the date_dim retrieves the dates that fall between the start and end dates, restricting the returned values to c.month_name = 'December' and c.day_of_month = 31. The period is calculated as the years between the date from the date_dim and the first_term. Note that even though more than 11 months may have elapsed between being sworn in in January and December 31, the first year still appears as 0:\n\nCREATE OR REPLACE TABLE date_dim AS\nWITH dates AS \n  (\n    SELECT generate_series::date AS date\n    FROM generate_series(DATE '1770-01-01', \n                         DATE '2030-12-31',\n                         INTERVAL '1 day') )\nSELECT date, \n  strftime(date, '%B') AS month_name,\n  strftime(date, '%-d') AS day_of_month,\n  year(date) AS year\nFROM dates;\n\n\n\n\n\n\n\nReplacing date_dim\n\n\n\nIn almost all the queries in this chapter, the only rows of date_dim that are used are those where month_name = 'December' AND day_of_month = 31. So I create a CTE year_ends that I use over and over again.\nNote that there is a dramatic reduction in the number of meaningless aliases (e.g., a or bb) in the rewritten queries.\n\n\n\ndate_dim &lt;- tbl(db, \"date_dim\")\n\n\nyear_ends &lt;-\n  date_dim |&gt;\n  filter(month_name == 'December', day_of_month == 31)\n\n\ncohorts &lt;-\n  first_terms |&gt;\n  inner_join(legislators_terms, by = \"id_bioguide\") |&gt;\n  left_join(year_ends,\n            join_by(between(y$date, x$term_start, x$term_end))) |&gt;\n  mutate(period = year(age(date, first_term))) |&gt;\n  select(period, id_bioguide, first_term, \n         term_start, term_end, date)\n\n\n\n\n\n\n\nTip\n\n\n\nIf a date dimension is not available, you can create a subquery with the necessary dates in a number of ways. One approach is to create the sequence of dates in R and copy to the database.\n\nyear_ends &lt;-\n  tibble(date = seq(as.Date(\"1770-12-31\"), \n                    as.Date(\"2020-12-31\"), \n                    \"years\")) |&gt;\n         copy_to(db, df = _, name = \"year_ends\", overwrite = TRUE)\n\nYou may want to save this as a table or view for later use. Alternatively, you can query the data set or any other table in the database that has a full set of dates. In this case, the table has all of the necessary years, but we will make a December 31 date for each year using the make_date function:\n\nlegislators_terms |&gt;\n  mutate(date = make_date(year(term_start), 12L, 31L)) |&gt;\n  distinct(date) |&gt;\n  arrange(date)\n\nThere are a number of creative ways to get the series of dates needed. Use which ever method is available and simplest within your queries.\n\n\nWe now have a row for each date (year END) for which we would like to calculate retention. The next step is to calculate the cohort_retained for each period, which is done with a count of id_bioguide. A coalesce function is used on period to set a default value of 0 when null. This handles the cases in which a legislator’s term starts and ends in the same year, giving credit for serving in that year. The final step is to calculate the cohort_size and pct_retained as we did previously using first_value window functions:\n\ncohort_stats &lt;-\n  cohorts |&gt;\n  mutate(period = coalesce(year(age(date, first_term)), 0)) |&gt;\n  group_by(period) |&gt;\n  mutate(cohort_retained = n_distinct(id_bioguide)) |&gt;\n  ungroup() |&gt;\n  window_order(period) |&gt;\n  mutate(cohort_size = first(cohort_retained),\n         pct_retained = cohort_retained / cohort_size) |&gt;\n  arrange(period)\n\nThe results, graphed in Figure 3.2, are now much more accurate. Almost all legislators are still in office in year 1, and the first big drop-off occurs in year 2, when some representatives will fail to be reelected.\n\n\n\n\n\n\n\n\nFigure 3.2: Legislator retention after adjusting for actual years in office\n\n\n\n\n\nIf the data set does not contain an end date, there are a couple of options for imputing one. One option is to add a fixed interval to the start date, when the length of a subscription or term is known. This can be done with date math by adding a constant interval to the term_start. Here, a case_when() is used to handle the addition for the two term_types:\n\ncohorts &lt;-\n  first_terms |&gt;\n  inner_join(legislators_terms, by = \"id_bioguide\") |&gt;\n  mutate(term_end = case_when(term_type == 'rep' ~ term_start + years(2L),\n                               term_type == 'sen' ~ term_start + years(6L))) |&gt;\n  select(id_bioguide, first_term, term_start, term_end)\n\ncohorts\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                id_bioguide\n                first_term\n                term_start\n                term_end\n              \n        \n        \n        \n                \n                  B000944\n                  1993-01-05\n                  1993-01-05\n                  1995-01-05\n                \n                \n                  C000127\n                  1993-01-05\n                  1993-01-05\n                  1995-01-05\n                \n                \n                  C000141\n                  1987-01-06\n                  1987-01-06\n                  1989-01-06\n                \n                \n                  C000174\n                  1983-01-03\n                  1983-01-03\n                  1985-01-03\n                \n        \n      \n    \n\n\n\nThis block of code can then be plugged into the retention code to derive the period and pct_retained. The drawback to this method is that it fails to capture instances in which a legislator did not complete a full term, which can happen in the event of death or appointment to a higher office.\nA second option is to use the subsequent starting date, minus one day, as the term_end date. This can be calculated with the lead() window function. This function is similar to the lag() function we’ve used previously, but rather than returning a value from a row earlier in the partition, it returns a value from a row later in the partition, as determined in the window_order() call. The default is one row, which we will use here, but the function has an optional argument indicating a different number of rows. Here we find the term_start date of the subsequent term using lead and then subtract the days(1L) to derive the term_end:\n\ncohorts &lt;-\n  first_terms |&gt;\n  inner_join(legislators_terms, by = \"id_bioguide\") |&gt;\n  group_by(id_bioguide) |&gt;\n  window_order(term_start) |&gt;\n  mutate(term_end = as.Date(lead(term_start) - days(1L))) |&gt;\n  select(id_bioguide, first_term, term_start, term_end)\n\ncohorts |&gt;\n  arrange(id_bioguide, term_start)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                id_bioguide\n                first_term\n                term_start\n                term_end\n              \n        \n        \n        \n                \n                  A000001\n                  1951-01-03\n                  1951-01-03\n                  NA\n                \n                \n                  A000002\n                  1947-01-03\n                  1947-01-03\n                  NA\n                \n                \n                  A000002\n                  1947-01-03\n                  1949-01-03\n                  NA\n                \n                \n                  A000002\n                  1947-01-03\n                  1951-01-03\n                  NA\n                \n        \n      \n    \n\n\n\nThis code block can then be plugged into the retention code. This method has a couple of drawbacks. First, when there is no subsequent term, the lead function returns null, leaving that term without a term_end. A default value, such as a default interval shown in the last example, could be used in such cases. The second drawback is that this method assumes that terms are always consecutive, with no time spent out of office. Although most legislators tend to serve continuously until their congressional careers end, there are certainly examples of gaps between terms spanning several years.\nAny time we make adjustments to fill in missing data, we need to be careful about the assumptions we make. In subscription- or term-based contexts, explicit start and end dates tend to be most accurate. Either of the two other methods shown—adding a fixed interval or setting the end date relative to the next start date—can be used when no end date is present and we have a reasonable expectation that most customers or users will stay for the duration assumed.\nNow that we’ve seen how to calculate a basic retention curve and correct for missing dates, we can start adding in cohort groups. Comparing retention between different groups is one of the main reasons to do cohort analysis. Next, I’ll discuss forming groups from the time series itself, and after that, I’ll discuss forming cohort groups from data in other tables.\n\n\n3.3.3 Cohorts Derived from the Time Series Itself\nNow that we have SQL code to calculate retention, we can start to split the entities into cohorts. In this section, I will show how to derive cohort groupings from the time series itself. First I’ll discuss time-based cohorts based on the first date, and I’ll explain how to make cohorts based on other attributes from the time series.\nThe most common way to create the cohorts is based on the first or minimum date or time that the entity appears in the time series. This means that only one table is necessary for the cohort retention analysis: the time series itself. Cohorting by the first appearance or action is interesting because often groups that start at different times behave differently. For consumer services, early adopters are often more enthusiastic and retain differently than later adopters, whereas in SaaS software, later adopters may retain better because the product is more mature. Time-based cohorts can be grouped by any time granularity that is meaningful to the organization, though weekly, monthly, or yearly cohorts are common. If you’re not sure what grouping to use, try running the cohort analysis with different groupings, without making the cohort sizes too small, to see where meaningful patterns emerge. Fortunately, once you know how to construct the cohorts and retention analysis, substituting different time granularities is straightforward.\nThe first example will use yearly cohorts, and then I will demonstrate swapping in centuries. The key question we will consider is whether the era in which a legislator first took office has any correlation with their retention. Political trends and the public mood do change over time, but by how much?\nTo calculate yearly cohorts, we first add the year of the first_term calculated previously to cohorts_retained, the CTE that finds period and cohort_retained:\n\ncohorts &lt;-\n  first_terms |&gt;\n  inner_join(legislators_terms, by = \"id_bioguide\") |&gt;\n  left_join(year_ends, \n            join_by(between(y$date, x$term_start, x$term_end))) |&gt;\n  mutate(first_year =  year(first_term),\n         period = coalesce(year(age(date, first_term)), 0)) |&gt;\n  group_by(first_year, period) |&gt;\n  summarize(cohort_retained = n_distinct(id_bioguide),\n            .groups = \"drop\")\n\ncohorts |&gt;\n  arrange(first_year, period)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                first_year\n                period\n                cohort_retained\n              \n        \n        \n        \n                \n                  1789\n                  0\n                  89\n                \n                \n                  1789\n                  1\n                  89\n                \n                \n                  1789\n                  2\n                  57\n                \n                \n                  1789\n                  3\n                  56\n                \n        \n      \n    \n\n\n\nData in cohorts are then used to calculate cohort_size and pct_retained. In this case, however, we need a PARTITION BY clause that includes first_year so that the first_value is calculated only within the set of rows for that first_year, rather than across the whole result set from the subquery:\n\ncohorts |&gt;\n  group_by(first_year) |&gt;\n  window_order(period) |&gt;\n  mutate(cohort_size = first(cohort_retained),\n         pct_retained = cohort_retained / cohort_size) |&gt;\n  ungroup() |&gt;\n  select(first_year, period, cohort_size, cohort_retained,\n         pct_retained) |&gt;\n  arrange(first_year, period)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                first_year\n                period\n                cohort_size\n                cohort_retained\n                pct_retained\n              \n        \n        \n        \n                \n                  1789\n                  0\n                  89\n                  89\n                  1.0000000\n                \n                \n                  1789\n                  1\n                  89\n                  89\n                  1.0000000\n                \n                \n                  1789\n                  2\n                  89\n                  57\n                  0.6404494\n                \n                \n                  1789\n                  3\n                  89\n                  56\n                  0.6292135\n                \n        \n      \n    \n\n\n\nThis data set includes over two hundred starting years, too many to easily graph or examine in a table. Next we’ll look at a less granular interval and cohort the legislators by the century of the first_term. This change is easily made by substituting century() for year() in the cohorts CTE.\n\n\n\n\n\n\nCenturies\n\n\n\nThe original text says:\n\nRecall that century names are offset from the years they represent, so that the 18th century lasted from 1700 to 1799, the 19th century lasted from 1800 to 1899, and so on.\n\nActually the 18th century ran from 1701 to 1800 and the 19th century from 1801 to 1900. This can be confirmed by comparing output from\n\nSELECT century('1700-12-31'::date) AS century\n\n\n1 records\n\n\ncentury\n\n\n\n\n17\n\n\n\n\n\n\nSELECT century('1701-01-01'::date) AS century\n\n\n1 records\n\n\ncentury\n\n\n\n\n18\n\n\n\n\n\n\n\nThe partitioning in the first_value function changes to the first_century field:\n\ncohorts &lt;-\n  first_terms |&gt;\n  inner_join(legislators_terms, by = \"id_bioguide\") |&gt;\n  left_join(year_ends, \n            join_by(between(y$date, x$term_start, x$term_end))) |&gt;\n  mutate(first_century =  century(first_term),\n         period = coalesce(year(age(date, first_term)), 0)) |&gt;\n  group_by(first_century, period) |&gt;\n  summarize(cohort_retained = n_distinct(id_bioguide),\n            .groups = \"drop\")\n\n\ncen_pct_retaineds &lt;-\n  cohorts |&gt;\n  group_by(first_century) |&gt;\n  window_order(period) |&gt;\n  mutate(cohort_size = first(cohort_retained),\n         pct_retained = cohort_retained / cohort_size) |&gt;\n  ungroup() |&gt;\n  select(first_century, period, cohort_size, cohort_retained,\n         pct_retained)\n\ncen_pct_retaineds |&gt;\n  arrange(first_century, period)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                first_century\n                period\n                cohort_size\n                cohort_retained\n                pct_retained\n              \n        \n        \n        \n                \n                  18\n                  0\n                  368\n                  368\n                  1.0000000\n                \n                \n                  18\n                  1\n                  368\n                  360\n                  0.9782609\n                \n                \n                  18\n                  2\n                  368\n                  242\n                  0.6576087\n                \n                \n                  18\n                  3\n                  368\n                  233\n                  0.6331522\n                \n        \n      \n    \n\n\n\nThe results are graphed in Figure 3.3. Retention in the early years has been higher for those first elected in the 20th or 21st century. The 21st century is still under way, and thus many of those legislators have not had the opportunity to stay in office for five or more years, though they are still included in the denominator. We might want to consider removing the 21st century from the analysis, but I’ve left it here to demonstrate how the retention curve drops artificially due to this circumstance.\n\n\n\n\n\n\n\n\nFigure 3.3: Legislator retention by century in which first term began\n\n\n\n\n\nCohorts can be defined from other attributes in a time series besides the first date, with options depending on the values in the table. The legislators_terms table has a state field, indicating which state the person is representing for that term. We can use this to create cohorts, and we will base them on the first state in order to ensure that anyone who has represented multiple states appears in the data only once.\n\n\n\n\n\n\nWarning\n\n\n\nWhen cohorting on an attribute that can change over time, it’s important to ensure that each entity is assigned only one value. Otherwise the entity may be represented in multiple cohorts, introducing bias into the analysis. Usually the value from the earliest record in the data set is used.\n\n\nTo find the first state for each legislator, we can use the first_value window function. In this example, we’ll also turn the min function into a window function to avoid a lengthy GROUP BY clause:\n\nfirst_term_states &lt;-\n  legislators_terms |&gt;\n  group_by(id_bioguide) |&gt;\n  window_order(term_start) |&gt;\n  mutate(first_term = min(term_start),\n         first_state = first(state)) |&gt;\n  ungroup() |&gt;\n  distinct(id_bioguide, first_term, first_state) |&gt;\n  arrange()\n\n\n\n\n\n\n\nReplacing windows\n\n\n\nThe original SQL had two window definitions: one for first_term and another for first_state. However, the value returned by min() is unaffected by the addition of ORDER BY term_start, so I just use the same window for both functions.\n\n\nWe can then plug this code into our retention code to find the retention by first_state:\n\ncohorts &lt;-\n  first_term_states |&gt;\n  inner_join(legislators_terms, by = \"id_bioguide\") |&gt;\n  left_join(year_ends, \n            join_by(between(y$date, x$term_start, x$term_end))) |&gt;\n  mutate(period = coalesce(year(age(date, first_term)), 0)) |&gt;\n  group_by(first_state, period) |&gt;\n  summarize(cohort_retained = n_distinct(id_bioguide),\n            .groups = \"drop\")\n\n\nstate_pct_retaineds &lt;-\n  cohorts |&gt;\n  group_by(first_state) |&gt;\n  window_order(period) |&gt;\n  mutate(cohort_size = first(cohort_retained),\n         pct_retained = cohort_retained / cohort_size) |&gt;\n  ungroup() |&gt;\n  select(first_state, period, cohort_size, cohort_retained,\n         pct_retained)\n\nstate_pct_retaineds |&gt;\n  arrange(first_state, period) \n\nWarning: Missing values are always removed in SQL aggregation functions.\nUse `na.rm = TRUE` to silence this warning\nThis warning is displayed once every 8 hours.\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                first_state\n                period\n                cohort_size\n                cohort_retained\n                pct_retained\n              \n        \n        \n        \n                \n                  AK\n                  0\n                  19\n                  19\n                  1.0000000\n                \n                \n                  AK\n                  1\n                  19\n                  19\n                  1.0000000\n                \n                \n                  AK\n                  2\n                  19\n                  15\n                  0.7894737\n                \n                \n                  AK\n                  3\n                  19\n                  15\n                  0.7894737\n                \n        \n      \n    \n\n\n\nThe retention curves for the five states with the highest total number of legislators are graphed in Figure 3.4. Those elected in Illinois and Massachusetts have the highest retention, while New Yorkers have the lowest retention. Determining the reasons why would be an interesting offshoot of this analysis.\n\n\n\n\n\n\n\n\nFigure 3.4: Legislator retention by first state: top five states by total legislators\n\n\n\n\n\nDefining cohorts from the time series is relatively straightforward using a min date for each entity and then converting that date into a month, year, or century as appropriate for the analysis. Switching between month and year or other levels of granularity also is straightforward, allowing for multiple options to be tested in order to find a grouping that is meaningful for the organization. Other attributes can be used for cohorting with the first_value window function. Next, we’ll turn to cases in which the cohorting attribute comes from a table other than that of the time series.\n\n\n3.3.4 Defining the Cohort from a Separate Table\nOften the characteristics that define a cohort exist in a table separate from the one that contains the time series. For example, a database might have a customer table with information such as acquisition source or registration date by which customers can be cohorted. Adding in attributes from other tables, or even subqueries, is relatively straightforward and can be done in retention analysis and related analyses discussed later in the chapter.\nFor this example, we’ll consider whether the gender of the legislator has any impact on their retention. The legislators table has a gender field, where F means female and M means male, that we can use to cohort the legislators. To do this, we’ll JOIN the legislators table in as alias to add gender to cohorts, in place of year or century:\n\ncohorts &lt;-\n  first_terms |&gt;\n  inner_join(legislators_terms, by = \"id_bioguide\") |&gt;\n  left_join(year_ends, \n            join_by(between(y$date, x$term_start, x$term_end))) |&gt;\n  inner_join(legislators, by = \"id_bioguide\") |&gt;\n  mutate(period = coalesce(year(age(date, first_term)), 0)) |&gt;\n  group_by(gender, period) |&gt;\n  summarize(cohort_retained = n_distinct(id_bioguide),\n            .groups = \"drop\")\n\n\ncohorts |&gt;\n  arrange(period, gender)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                gender\n                period\n                cohort_retained\n              \n        \n        \n        \n                \n                  F\n                  0\n                    366\n                \n                \n                  M\n                  0\n                  12152\n                \n                \n                  F\n                  1\n                    349\n                \n                \n                  M\n                  1\n                  11979\n                \n        \n      \n    \n\n\n\nIt’s immediately clear that many more males than females have served legislative terms. We can now calculate the pct_retained so we can compare the retention for these groups:\n\ngender_retained &lt;-\n  cohorts |&gt;\n  group_by(gender) |&gt;\n  window_order(period) |&gt;\n  mutate(cohort_size = first(cohort_retained),\n         pct_retained = cohort_retained / cohort_size) |&gt;\n  ungroup() |&gt;\n  select(gender, period, cohort_size, cohort_retained,\n         pct_retained)\n\ngender_retained |&gt;\n  arrange(period, gender)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                gender\n                period\n                cohort_size\n                cohort_retained\n                pct_retained\n              \n        \n        \n        \n                \n                  F\n                  0\n                    366\n                    366\n                  1.0000000\n                \n                \n                  M\n                  0\n                  12152\n                  12152\n                  1.0000000\n                \n                \n                  F\n                  1\n                    366\n                    349\n                  0.9535519\n                \n                \n                  M\n                  1\n                  12152\n                  11979\n                  0.9857637\n                \n        \n      \n    \n\n\n\nWe can see from the results graphed in Figure 3.5 that retention is higher for female legislators than for their male counterparts for periods 2 through 29. The first female legislator did not take office until 1917, when Jeannette Rankin joined the House as a Republican representative from Montana. As we saw earlier, retention has increased in more recent centuries.\n\n\n\n\n\n\n\n\nFigure 3.5: Legislator retention by gender\n\n\n\n\n\nTo make a fairer comparison, we might restrict the legislators included in the analysis to only those whose first_term started since there have been women in Congress. We can do this by adding a WHERE filter to the cohorts CTE. Here the results are also restricted to those who started before 2000, to ensure the cohorts have had at least 20 possible years to stay in office:\n\ncohorts &lt;-\n  first_terms |&gt;\n  filter(between(first_term, '1917-01-01', '1999-12-31')) |&gt;\n  inner_join(legislators_terms, by = \"id_bioguide\") |&gt;\n  left_join(year_ends, \n            join_by(between(y$date, x$term_start, x$term_end))) |&gt;\n  inner_join(legislators, by = \"id_bioguide\") |&gt;\n  mutate(period = coalesce(year(age(date, first_term)), 0)) |&gt;\n  group_by(gender, period) |&gt;\n  summarize(cohort_retained = n_distinct(id_bioguide),\n            .groups = \"drop\")\n\n\ngender_retained_fairer &lt;-\n  cohorts |&gt;\n  group_by(gender) |&gt;\n  window_order(period) |&gt;\n  mutate(cohort_size = first(cohort_retained),\n         pct_retained = cohort_retained / cohort_size) |&gt;\n  ungroup() |&gt;\n  select(gender, period, cohort_size, cohort_retained,\n         pct_retained)\n\ngender_retained_fairer |&gt;\n  arrange(period, gender)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                gender\n                period\n                cohort_size\n                cohort_retained\n                pct_retained\n              \n        \n        \n        \n                \n                  F\n                  0\n                   200\n                   200\n                  1.0000000\n                \n                \n                  M\n                  0\n                  3833\n                  3833\n                  1.0000000\n                \n                \n                  F\n                  1\n                   200\n                   187\n                  0.9350000\n                \n                \n                  M\n                  1\n                  3833\n                  3769\n                  0.9833029\n                \n        \n      \n    \n\n\n\nMale legislators still outnumber female legislators, but by a smaller margin. The retention for the cohorts is graphed in Figure 3.6. With the revised cohorts, male legislators have higher retention through year 7, but starting in year 12, female legislators have higher retention. The difference between the two gender-based cohort analyses underscores the importance of setting up appropriate cohorts and ensuring that they have comparable amounts of time to be present or complete other actions of interest. To further improve this analysis, we could cohort by both starting year or decade and gender, in order to control for additional changes in retention through the 20th century and into the 21st century.\n\n\n\n\n\n\n\n\nFigure 3.6: Legislator retention by gender: cohorts from 1917 to 1999\n\n\n\n\n\nCohorts can be defined in multiple ways, from the time series and from other tables. With the framework we’ve developed, subqueries, views, or other derived tables can be swapped in, opening up a whole range of calculations to be the basis of a cohort. Multiple criteria, such as starting year and gender, can be used. One caution when dividing populations into cohorts based on multiple criteria is that this can lead to sparse cohorts, where some of the defined groups are too small and are not represented in the data set for all time periods. The next section will discuss methods for overcoming this challenge.\n\n\n3.3.5 Dealing with Sparse Cohorts\nIn the ideal data set, every cohort has some action or record in the time series for every period of interest. We’ve already seen how “missing” dates can occur due to subscriptions or terms lasting over multiple periods, and we looked at how to correct for them using a date dimension to infer intermediate dates. Another issue can arise when, due to grouping criteria, the cohort becomes too small and as a result is represented only sporadically in the data. A cohort may disappear from the result set, when we would prefer it to appear with a zero retention value. This problem is called sparse cohorts, and it can be worked around with the careful use of LEFT JOINs.\nTo demonstrate this, let’s attempt to cohort female legislators by the first state they represented to see if there are any differences in retention. We’ve already seen that there have been relatively few female legislators. Cohorting them further by state is highly likely to create some sparse cohorts in which there are very few members. Before making code adjustments, let’s add first_state (calculated in the section on deriving cohorts from the time series) into our previous gender example and look at the results:\n\ncohorts &lt;-\n  first_term_states |&gt;\n  filter(between(first_term, '1917-01-01', '1999-12-31')) |&gt;\n  inner_join(legislators_terms, by = \"id_bioguide\") |&gt;\n  left_join(year_ends, \n            join_by(between(y$date, x$term_start, x$term_end))) |&gt;\n  inner_join(legislators, by = \"id_bioguide\") |&gt;\n  mutate(period = coalesce(year(age(date, first_term)), 0)) |&gt;\n  group_by(gender, first_state, period) |&gt;\n  summarize(cohort_retained = n_distinct(id_bioguide),\n            .groups = \"drop\")\n\n\ngender_retained_sparse &lt;-\n  cohorts |&gt;\n  group_by(gender, first_state) |&gt;\n  window_order(period) |&gt;\n  mutate(cohort_size = first(cohort_retained),\n         pct_retained = cohort_retained / cohort_size) |&gt;\n  ungroup() |&gt;\n  select(gender, first_state, period, cohort_size, cohort_retained,\n         pct_retained)\n\ngender_retained_sparse |&gt;\n  arrange(first_state, period, gender) |&gt;\n  filter(first_state == \"AZ\") \n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                gender\n                first_state\n                period\n                cohort_size\n                cohort_retained\n                pct_retained\n              \n        \n        \n        \n                \n                  F\n                  AZ\n                  0\n                   2\n                   2\n                  1\n                \n                \n                  M\n                  AZ\n                  0\n                  26\n                  26\n                  1\n                \n                \n                  F\n                  AZ\n                  1\n                   2\n                   2\n                  1\n                \n                \n                  M\n                  AZ\n                  1\n                  26\n                  26\n                  1\n                \n        \n      \n    \n\n\n\nGraphing the results for the first 20 periods, as in Figure 3.7, reveals the sparse cohorts. Alaska did not have any female legislators, while Arizona’s female retention curve disappears after year 3. Only California, a large state with many legislators, has complete retention curves for both genders. This pattern repeats for other small and large states.\n\n\n\n\n\n\n\n\nFigure 3.7: Legislator retention by gender and first state\n\n\n\n\n\nNow let’s look at how to ensure a record for every period so that the query returns zero values for retention instead of nulls. The first step is to query for all combinations of periods and cohort attributes, in this case first_state and gender, with the starting cohort_size for each combination. This can be done by JOINing cohort_sizes with periods, a data frame that uses generate_series() to generate all integers from 0 to 20.\nThis is a handy way to force a Cartesian JOIN when the two subqueries don’t have any fields in common:\n\nperiods &lt;- tbl(db, \n               sql(\"(SELECT generate_series AS period \n                    FROM generate_series(0, 20, 1))\"))\n\n\ncohort_sizes_filled &lt;-\n  cohorts |&gt;\n  group_by(gender, first_state) |&gt;\n  window_order(period) |&gt;\n  mutate(cohort_size = first(cohort_retained)) |&gt;\n  ungroup() |&gt;\n  distinct(gender, first_state, cohort_size) |&gt;\n  cross_join(periods)\n\nThe next step is to JOIN this back to the actual periods in office, with a LEFT JOIN to ensure all the time periods remain in the final result:\n\npct_retained &lt;-\n  cohort_sizes_filled |&gt;\n  left_join(cohorts, join_by(gender, first_state, period)) |&gt;\n  mutate(cohort_retained = coalesce(cohort_retained, 0),\n         pct_retained = cohort_retained / cohort_size) |&gt; \n  select(gender, first_state, period, cohort_size, cohort_retained,\n         pct_retained)\n\nWe can then pivot the results and confirm that a value exists for each cohort for each period:\n\npct_retained |&gt;\n  select(gender, first_state, period, pct_retained) |&gt;\n  filter(period %in% !!seq(0, 10, 2)) |&gt;\n  pivot_wider(names_from = period,\n              values_from = pct_retained,\n              names_prefix = \"yr\",\n              names_sort = TRUE) |&gt;\n  filter(first_state %in% c('AL', 'AR', 'CA'),\n         gender == 'F') |&gt;\n  arrange(first_state) \n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                gender\n                first_state\n                yr0\n                yr2\n                yr4\n                yr6\n                yr8\n                yr10\n              \n        \n        \n        \n                \n                  F\n                  AL\n                  1\n                  0.00\n                  0.0\n                  0.00\n                  0.00\n                  0.00\n                \n                \n                  F\n                  AR\n                  1\n                  0.80\n                  0.2\n                  0.40\n                  0.40\n                  0.40\n                \n                \n                  F\n                  CA\n                  1\n                  0.92\n                  0.8\n                  0.64\n                  0.68\n                  0.68\n                \n        \n      \n    \n\n\n\nNotice that at this point, the SQL code has gotten quite long. One of the harder parts of writing SQL for cohort retention analysis is keeping all of the logic straight and the code organized, a topic I’ll discuss more in Chapter 8. When building up retention code, I find it helpful to go step-by-step, checking results along the way. I also spot-check individual cohorts to validate that the final result is accurate.\nCohorts can be defined in many ways. So far, we’ve normalized all our cohorts to the first date they appear in the time series data. This isn’t the only option, however, and interesting analysis can be done starting in the middle of an entity’s life span. Before concluding our work on retention analysis, let’s take a look at this additional way to define cohorts.\n\n\n3.3.6 Defining Cohorts from Dates Other Than the First Date\nUsually time-based cohorts are defined from the entity’s first appearance in the time series or from some other earliest date, such as a registration date. However, cohorting on a different date can be useful and insightful. For example, we might want to look at retention across all customers using a service as of a particular date. This type of analysis can be used to understand whether product or marketing changes have had a long-term impact on existing customers.\nWhen using a date other than the first date, we need to take care to precisely define the criteria for inclusion in each cohort. One option is to pick entities present on a particular calendar date. This is relatively straightforward to put into SQL code, but it can be problematic if a large share of the regular user population doesn’t show up every day, causing retention to vary depending on the exact day chosen. One option to correct for this is to calculate retention for several starting dates and then average the results.\nAnother option is to use a window of time such as a week or month. Any entity that appears in the data set during that window is included in the cohort. While this approach is often more representative of the business or process, the trade-off is that the SQL code will become more complex, and the query time may be slower due to more intense database calculations. Finding the right balance between query performance and accuracy of results is something of an art.\nLet’s take a look at how to calculate such midstream analysis with the legislators data set by considering retention for legislators who were in office in the year 2000. We’ll cohort by the term_type, which has values of “sen” for senators and “rep” for representatives. The definition will include any legislator in office at any time during the year 2000: those who started prior to 2000 and whose terms ended during or after 2000 qualify, as do those who started a term in 2000. We can hardcode any date in 2000 as the first_term, since we will later check whether they were in office at some point during 2000. The min_start of the terms falling in this window is also calculated for use in a later step:\n\nfirst_terms &lt;-\n  legislators_terms |&gt;\n  filter(term_start &lt;= \"2000-12-31\", \n         term_end &gt;= \"2000-01-01\") |&gt;\n  mutate(first_term = as.Date(\"2000-01-01\")) |&gt;\n  group_by(id_bioguide, term_type, first_term) |&gt;\n  summarize(min_start = min(term_start), .groups = \"drop\") \n\nWe can then plug this into our retention code, with two adjustments. First, an additional JOIN criterion between first_terms and the legislators_terms table is added in order to return only terms that started on or after the min_start date. Second, an additional filter is added to year_ends so that it only returns dates in 2000 or later:\n\ncohorts &lt;-\n  first_terms |&gt;\n  inner_join(legislators_terms |&gt; select(-term_type),\n             join_by(id_bioguide, y$term_start &gt;= x$min_start)) |&gt;\n  left_join(year_ends |&gt; filter(year(date) &gt;= 2000), \n            join_by(between(y$date, x$term_start, x$term_end))) |&gt;\n  inner_join(legislators, by = \"id_bioguide\") |&gt;\n  mutate(period = coalesce(year(age(date, first_term)), 0)) |&gt;\n  group_by(term_type, period) |&gt;\n  summarize(cohort_retained = n_distinct(id_bioguide),\n            .groups = \"drop\")\n\n\npct_retained_2000 &lt;-\n  cohorts |&gt;\n  group_by(term_type) |&gt;\n  window_order(period) |&gt;\n  mutate(cohort_size = first(cohort_retained),\n         pct_retained = cohort_retained / cohort_size) |&gt;\n  ungroup() |&gt;\n  select(term_type, period, cohort_size, cohort_retained, pct_retained)\n\nFigure 3.8 shows that despite longer terms for senators, retention among the two cohorts was similar, and was actually worse for senators after 10 years. A further analysis comparing the different years they were first elected, or other cohort attributes, might yield some interesting insights.\n\n\n\n\n\n\n\n\nFigure 3.8: Retention by term type for legislators in office during the year 2000\n\n\n\n\n\nA common use case for cohorting on a value other than a starting value is when trying to analyze retention after an entity has reached a threshold, such as a certain number of purchases or a certain amount spent. As with any cohort, it’s important to take care in defining what qualifies an entity to be in a cohort and which date will be used as the starting date.\nCohort retention is a powerful way to understand the behavior of entities in a time series data set. We’ve seen how to calculate retention with SQL and how to cohort based on the time series itself or on other tables, and from points in the middle of entity life span. We also looked at how to use functions and JOINs to adjust dates within time series and compensate for sparse cohorts. There are several types of analyses that are related to cohort retention: analysis, survivorship, returnship, and cumulative calculations, all of which build off of the SQL code that we’ve developed for retention. Let’s turn to them next.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Cohort Analysis -- `dbplyr` version</span>"
    ]
  },
  {
    "objectID": "dbplyr.html#related-cohort-analyses",
    "href": "dbplyr.html#related-cohort-analyses",
    "title": "3  Cohort Analysis – dbplyr version",
    "section": "3.4 Related Cohort Analyses",
    "text": "3.4 Related Cohort Analyses\nIn the last section, we learned how to write SQL for cohort retention analysis. Retention captures whether an entity was in a time series data set on a specific date or window of time. In addition to presence on a specific date, analysis is often interested in questions of how long an entity lasted, whether an entity did multiple actions, and how many of those actions occurred. These can all be answered with code that is similar to retention and is well suited to just about any cohorting criteria you like. Let’s take a look at the first of these, survivorship.\n\n3.4.1 Survivorship\nSurvivorship, also called survival analysis, is concerned with questions about how long something lasts, or the duration of time until a particular event such as churn or death. Survivorship analysis can answer questions about the share of the population that is likely to remain past a certain amount of time. Cohorts can help identify or at least provide hypotheses about which characteristics or circumstances increase or decrease the survival likelihood.\nThis is similar to a retention analysis, but instead of calculating whether an entity was present in a certain period, we calculate whether the entity is present in that period or later in the time series. Then the share of the total cohort is calculated. Typically one or more periods are chosen depending on the nature of the data set analyzed. For example, if we want to know the share of game players who survive for a week or longer, we can check for actions that occur after a week from starting and consider those players still surviving. On the other hand, if we are concerned about the number of students who are still in school after a certain number of years, we could look for the absence of a graduation event in a data set. The number of periods can be SELECTed either by calculating an average or typical life span or by choosing time periods that are meaningful to the organization or process analyzed, such as a month, year, or longer time period.\nIn this example, we’ll look at the share of legislators who survived in office for a decade or more after their first term started. Since we don’t need to know the specific dates of each term, we can start by calculating the first and last term_start dates, using min and max aggregations:\n\nfirst_last_terms &lt;-\n  legislators_terms |&gt;\n  group_by(id_bioguide) |&gt;\n  summarize(first_term = min(term_start, na.rm = TRUE),\n            last_term = max(term_start, na.rm = TRUE),\n            .groups = \"drop\")\n\nNext, we add first_century, the century of first_term, and tenure as the number of years between the first_term and last_term:\n\nfirst_centuries &lt;-\n  first_last_terms |&gt;\n  mutate(first_century = century(first_term),\n         tenure = year(age(last_term, first_term)))\n\nFinally, we calculate the cohort_size with a count of all the legislators, as well as calculating the number who survived for at least 10 years by using a case_when statement and n_distinct(). The percent who survived is found by dividing these two values:\nHere na.rm = TRUE matters!\n\nfirst_centuries |&gt;\n  group_by(first_century) |&gt;\n  summarize(cohort_size = n_distinct(id_bioguide, na.rm = TRUE),\n            survived_10 = n_distinct(case_when(tenure &gt;= 10 ~ id_bioguide),\n                                     na.rm = TRUE),\n            .groups = \"drop\") |&gt;\n  mutate(pct_survived_10 = survived_10 / cohort_size) |&gt;\n  arrange(first_century)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                first_century\n                cohort_size\n                survived_10\n                pct_survived_10\n              \n        \n        \n        \n                \n                  18\n                   368\n                    83\n                  0.2255435\n                \n                \n                  19\n                  6299\n                   892\n                  0.1416098\n                \n                \n                  20\n                  5091\n                  1853\n                  0.3639756\n                \n                \n                  21\n                   760\n                   119\n                  0.1565789\n                \n        \n      \n    \n\n\n\nSince terms may or may not be consecutive, we can also calculate the share of legislators in each century who survived for five or more total terms. In the subquery, add a count to find the total number of terms per legislator. Then in the outer query, divide the number of legislators with five or more terms by the total cohort size:\n\ntotal_terms &lt;-\n  legislators_terms |&gt;\n  group_by(id_bioguide) |&gt;\n  summarize(first_century = century(min(term_start)),\n            total_terms = count(term_start),\n            .groups = \"drop\")\n\n\ntotal_terms |&gt;\n  group_by(first_century) |&gt;\n  summarize(cohort_size = n_distinct(id_bioguide, na.rm = TRUE),\n            survived_5 = n_distinct(case_when(total_terms &gt;= 5 ~ id_bioguide),\n                                     na.rm = TRUE),\n            .groups = \"drop\") |&gt;\n  mutate(pct_survived_5_terms = survived_5 / cohort_size) |&gt;\n  arrange(first_century)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                first_century\n                cohort_size\n                survived_5\n                pct_survived_5_terms\n              \n        \n        \n        \n                \n                  18\n                   368\n                    63\n                  0.1711957\n                \n                \n                  19\n                  6299\n                   711\n                  0.1128751\n                \n                \n                  20\n                  5091\n                  2153\n                  0.4229032\n                \n                \n                  21\n                   760\n                   205\n                  0.2697368\n                \n        \n      \n    \n\n\n\nTen years or five terms is somewhat arbitrary. We can also calculate the survivorship for each number of years or periods and display the results in graph or table form. Here, we calculate the survivorship for each number of terms from 1 to 20. This is accomplished through a Cartesian JOIN to a subquery that contains those integers derived by the generate_series function:\n\nsurv_century &lt;-\n  total_terms |&gt;\n  cross_join(periods)|&gt; \n  rename(terms = period) |&gt;\n  filter(terms &gt; 0) |&gt;\n  group_by(first_century, terms) |&gt;\n  summarize(cohort_size = n_distinct(id_bioguide, na.rm = TRUE),\n            cohort_survived = n_distinct(case_when(total_terms &gt;= terms ~ id_bioguide),\n                                     na.rm = TRUE),\n            .groups = \"drop\") |&gt;\n  mutate(pct_survived = cohort_survived / cohort_size) \n\nsurv_century |&gt;\n  arrange(first_century, terms)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                first_century\n                terms\n                cohort_size\n                cohort_survived\n                pct_survived\n              \n        \n        \n        \n                \n                  18\n                  1\n                  368\n                  368\n                  1.0000000\n                \n                \n                  18\n                  2\n                  368\n                  249\n                  0.6766304\n                \n                \n                  18\n                  3\n                  368\n                  153\n                  0.4157609\n                \n                \n                  18\n                  4\n                  368\n                   96\n                  0.2608696\n                \n        \n      \n    \n\n\n\nThe results are graphed in Figure 3.9. Survivorship was highest in the 20th century, a result that agrees with results we saw previously in which retention was also highest in the 20th century.\n\n\n\n\n\n\n\n\nFigure 3.9: Retention by term type for legislators in office during the year 2000\n\n\n\n\n\nSurvivorship is closely related to retention. While retention counts entities present in a specific number of periods from the start, survivorship considers only whether an entity was present as of a specific period or later. As a result, the code is simpler since it needs only the first and last dates in the time series, or a count of dates. Cohorting is done similar to cohorting for retention, and cohort definitions can come from within the time series or be derived from another table or subquery.\nNext we’ll consider another type of analysis that is in some ways the inverse of survivorship. Rather than calculating whether an entity is present in the data set at a certain time or later, we will calculate whether an entity returns or repeats an action at a certain period or earlier. This is called returnship or repeat purchase behavior.\n\n\n3.4.2 Returnship, or Repeat Purchase Behavior\nSurvivorship is useful for understanding how long a cohort is likely to stick around. Another useful type of cohort analysis seeks to understand whether a cohort member can be expected to return within a given window of time and the intensity of activity during that window. This is called returnship or repeat purchase behavior.\nFor example, an ecommerce site might want to know not only how many new buyers were acquired via a marketing campaign but also whether those buyers have become repeat buyers. One way to figure this out is to simply calculate total purchases per customer. However, comparing customers acquired two years ago with those acquired a month ago isn’t fair, since the former have had a much longer time in which to return. The older cohort would almost certainly appear more valuable than the newer one. Although this is true in a sense, it gives an incomplete picture of how the cohorts are likely to behave across their entire life span.\nTo make fair comparisons between cohorts with different starting dates, we need to create an analysis based on a time box, or a fixed window of time from the first date, and consider whether cohort members returned within that window. This way, every cohort has an equal amount of time under consideration, so long as we include only those cohorts for which the full window has elapsed. Returnship analysis is common for retail organizations, but it can also be applied in other domains. For example, a university might want to see how many students enrolled in a second course, or a hospital might be interested in how many patients need follow-up medical treatments after an initial incident.\nTo demonstrate returnship analysis, we can ask a new question of the legislators data set: how many legislators have more than one term type, and specifically, what share of them start as representatives and go on to become senators (some senators later become representatives, but that is much less common). Since relatively few make this transition, we’ll cohort legislators by the century in which they first became a representative.\n\nrep_first_terms &lt;-\n  legislators_terms |&gt;\n  filter(term_type == 'rep') |&gt;\n  group_by(id_bioguide) |&gt;\n  summarize(first_term = min(term_start, na.rm = TRUE),\n            .groups = \"drop\")\n\nThe first step is to find the cohort size for each century, using the CTE and century() calculations seen previously, for only those with term_type = 'rep':\n\nrep_centuries &lt;-\n  rep_first_terms |&gt;\n  mutate(cohort_century = century(first_term)) |&gt;\n  group_by(cohort_century) |&gt;\n  summarize(reps = count(id_bioguide),\n            .groups = \"drop\")\n\nrep_centuries |&gt;\n  arrange(cohort_century)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                cohort_century\n                reps\n              \n        \n        \n        \n                \n                  18\n                   299\n                \n                \n                  19\n                  5773\n                \n                \n                  20\n                  4481\n                \n                \n                  21\n                   683\n                \n        \n      \n    \n\n\n\nNext we’ll perform a similar calculation, with a JOIN to the legislators_terms table, to find the representatives who later became senators. This is accomplished with the clauses term_type = 'sen' and term_start &gt; first_term:\n\nrep_sen_centuries &lt;-\n  rep_first_terms |&gt;\n  inner_join(legislators_terms, by = join_by(id_bioguide)) |&gt;\n  filter(term_type == 'sen', \n         term_start &gt; first_term) |&gt;\n  mutate(cohort_century = century(first_term)) |&gt;\n  group_by(cohort_century) |&gt;\n  summarize(rep_and_sen = n_distinct(id_bioguide),\n            .groups = \"drop\")\n\nrep_sen_centuries |&gt;\n  arrange(cohort_century) \n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                cohort_century\n                rep_and_sen\n              \n        \n        \n        \n                \n                  18\n                   57\n                \n                \n                  19\n                  329\n                \n                \n                  20\n                  254\n                \n                \n                  21\n                   25\n                \n        \n      \n    \n\n\n\nFinally, we JOIN these two subqueries together and calculate the percent of representatives who became senators. A LEFT JOIN is used; this clause is typically recommended to ensure that all cohorts are included whether or not the subsequent event happened. If there is a century in which no representatives became senators, we still want to include that century in the result set:\n\nrep_centuries |&gt;\n  left_join(rep_sen_centuries, by = join_by(cohort_century)) |&gt;\n  mutate(pct_rep_and_sen = rep_and_sen / reps) |&gt;\n  select(cohort_century, pct_rep_and_sen) |&gt;\n  arrange(cohort_century) \n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                cohort_century\n                pct_rep_and_sen\n              \n        \n        \n        \n                \n                  18\n                  0.19063545\n                \n                \n                  19\n                  0.05698943\n                \n                \n                  20\n                  0.05668378\n                \n                \n                  21\n                  0.03660322\n                \n        \n      \n    \n\n\n\nRepresentatives from the 18th century were most likely to become senators. However, we have not yet applied a time box to ensure a fair comparison. While we can safely assume that all legislators who served in the 18th and 19th centuries are no longer living, many of those who were first elected in the 20th and 21st centuries are still in the middle of their careers. Adding the filter WHERE age(term_start, first_term) &lt;= INTERVAL '10 years' to CTE rep_sen_centuries creates a time box of 10 years. Note that the window can easily be made larger or smaller by changing the constant in the interval. An additional filter applied to rep_centuries, WHERE first_term &lt;= '2009-12-31', excludes those who were less than 10 years into their careers when the data set was assembled:\n\nrep_centuries &lt;-\n  rep_first_terms |&gt;\n  filter(first_term &lt;= \"2009-12-31\") |&gt;\n  mutate(cohort_century = century(first_term)) |&gt;\n  group_by(cohort_century) |&gt;\n  summarize(reps = count(id_bioguide),\n            .groups = \"drop\")\n\nrep_sen_centuries &lt;-\n  rep_first_terms |&gt;\n  inner_join(legislators_terms, by = join_by(id_bioguide)) |&gt;\n  filter(term_type == 'sen', \n         term_start &gt; first_term,\n         age(term_start, first_term) &lt;= years(10L)) |&gt;\n  mutate(cohort_century = century(first_term)) |&gt;\n  group_by(cohort_century) |&gt;\n  summarize(rep_and_sen = n_distinct(id_bioguide),\n            .groups = \"drop\")\n\n\nrep_centuries |&gt;\n  left_join(rep_sen_centuries, by = join_by(cohort_century)) |&gt;\n  mutate(pct_rep_and_sen = rep_and_sen / reps) |&gt;\n  select(cohort_century, pct_rep_and_sen) |&gt;\n  arrange(cohort_century) \n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                cohort_century\n                pct_rep_and_sen\n              \n        \n        \n        \n                \n                  18\n                  0.09698997\n                \n                \n                  19\n                  0.02442404\n                \n                \n                  20\n                  0.03481366\n                \n                \n                  21\n                  0.07636364\n                \n        \n      \n    \n\n\n\nWith this new adjustment, the 18th century still had the highest share of representatives becoming senators within 10 years, but the 21st century has the second-highest share, and the 20th century had a higher share than the 19th.\nSince 10 years is somewhat arbitrary, we might also want to compare several time windows. One option is to run the query several times with different intervals and note the results. Another option is to calculate multiple windows in the same result set by using a set of CASE statements inside of count(DISTINCT x) aggregations to form the intervals, rather than specifying the interval in the WHERE clause:\n\nterms &lt;-\n  periods |&gt;\n  filter(period %in% c(5, 10, 15)) |&gt;\n  rename(term = period)\n\nrep_sen_centuries &lt;-\n  rep_first_terms |&gt;\n  inner_join(legislators_terms, by = join_by(id_bioguide)) |&gt;\n  filter(term_type == 'sen', \n         term_start &gt; first_term) |&gt;\n  cross_join(terms) |&gt;\n  mutate(tenure = age(term_start, first_term),\n         id_bioguide = case_when(tenure &lt;= years(term) ~ id_bioguide),\n         cohort_century = century(first_term)) |&gt;\n  group_by(cohort_century, term) |&gt;\n  summarize(rep_and_sen = n_distinct(id_bioguide, na.rm = TRUE),\n            .groups = \"drop\")\n\n\nrep_centuries |&gt;\n  left_join(rep_sen_centuries, by = join_by(cohort_century)) |&gt;\n  mutate(pct_rep_and_sen = rep_and_sen / reps) |&gt;\n  pivot_wider(id_cols = cohort_century,\n              names_from = term,\n              names_glue = \"pct_{term}_yrs\",\n              names_sort = TRUE,\n              values_from = pct_rep_and_sen) |&gt;\n  arrange(cohort_century)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                cohort_century\n                pct_5_yrs\n                pct_10_yrs\n                pct_15_yrs\n              \n        \n        \n        \n                \n                  18\n                  0.050167224\n                  0.09698997\n                  0.14381271\n                \n                \n                  19\n                  0.008834228\n                  0.02442404\n                  0.04087996\n                \n                \n                  20\n                  0.010042401\n                  0.03481366\n                  0.04775720\n                \n                \n                  21\n                  0.040000000\n                  0.07636364\n                  0.08727273\n                \n        \n      \n    \n\n\n\nWith this output, we can see how the share of representatives who became senators evolved over time, both within each cohort and across cohorts. In addition to the table format, graphing the output often reveals interesting trends. In Figure 3.10, the cohorts based on century are replaced with cohorts based on the first decade, and the trends over 10 and 20 years are shown. Conversion of representatives to senators during the first few decades of the new US legislature was clearly different from patterns in the years since.\n\nrep_decades &lt;-\n  rep_first_terms |&gt;\n  filter(first_term &lt;= \"2009-12-31\") |&gt;\n  mutate(cohort_decade = decade(first_term)) |&gt;\n  group_by(cohort_decade) |&gt;\n  summarize(reps = count(id_bioguide),\n            .groups = \"drop\")\n\nterms &lt;-\n  periods |&gt;\n  filter(period %in% c(10, 20)) |&gt;\n  rename(term = period)\n\nrep_sen_decades &lt;-\n  rep_first_terms |&gt;\n  inner_join(legislators_terms, by = join_by(id_bioguide)) |&gt;\n  filter(term_type == 'sen', \n         term_start &gt; first_term) |&gt;\n  cross_join(terms) |&gt;\n  mutate(tenure = age(term_start, first_term),\n         id_bioguide = case_when(tenure &lt;= years(term) ~ id_bioguide),\n         cohort_decade = decade(first_term)) |&gt;\n  group_by(cohort_decade, term) |&gt;\n  summarize(rep_and_sen = n_distinct(id_bioguide, na.rm = TRUE),\n            .groups = \"drop\")\n\n\n\n\n\n\n\n\n\nFigure 3.10: Trend of the share of representatives for each cohort, defined by starting decade, who later became senators\n\n\n\n\n\nFinding the repeat behavior within a fixed time box is a useful tool for comparing cohorts. This is particularly true when the behaviors are intermittent in nature, such as purchase behavior or content or service consumption. In the next section, we’ll look at how to calculate not only whether an entity had a subsequent action but also how many subsequent actions they had, and we’ll aggregate them with cumulative calculations.\n\n\n3.4.3 Cumulative Calculations\nCumulative cohort analysis can be used to establish cumulative lifetime value, also called customer lifetime value (the acronyms CLTV and LTV are used interchangeably), and to monitor newer cohorts in order to be able to predict what their full LTV will be. This is possible because early behavior is often highly correlated with long-term behavior. Users of a service who return frequently in their first days or weeks of using it tend to be the most likely to stay around over the long term. Customers who buy a second or third time early on are likely to continue purchasing over a longer time period. Subscribers who renew after the first month or year are often likely to stick around over many subsequent months or years.\nIn this section, I’ll mainly talk about the revenue-generating activities of customers, but this analysis can also be applied to situations in which customers or entities incur costs, such as through product returns, support interactions, or use of health-care services.\nWith cumulative calculations, we’re less concerned about whether an entity did an action on a particular date and more about the total as of a particular date. The cumulative calculations used in this type of analysis are most often counts or sums. We will again use the time box concept to ensure apples-to-apples comparisons between cohorts. Let’s look at the number of terms started within 10 years of the first term_start, cohorting the legislators by century and type of first term:\n\nfirst_terms &lt;-\n  legislators_terms |&gt;\n  group_by(id_bioguide) |&gt;\n  window_order(term_start) |&gt;\n  summarize(first_type = first(term_type),\n            first_term = min(term_start, na.rm = TRUE)) |&gt;\n  mutate(first_plus_10 = first_term + years(10)) |&gt;\n  ungroup()\n\ncohort_data &lt;-\n  first_terms |&gt;\n  left_join(legislators_terms,\n            join_by(id_bioguide,\n                    between(y$term_start,\n                            x$first_term,\n                            x$first_plus_10))) |&gt;\n  mutate(century = century(first_term)) |&gt;\n  group_by(century, first_type) |&gt;\n  summarize(cohort = n_distinct(id_bioguide),\n            terms = count(term_start),\n            .groups = \"drop\") |&gt;\n  mutate(terms_per_leg = terms / cohort)\n\ncohort_data |&gt;\n  arrange(century, first_type)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                century\n                first_type\n                cohort\n                terms\n                terms_per_leg\n              \n        \n        \n        \n                \n                  18\n                  rep\n                   297\n                    760\n                  2.558923\n                \n                \n                  18\n                  sen\n                    71\n                    101\n                  1.422535\n                \n                \n                  19\n                  rep\n                  5744\n                  12165\n                  2.117862\n                \n                \n                  19\n                  sen\n                   555\n                    795\n                  1.432432\n                \n        \n      \n    \n\n\n\nThe largest cohort is that of representatives first elected in the 19th century, but the cohort with the largest number of terms started within 10 years is that of representatives first elected in the 20th century. This type of calculation can be useful for understanding the overall contribution of a cohort to an organization.T otal sales or total repeat purchases can be valuable metrics. Usually, though, we want to normalize to understand the contribution on a per-entity basis. Calculations we might want to make include average actions per person, average order value (AOV), items per order, and orders per customer. To normalize by the cohort size, simply divide by the starting cohort, which we’ve done previously with retention, survivorship, and returnship. Here we do that and also pivot the results into table form for easier comparisons:\n\ncohort_data |&gt;\n  select(century, first_type,   cohort, terms_per_leg) |&gt;\n  rename(terms = terms_per_leg) |&gt;\n  pivot_wider(names_from = first_type,\n              values_from = c(cohort, terms),\n              names_glue = \"{first_type}_{.value}\",\n              names_sort = TRUE) |&gt;\n  arrange(century)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                century\n                rep_cohort\n                sen_cohort\n                rep_terms\n                sen_terms\n              \n        \n        \n        \n                \n                  18\n                   297\n                   71\n                  2.558923\n                  1.422535\n                \n                \n                  19\n                  5744\n                  555\n                  2.117862\n                  1.432432\n                \n                \n                  20\n                  4473\n                  618\n                  3.622401\n                  1.631068\n                \n                \n                  21\n                   683\n                   77\n                  3.225476\n                  1.532468\n                \n        \n      \n    \n\n\n\nWith the cumulative terms normalized by the cohort size, we can now confirm that representatives first elected in the 20th century had the highest average number of terms, while those who started in the 19th century had the fewest number of terms on average. Senators have fewer but longer terms than their representative peers, and again those who started in the 20th century have had the highest number of terms on average.\nCumulative calculations are often used in customer lifetime value calculations. LTV is usually calculated using monetary measures, such as total dollars spent by a customer, or the gross margin (revenue minus costs) generated by a customer across their lifetime. To facilitate comparisons between cohorts, the “lifetime” is often chosen to reflect average customer lifetime, or periods that are convenient to analyze, such as 3, 5, or 10 years. The legislators data set doesn’t contain financial metrics, but swapping in dollar values in any of the preceding SQL code would be straightforward. Fortunately, SQL is a flexible enough language that we can adapt these templates to address a wide variety of analytical questions.\nCohort analysis includes a set of techniques that can be used to answer questions related to behavior over time and how various attributes may contribute to differences between groups. Survivorship, returnship, and cumulative calculations all shed light on these questions. With a good understanding of how cohorts behave, we often have to turn our attention back to the composition or mix of cohorts over time, understanding how that can impact total retention, survivorship, returnship, or cumulative values such that these measures differ surprisingly from the individual cohorts.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Cohort Analysis -- `dbplyr` version</span>"
    ]
  },
  {
    "objectID": "dbplyr.html#cross-section-analysis-through-a-cohort-lens",
    "href": "dbplyr.html#cross-section-analysis-through-a-cohort-lens",
    "title": "3  Cohort Analysis – dbplyr version",
    "section": "3.5 Cross-Section Analysis, through a Cohort Lens",
    "text": "3.5 Cross-Section Analysis, through a Cohort Lens\nSo far in this chapter, we’ve been looking at cohort analysis. We’ve followed the behavior of cohorts across time with retention, survivorship, returnship, and cumulative behavior analyses. One of the challenges with these analyses, however, is that even as they make changes within cohorts easy to spot, it can be difficult to spot changes in the overall composition of a customer or user base.\nMix shifts, which are changes in the composition of the customer or user base over time, can also occur, making later cohorts different from earlier ones. Mix shifts may be due to international expansion, shifting between organic and paid acquisition strategies, or moving from a niche enthusiast audience to a broader mass market one. Creating additional cohorts, or segments, along any of these suspected lines can help diagnose whether a mix shift is happening.\nCohort analysis can be contrasted with cross-sectional analysis, which compares individuals or groups at a single point in time. Cross-sectional studies can correlate years of education with current income, for example. On the positive side, collecting data sets for cross-sectional analysis is often easier since no time series is necessary. Cross-sectional analysis can be insightful, generating hypotheses for further investigation. On the negative side, a form of selection bias called survivorship bias usually exists, which can lead to false conclusions.\n\n\n\n\n\n\nSurvivorship bias\n\n\n\nThe note on survivorship bias in the original text is problematic because the second and third paragraphs do not provide examples that clearly illustrate the phenomenon of survivorship bias.\nThe paragraph on college dropouts probably illustrates a mix of availability bias and the base rate fallacy. it is easy to recall examples of people who have dropped out of college before going onto successful careers in business. Classic examples include Bill Gates, Steve Jobs, and Mark Zuckerberg. I suspect that it is much easier to recall examples of successful dropouts because it’s a more salient fact for those cases. If Mark Zuckerberg had completed his undergraduate studies at Harvard, it would hardly merit a mention in any story about him; that he dropped out is an interesting fact.\nThe third paragraph is more clearly an illustration of the base rate fallacy. If we compare the proportion of best customers who live in California or Texas and are 18 to 30 years old with the number of people in the population who live in California or Texas and are 18 to 30 years old, we can adjust for the underlying base rate problem. Of course, it the people entering into the customer pool do not reflect the underlying populations, then only correcting for this base rate issue would not produce valid survival rates. In this case, we could characterize the issue as a survivorship bias that could be addressed by a proper cohort analysis.\n\n\n\n\n\n\n\n\nSurvivorship bias\n\n\n\n“Let’s look at our best customers and see what they have in common.” This seemingly innocent and well-intentioned idea can lead to some very problematic conclusions. Survivorship bias is the logical error of focusing on the people or things that made it past some selection process, while ignoring those that did not. Commonly this is because the entities no longer exist in the data set at the time of selection, because they have failed, churned, or left the population for some other reason. Concentrating only on the remaining population can lead to overly optimistic conclusions, because failures are ignored.\nMuch has been written about a few people who dropped out of college and started wildly successful technology companies. This doesn’t mean you should immediately leave college, since the vast majority of people who drop out do not go on to be successful CEOs. That part of the population doesn’t make for nearly as sensational headlines, so it’s easy to forget about that reality.\nIn the successful customer context, survivorship bias might show up as an observation that the best customers tend to live in California or Texas and tend to be 18 to 30 years old. This is a large population to start with, and it may turn out that these characteristics are shared by many customers who churned prior to the analysis date. Going back to the original population might reveal that other demographics, such as 41-to-50-year-olds in Vermont, actually stick around and spend more over time, even though there are fewer of them in absolute terms. Cohort analysis helps distinguish and reduce survivorship bias.\n\n\nCohort analysis is a way to overcome survivorship bias by including all members of a starting cohort in the analysis. We can take a series of cross sections from a cohort analysis to understand how the mix of entities may have changed over time. On any given date, users from a variety of cohorts are present. We can use cross-sectional analysis to examine them, like layers of sediment, to reveal new insights. In the next example, we’ll create a time series of the share of legislators from each cohort for each year in the data set.\nThe first step is to find the number of legislators in office each year by JOINing the legislators table to the date_dim, WHERE the date from the date_dim is between the start and end dates of each term. Here we use December 31 for each year to find the legislators in office at each year’s end:\n\nyear_ends &lt;-\n  date_dim |&gt;\n  filter(month_name == 'December', \n         day_of_month == 31,\n         year &lt;= 2019)\n\ncohort_data &lt;-\n  legislators_terms |&gt;\n  inner_join(year_ends,\n             join_by(between(y$date, x$term_start, x$term_end)))\n\ncohort_data |&gt;\n  group_by(date) |&gt;\n  summarize(legislators = n_distinct(id_bioguide)) |&gt;\n  arrange(date)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                date\n                legislators\n              \n        \n        \n        \n                \n                  1789-12-31\n                   89\n                \n                \n                  1790-12-31\n                   95\n                \n                \n                  1791-12-31\n                   99\n                \n                \n                  1792-12-31\n                  101\n                \n        \n      \n    \n\n\n\nNext, we add in the century cohorting criterion by JOINing to first_terms:\n\nfirst_terms &lt;-\n  legislators_terms |&gt;\n  group_by(id_bioguide) |&gt;\n  summarize(first_term = min(term_start, na.rm = TRUE),\n            .groups = \"drop\")\n\ncohorts &lt;-\n  cohort_data |&gt;\n  inner_join(first_terms, by = \"id_bioguide\") |&gt;\n  mutate(century = century(first_term)) |&gt;\n  group_by(date, century) |&gt;\n  summarize(legislators = n_distinct(id_bioguide),\n            .groups = \"drop\")\n\n\ncohorts |&gt;\n  arrange(date) \n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                date\n                century\n                legislators\n              \n        \n        \n        \n                \n                  1789-12-31\n                  18\n                   89\n                \n                \n                  1790-12-31\n                  18\n                   95\n                \n                \n                  1791-12-31\n                  18\n                   99\n                \n                \n                  1792-12-31\n                  18\n                  101\n                \n        \n      \n    \n\n\n\nFinally, we calculate the percent of total legislators in each year that the century cohort represents. This can be done in a couple of ways, depending on the shape of output desired. The first way is to keep a row for each date and century combination and use a sum window function in the denominator of the percentage calculation:\n\npct_centuries &lt;-\n  cohorts |&gt;\n  group_by(date) |&gt;\n  mutate(cohort = sum(legislators),\n         pct_century = legislators / cohort) |&gt;\n  ungroup()\n\n\npct_centuries |&gt;\n  filter(date &gt;= \"2018-12-31\") |&gt;\n  arrange(date, century)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                date\n                century\n                legislators\n                cohort\n                pct_century\n              \n        \n        \n        \n                \n                  2018-12-31\n                  20\n                  122\n                  539\n                  0.2263451\n                \n                \n                  2018-12-31\n                  21\n                  417\n                  539\n                  0.7736549\n                \n                \n                  2019-12-31\n                  20\n                   97\n                  537\n                  0.1806331\n                \n                \n                  2019-12-31\n                  21\n                  440\n                  537\n                  0.8193669\n                \n        \n      \n    \n\n\n\nThe second approach results in one row per year, with a column for each century, a table format that may be easier to scan for trends:\n\npct_centuries |&gt;\n  pivot_wider(id_cols = \"date\",\n              names_from = \"century\",\n              names_prefix = \"pct_\",\n              names_sort = TRUE,\n              values_from = \"pct_century\",\n              values_fill = 0) |&gt;\n  select(date, starts_with(\"pct_\")) |&gt;\n  filter(date &gt;= \"2017-12-31\") |&gt;\n  arrange(date) \n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                date\n                pct_18\n                pct_19\n                pct_20\n                pct_21\n              \n        \n        \n        \n                \n                  2017-12-31\n                  0\n                  0\n                  0.2304833\n                  0.7695167\n                \n                \n                  2018-12-31\n                  0\n                  0\n                  0.2263451\n                  0.7736549\n                \n                \n                  2019-12-31\n                  0\n                  0\n                  0.1806331\n                  0.8193669\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n\n\n\nFigure 3.11: Percent of legislators each year, by century first elected\n\n\n\n\n\nWe can graph the output, as in Figure 3.11, to see how newer cohorts of legislators gradually overtake older cohorts, until they themselves are replaced by new cohorts.\nRather than cohorting on first_term, we can cohort on tenure instead. Finding the share of customers who are relatively new, are of medium tenure, or are long-term customers at various points in time can be insightful. Let’s take a look at how the tenure of legislators in Congress has changed over time.\nThe first step is to calculate, for each year, the cumulative number of years in office for each legislator. Since there can be gaps between terms when legislators are voted out or leave office for other reasons, we’ll first find each year in which the legislator was in office at the end of the year in cohort_data. Then we’ll use a count window function, with the window covering the rows unbounded preceding, or all prior rows for that legislator, and CURRENT ROW:\n\ncohorts &lt;-\n  cohort_data |&gt;\n  group_by(id_bioguide) |&gt;\n  window_order(date) |&gt;\n  mutate(cume_years = cumsum(as.integer(!is.na(date)))) |&gt;\n  ungroup() |&gt;\n  window_order() |&gt;\n  select(id_bioguide, date, cume_years)\n\nNext, count the number of legislators for each combination of date and cume_years to create a distribution:\n\ncohort_stats &lt;-\n  cohorts |&gt;\n  group_by(date, cume_years) |&gt;\n  summarize(legislators = n_distinct(id_bioguide),\n            .groups = \"drop\") |&gt;\n  arrange(date, cume_years) \n\ncohort_stats\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                date\n                cume_years\n                legislators\n              \n        \n        \n        \n                \n                  1789-12-31\n                  1\n                  89\n                \n                \n                  1790-12-31\n                  1\n                   6\n                \n                \n                  1790-12-31\n                  2\n                  89\n                \n                \n                  1791-12-31\n                  1\n                  37\n                \n        \n      \n    \n\n\n\nBefore calculating the percentage for each tenure per year and adjusting the presentation format, we might want to consider grouping the tenures. A quick profiling of our results so far reveals that in some years, almost 40 different tenures are represented. This will likely be difficult to visualize and interpret:\n\ncohort_stats |&gt;\n  group_by(date) |&gt;\n  summarize(tenures = n(), .groups = \"drop\") |&gt;\n  arrange(desc(date))\n\nWarning: ORDER BY is ignored in subqueries without LIMIT\nℹ Do you need to move arrange() later in the pipeline or use window_order() instead?\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                date\n                tenures\n              \n        \n        \n        \n                \n                  2019-12-31\n                  36\n                \n                \n                  2018-12-31\n                  37\n                \n                \n                  2017-12-31\n                  36\n                \n                \n                  2016-12-31\n                  37\n                \n        \n      \n    \n\n\n\nAs a result, we may want to group the values. There is no single right way to group tenures. If there are organizational definitions of tenure groups, go ahead and use them. Otherwise, I usually try to break them up into three to five groups of roughly equal size. Here we’ll group the tenures into four cohorts, where cume_years is less than or equal to 4 years, between 5 and 10 years, between 11 and 20 years, and equal to or more than 21 years:\n\ndf_fig_4_14 &lt;-\n  cohorts |&gt;  \n  collect() |&gt;\n  mutate(tenure = cut(cume_years, \n                      breaks = c(0, 5, 11, 21, Inf), \n                      labels = c(\"1 to 4\", \"5 to 10\", \"11 to 20\", \"21+\"),\n                      right = FALSE)) |&gt;\n  group_by(date, tenure) |&gt;\n  summarize(legislators = n_distinct(id_bioguide),\n            .groups = \"drop\") |&gt;\n  group_by(date) |&gt;\n  mutate(pct_legislators = legislators / sum(legislators)) |&gt;\n  ungroup()\n\n\n\n\n\n\n\nUsing cut()\n\n\n\nI “cheated” a little in the code above, as I brought the data into R using collect() so I could apply cut() to put the data into bins.\nIs there a way to bin the data using SQL without resorting to complex CASE WHEN statements? A natural way to do this is to use the relational nature of SQL and create a table of bins that is then joined to the data. Note that I keep cut in the data so that fct_reorder() can use it to organize the data correctly for graphing.\n\nbins &lt;- \n  tibble(bin = c(\"1 to 4\", \"5 to 10\", \"11 to 20\", \"21+\"),\n         cut = c(0, 5, 11, 21)) |&gt;\n  copy_to(db, df = _, name = \"bins\", overwrite = TRUE) |&gt;\n  mutate(bin_min = cut, bin_max = coalesce(lead(cut), Inf))\n\ndf_fig_4_14 &lt;-\n  cohorts |&gt;  \n  inner_join(bins, \n             join_by(cume_years &gt;= bin_min, cume_years &lt; bin_max)) |&gt;\n  rename(tenure = bin) |&gt;\n  group_by(date, tenure, cut) |&gt;\n  summarize(legislators = n_distinct(id_bioguide),\n            .groups = \"drop\") |&gt;\n  group_by(date) |&gt;\n  mutate(pct_legislators = legislators / sum(legislators)) |&gt;\n  ungroup()\n\n\n\nThe graphing of the results in Figure 3.12 shows that in the early years of the country, most legislators had very little tenure. In more recent years, the share of legislators with 21 or more years in office has been increasing. There are also interesting periodic increases in 1-to-4-year-tenure legislators that may reflect shifts in political trends.\n\n\n\n\n\n\n\n\nFigure 3.12: Percent of legislators by number of years in office\n\n\n\n\n\nA cross section of a population at any point in time is made up of members from multiple cohorts. Creating a time series of these cross sections is another interesting way of analyzing trends. Combining this with insights from retention can provide a more robust picture of trends in any organization.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Cohort Analysis -- `dbplyr` version</span>"
    ]
  },
  {
    "objectID": "dbplyr.html#conclusion",
    "href": "dbplyr.html#conclusion",
    "title": "3  Cohort Analysis – dbplyr version",
    "section": "3.6 Conclusion",
    "text": "3.6 Conclusion\nCohort analysis is a useful way to investigate how groups change over time, whether it be from the perspective of retention, repeat behavior, or cumulative actions. Cohort analysis is retrospective, looking back at populations using intrinsic attributes or attributes derived from behavior. Interesting and hopefully useful correlations can be found through this type of analysis. However, as the saying goes, correlation does not imply causation. To determine actual causality, randomized experiments are the gold standard. Chapter 7 will go into depth on experiment analysis.\nBefore we turn to experimentation, however, we have a few other types of analysis to cover. Next we’ll cover text analysis: components of text analysis often show up in other analyses, and it’s an interesting facet of analysis in itself.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Cohort Analysis -- `dbplyr` version</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Tanimura, C. 2021. SQL for Data Analysis. O’Reilly Media. https://books.google.com.au/books?id=ojhCEAAAQBAJ.",
    "crumbs": [
      "References"
    ]
  }
]