# Un intermezzo

I take a brief pause in this chapter to organize some bigger-picture thoughts about Chapter 4 of @tanimura2021sql.

My first thought is that the distinctions between each pair of the four types of cohort analysis identified by @tanimura2021sql [p. 124] are not equally sharp or stark.
One distinction between retention and survivorship appears to turn on whether the activity engaged involves "repeated actions" or not.
While this distinction certainly matters from a data analysis perspective, it's not clear that it's central to the analysis and my inclination is to view survivorship as the more fundamental idea underlying both.

A more important distinction between retention and survivorship analysis in the taxonomy of Chapter 4 of @tanimura2021sql relates to whether a cohort member can exit the data and return at a later date.
@tanimura2021sql [p. 124] suggests that retention analysis is "concerned with whether the cohort member has a record in the time series on a particular date, expressed as a number of periods from the starting date."
This description allows for an individual to be in the sample at time $0$ and time $2$ even if not in the sample at time $1$.
Elsewhere @tanimura2021sql [p. 127] suggests that often "a cohort can lose but cannot gain new members once it is formed."
I argue that the distinction between analyses where exit can happen only once from those where re-entry is possible is a more fundamental distinction and I discuss it in more detail below.

Returnship, the third type of cohort analysis identified by @tanimura2021sql, seems to be one of repeated actions occurring "more than some minimum threshold of times", thus putting it close to retention.

Finally, cumulative analyses "are concerned with the total number of times or amounts measured at one or more fixed time windows".
In a sense, returnship seems to involve counting over windows, while cumulative analysis likely requires summing of some measure.
Given that a count is simply a sum of ones that indicate an action, this suggests that returnship is often perhaps a species of cumulative analysis.

**Rewrite this paragraph once structure is understood.**
@tanimura2021sql seems to concur regarding the existence of fundamental links between the four types of analysis, but elects to treat retention as the basic building block.
While there is merit to this view, my inclination is to consider survivorship as the elemental analysis and to build up from there.
My hunch is that a lot of the work in Chapter 4 of @tanimura2021sql can be better understood if one begins each analysis with a step that organizes survivorship data into a canonical structure.

```{r}
#| warning: false
#| include: true
library(DBI)
library(tidyverse)
library(dbplyr)
library(ggplot2)
library(farr)
library(jsonlite)
```

```{r}
#| include: false
#| eval: true
# options("tinytable_tt_digits" = 4)
Sys.setenv(DATA_DIR = "data")

library(tinytable)

options(tinytable_theme_spacing_rowsep = 0.0)
options(tinytable_theme_spacing_colsep = 0.1)
```

```{r}
#| include: false
#| eval: true
print.tbl_sql <- function(x, ...) {
  collect(x, n = 10) |> 
    tt(...) |>
    theme_tt("spacing") |>
    knitr::knit_print()
}

registerS3method("print", "tbl_sql", print.tbl_sql)
```


```{r}
#| include: true
db <- dbConnect(duckdb::duckdb())
```

```{r}
#| include: true
legislators_terms <- load_parquet(db, "legislators_terms")
legislators <- load_parquet(db, "legislators")
```

In addition to the two tables above, in this chapter I will use an additional data frame with data on congressional terms.

```{r}
congress_terms <- load_parquet(db, "congress_terms")
```

## Survival data: The basic building block

@singer2003longitudinal [p. 306] suggest that "researchers use **survival analysis** in a variety of contexts that share a common characterisit: interest centers on describing *whether events occur* or *when events occur*."

### Survival: Once-only events

Often analytical simplicity is obtained by defining the event in such a way that it can happen at most once.
@singer2003longitudinal provide examples such as time to relapse among recently treated alcoholic and age at first suicide ideation.
While one could track alcoholics over an extended period that allows them the opportunity to relapse, re-enter treatment, and then perhaps relapse again, by defining relapse as the first such event after treatment, it can occur at most once.
In other settings, events occur at most once for each individual (e.g., death for most individual humans).

I suggest that the canonical form of data for survival analysis is a table with the following columns:

 - Identifier: One more columns that identify the individuals in the sample.
 In the legislator data, this would be `id_bioguide`.
 - Entry date: The relevant start date for the individual
 - Event date: The date, if any, on which the relevant event occurs for the individual.

Most queries involving cohorts in @sec-original do not use a survivorship approach.^[Most queries uses what I call a census-date approach that I discuss in @sec-census-date.]
The queries using a survivorship approach are given in @sec-survivorship.

Interestingly, @tanimura2021sql [p. 124] suggests that what distinguishes survivorship analysis is that "instead of calculating whether an entity was present in a certain period [as in retention analyis], we calculate whether the entity is present in that period or later in the time series."
With *senso strictu* survivorship analysis where the "event" is death, the event only occurs once.
So if an individual is alive both before and after a given date, then that individual must be alive on that date and there is no distinction between an entity being present in a certain period and that entity being present in that period or later in the time series.
Similar logic applies to other once-only events such as first relapse or first ideation of suicide: if the event had not occurred by a date later than $t$, then it has not occurred by $t$.
As such the primary distinction I make here is the not the same distinction as that made in @tanimura2021sql.

Before moving on to discuss the census-date approach, I spend some time considering the approaches used in @sec-survivorship.
The first query [@tanimura2021sql, p. 154--155] effectively organizes the data into the canonical form for survival data with `first_century` as the cohort, except that the exit date is measured as `term_start` for each legislator's last term.^[The choice of `term_start` rather than `term_end` is an odd one that is justified by the notion that "we don't need to know the specific dates of each term" because of a focus on "the share of legislators who survived in office for a decade or more after their first term started" [@tanimura2021sql, p. 154].
Of course, a two-term senator will serve for 12 years, but the tenure calculated in this way would be six years rather than 12, which would seem to be a serious error.]
In effect, any gaps in a legislator's term are filled in in the sense that any legislator with a term covering any period after five years would be deemed to have "survived" for five years.

What is not clear from @tanimura2021sql is why one would prefer "survivorship" analysis (with filling-in) over "retention" analysis, as there is no real context given for the queries.
One example that is given does not help much: "if we are concerned about the number of students who are still in school after a certain number of years, we could look for the absence of a graduation event in a data set" [@tanimura2021sql, p. 154].
But suppose our cohort comprises students who begin high school, where high school is understood as covering grades 9 through 12.
It would not seem correct to treat a student who completed grades 9 and 10, then dropped out for a year before returning to complete the eleventh grade and then dropping out again as having "survived" four years of high school.

In contrast, there are clear analytical benefits to focuses on once-only events.
Apart from simplifying data collation, a focus on once-only events allows an analyst to deploy the extensive analytical machinery available for survival analysis.
For example, @singer2003longitudinal "focuses exclusively on the most common and fundamental problem: the analysis of single spells [i.e., once-only events]" [p. 311].
@singer2003longitudinal provides tools for discrete-time and continuous-time analyses, including the Cox regression model and extensions to that model.
While such models are beyond the scope of this book, they can be implemented once an analyst has organized the data into the canonical form for survival data.
My focus here is on organizing data for analysis.

### Survival: Censoring
 
Note that we will often not observe event dates for many observations due to **censoring**.
While events may be inevitable for any given individual (the proverbial death and taxes), such events need not occur during the period covered by the sample under study.
This fact may not always be obvious from the data set in question.

To illustrate this point, I consider the legislators data .
It is important to recognize that the data in `legislators` and `legislators_terms` were obtained at some unspecified date in the past.

```{r}
max_term_start <-
  legislators_terms |>
  summarize(max(term_start, na.rm = TRUE)) |>
  pull()

max_term_start
```

As we can see there are no terms in the data *starting* after the November 2020 election, suggesting that the data were extracted before terms related to that election started.
Looking at the `term_end` dates, we see that no member of the House of Representatives (`term_type == "rep"`) has a term ending after 3 January 2021.

```{r}
legislators_terms |>
  filter(term_end >= max_term_start) |>
  count(term_type, term_end) |>
  arrange(term_type, term_end)
```

As we are in "the future" with regard to whenever the legislators data were extracted, we can gain some insight into when the data were collected by looking at the data we can get today from the GitHub repository from which the data were obtained.
The data on legislators' terms are divided into two JSON files---one for current legislators and one for past legislators.
Using JSON wrangling of the kind I have [written about in the past](https://github.com/iangow/notes/blob/main/sec_submissions.pdf), `get_terms()` processes either of these two files and returns a data frame.

```{r}
get_terms <- function(file) {

  url <- str_c("https://theunitedstates.io/congress-legislators/", file)
  
  tibble(json = list(read_json(url))) |>
    unnest_longer(json) |>
    unnest_wider(json) |>
    select(id, terms) |>
    unnest_wider(id) |> 
    select(bioguide, terms) |>
    unnest_longer(terms) |>
    unnest_wider(terms) |>
    select(bioguide, type, start, end, state, district, party, url,  class) |>
    rename_with(\(x) str_c("term_", x), c(type, start, end)) |>
    rename(id_bioguide = bioguide)
}
```

I apply `get_terms()` twice to get the data and combine them and push them to the DuckDB database instance containing the older data sets we have.

```{r}
updated_terms <-
  get_terms("legislators-current.json") |>
  bind_rows(get_terms("legislators-historical.json")) |>
  copy_to(db, df = _, name = "updated_terms", overwrite = TRUE)
```

Finally, I join the old and new data and look for case where the updated `term_end` differs from that in the older data set.
Such cases are shown in @tbl-changed-term-ends.

```{r}
#| label: tbl-changed-term-ends
#| tbl-cap: Legislators with changed `term_end` values in updated data
legislators |>
  select(id_bioguide, full_name) |>
  inner_join(updated_terms, by = "id_bioguide") |>
  inner_join(legislators_terms,
             by = c("id_bioguide", "term_start"),
             suffix = c("_updated", "")) |>
  filter(term_end != term_end_updated) |>
  select(full_name, term_type, term_start, term_end,
         term_end_updated) |>
  arrange(term_end_updated) 
```

Looking at the table, we see that the earliest updated `term_end` relates to John Lewis, a civil rights icon and long-time legislator who passed away on 17 July 2020.
It seems reasonable to assume that the data were collated prior to that date and, lacking more precise information, I assume that the extraction date was 30 June 2020.

```{r}
extract_date <- as.Date("2020-06-30")
```

Once we fix `extract_date`, we should consider all `term_end` dates after that date as merely *expected* `term_end` dates, as subsequent events might have led to some members of Congress to finish their terms early.
For this reason, it might seem appropriate to code such `term_end` values as "don't know" or `NA` (`NULL` in SQL).
This is especially so when we view `last_term` as representing the end of a legislator' career, as we simply don't know when a legislator's career will end.
But coding the data in this way would lead to a loss of the information impounded in the fact that a legislator's term has extended at least as far as 30 June 2020.
For this reason, the standard approach is to code `term_end` as the last observed date and create an indicator variable that informs users of the data that the data have been censored for this observation.
The following code creates `survival_data`, a data frame containing legislator data in canonical survival form.
A sample of these data is provided in @tbl-survival-canonical.

```{r}
survival_data <-
  legislators_terms |>
  group_by(id_bioguide) |>
  summarize(entry_date = min(term_start, na.rm = TRUE),
            exit_date = max(term_end, na.rm = TRUE),
            .groups = "drop") |>
  mutate(censored = exit_date > extract_date,
         exit_date = if_else(censored, extract_date, exit_date))
```

```{r}
#| label: tbl-survival-canonical
#| tbl-cap: Legislator data in canonical survival form
survival_data
```

@tanimura2021sql does not address the issue of censoring.
This likely reflects the emphasis of that book on preparing data for descriptive analysis in business contexts rather than on more sophisticated statistical analysis, such as that appearing in scientific journals.
However, it is important to account for censoring for many practical business questions.
For instance, Chapter 7 of @tanimura2021sql discusses experimental analysis and one could imagine looking at the effects on customer retention of some marketing initiative using A/B testing of the kind studied there.
In this sitation, it will be common for the retention periods for some customers to be censored.

It is worth noting that what I am calling a canonical form for survival data differs from what @singer2003longitudinal call the **person-level** form of data.
The main difference in the person-level form seen in Figure 10.4 of @singer2003longitudinal [p. 353] is that (using variable names from our current context) `entry_date` and `exit_date` have been converted into a "time to event" form reflecting the number of units of time between `entry_date` and `exit_date`.
One corollary of this aspect of the person-level form is, as pointed out by @singer2003longitudinal [p. 310], a need to specify a "metric for clocking time" (e.g., days or years).
With the canonical data form I present here, I effectively *defer* the need to choose the metric; as will be seen one cannot *avoid* this choice.



### Events that can happen more than once: The census-date approach {#sec-census-date}

In many contexts, the event of interest will be a once-only event.
In some cases, the one-off nature of the event will be a function of the underlying realities (e.g., *senso strictu* survivorship analysis in which individuals only die once).
In other cases, the one-off nature of the event will derive from the definition employed by the researcher (e.g., first relapse in the study of alcoholism above).
The latter set might be driven by what is of greatest interest to researchers, or the definition may lead to simplifications with analytical benefits.

However in many cases it will be important to recognize that events can occur for an individual more than once.
A subscription streaming service such as Netflix or Max will have customers who sign up for a monthly subscription, drop off some months later, then rejoin at a later date.
Ignoring this behaviour in analysis would be problematic if it is common enough to represent a significant portion of a service's business.

There are two approaches to addressing these situations.
One approach is to focus analysis on "whether the cohort member has a record in the time series on a particular date, expressed as a number of periods from the starting date" [@tanimura2021sql, p. 124].
There is a little ambiguity embedded in this sentence regarding how the term "period" is defined.
One definition turns on dates specific to an individual, such as age, which is typically reckoned as the number of birthdays an individual has experienced.^[Things might be different for people born on 29 February.]
Another definition, which I call the **census-date approach**, reckons periods using a common date across individuals or cohorts.

Each census-date analysis in @sec-original uses 31 December of each year as the census date.
For reasons we will learn about in @sec-stints, the choice of 31 December is appropriate because the *apparent* gaps that appear in the tenures of legislators in certain parts of the year do not affect 31 December.

### Events that can happen more than once: Stints {#sec-stints}

The Oxford English Dictionary defines a **stint** as "a person's fixed or allotted period of work."
In the current context, I define a stint as a continuous period in office either as a representive or as a senator including periods that comprise multiple terms.
The critical thing for current purposes is that one can have more than one stint as a legislator.
One could have one stint as representative, followed by a stint as senator, followed by a second stint as representative.
An alternative term a stint might be a **spell**, as used by @singer2003longitudinal [p. 311] in a quote above.

As always, to better understand the issues one faces in practice, it is helpful to look at real data.
I start with data in `legislators_terms` related to Nancy Pelosi, a long-serving representative from California.

```{r}
pelosi_terms <-
  legislators_terms |> 
  filter(id_bioguide == "P000197") |>
  select(id_bioguide, term_type, term_start, term_end, state, district)
```

```{r}
#| echo: false
#| label: tbl-pelosi-terms
#| tbl-cap: Congression terms of Nancy Pelosi
pelosi_terms |>
  arrange(term_start) |> 
  collect() |>
  tt() |>
  style_tt(fontsize = 0.8) |>
  theme_tt("spacing")
```

As can be seen in @tbl-pelosi-terms, Nancy Pelosi had served continuously since 1987.^[The `legislators_terms` data set ends before Pelosi's term ending in January 2021. From that data set, it is not clear that Pelosi was elected to additional terms beginning in 2021 and 2023.]
She started out as the repsentative for California's 5th congressional district, then for its 8th, then for its 12th.^[According to [Wikipedia](https://en.wikipedia.org/wiki/Nancy_Pelosi#Electoral_history), the shifts from one district to another were due to redistricting, or the redrawing of electoral boundaries as population numbers changed.]
In other words, Pelosi has had a single stint as a legislator.

It might seem from Nancy Pelosi's later terms that we could identify continuing stints by comparing `term_start` with the preceding `term_end` value and coding two terms as part of the same stint if the dates are the same.
This approach would work, for example, for the term starting `2019-01-03` and the preceding term ending the same day.

However, if we calculate `gap`, the number of days between the end of the previous term and the start of the current one, we see that there is often a non-zero gap between terms as coded in the `legislators_terms` data set.
This can be seen in @tbl-pelosi-term-gaps, which presents data from `pelosi_term_gaps` calculated below.

```{r}
pelosi_term_gaps <-
  pelosi_terms |>
  group_by(id_bioguide) |>
  window_order(term_start) |>
  mutate(gap = term_start - lag(term_end)) |>
  ungroup() |>
  select(id_bioguide, term_type, term_start, term_end, gap)
```

```{r}
#| echo: false
#| label: tbl-pelosi-term-gaps
#| tbl-cap: Congression terms of Nancy Pelosi with `gap`
pelosi_term_gaps |>
  arrange(term_start) |>
  collect(n = 8) |>
  tt() |>
  theme_tt("spacing")
```

In @tbl-pelosi-term-gaps, we can see that there are gaps of as much as 4 days between the end of one term and the start of the next.
These gaps would be problematic for a census-date approach that used 4 January as the census date, as Nancy Pelosi would appear *not* to be a legislator on that date in 1993, 1997, or 1999.
In contrast, the census-date approach using 31 December would not be affected by these gaps.

The shortness of the gaps above raises the possibility that one approach would be to consider two terms to be part of the same stint if there is just a short gap between them.
But what is a "short gap" for this purpose?
Would four days suffice?
Looking at the terms of James Abdnor (`id_bioguide == "A000009")`) in @tbl-bbdnor-term-gaps suggests not.

```{r}
#| echo: false
#| label: tbl-bbdnor-term-gaps
#| tbl-cap: Congression terms of James Abdnor
legislators_terms |>
  filter(id_bioguide == "A000009") |>
  group_by(id_bioguide) |>
  window_order(term_start) |>
  mutate(gap = term_start - lag(term_end)) |>
  ungroup() |>
  window_order() |>
  select(id_bioguide, term_type, term_start, term_end, gap) |>
  arrange(term_start) |>
  collect() |>
  tt() |>
  theme_tt("spacing")
```

So maybe a month (say 30 days)?
Looking at the terms of John Quincy Adams (`id_bioguide == "A000041")`) in @tbl-bbdnor-term-gaps, it seems this would not work.

```{r}
#| echo: false
#| label: tbl-adams-term-gaps
#| tbl-cap: Congression terms of John Quincy Adams
legislators_terms |>
  filter(id_bioguide == "A000041") |>
  group_by(id_bioguide) |>
  window_order(term_start) |>
  mutate(gap = term_start - lag(term_end)) |>
  ungroup() |>
  select(id_bioguide, term_type, term_start, term_end, gap) |>
  arrange(term_start) |>
  collect() |>
  tt() |>
  theme_tt("spacing")
```

What's going on here?
If we go to the [website of the United States Senate](https://www.senate.gov/legislative/DatesofSessionsofCongress.htm), we can see that sessions of Congress often began later in the year in the 19th century.
Furthermore, the `term_start` data in `legislators_terms` appear to be based on the dates on which legislative sessions started.
Data on these dates---derived from the United States Senate website---are contained in `congress_terms`.

```{r}
congress_terms
```

```{r}
congress_terms |> 
  window_order(term_start) |> 
  count(same_year = year(term_start) != year(lag(term_end)))
```



```{r}
stints_raw <-
  legislators_terms |>
  group_by(id_bioguide, term_type) |>
  window_order(term_start) |>
  mutate(same_year = year(term_start) == year(lag(term_end)),
         new_stint = is.na(same_year) | !same_year) |>
  group_by(id_bioguide) |>
  window_order(term_start) |>
  mutate(stint_number = cumsum(as.integer(new_stint))) |>
  ungroup() |>
  arrange(id_bioguide, term_start) |>
  select(id_bioguide, term_type, term_start, term_end, 
         same_year, new_stint, stint_number) |>
  compute()
```



```{r}
stints <-
  stints_raw |>
  group_by(id_bioguide, term_type, stint_number) |>
  summarize(stint_start = min(term_start, na.rm = TRUE),
            stint_end = max(term_end, na.rm = TRUE),
            .groups = "drop")
```

```{r}
legislators |>
  select(id_bioguide, full_name) |>
  inner_join(stints, by = "id_bioguide") |> 
  filter(id_bioguide %in% c("P000197", "A000009", "A000041")) |> 
  arrange(id_bioguide, stint_start)
```

```{r}
stints |> count(stint_number)
```
```{r}
six_stinters <-
  stints |>
  filter(stint_number == 6) |>
  distinct(id_bioguide) |>
  inner_join(legislators, by = "id_bioguide") |>
  select(id_bioguide, full_name) |>
  inner_join(stints, by = "id_bioguide") |> 
  arrange(id_bioguide, stint_start) 
```


```{r}
#| echo: false
#| label: tbl-six-stints
#| tbl-cap: Legislators with six stints
six_stinters |>
  collect() |>
  tt() |>
  theme_tt("spacing")
```


## Adding cohorts: The canonical form

```{sql}
#| connection: db
CREATE OR REPLACE TABLE date_dim AS
WITH dates AS 
  (
    SELECT generate_series::date AS date
    FROM generate_series(DATE '1770-01-01', 
                         DATE '2030-12-31',
                         INTERVAL '1 day') )
SELECT date, 
  strftime(date, '%B') AS month_name,
  strftime(date, '%-d') AS day_of_month,
  year(date) AS year
FROM dates;
```

```{r}
date_dim <- tbl(db, "date_dim")
```

```{r}
year_ends <-
  date_dim |>
  filter(month_name == 'December', day_of_month == 31) |>
  select(date)
```

### Cohorts considered in @tanimura2021sql

There are several different cohorts uses in analyses in Chapter 4 of @tanimura2021sql.
Note that not all analyses involve cohorts. For example, pp. 170--171.

 - `first_year`
 - `first_century` (also called `cohort_century` or `century`)
 - `first_state`
 - `gender`
 - `first_state` and `gender`
 - `term_type`
 - `first_century` and `first_type`
 - `date` (last day of the year) and `century` (`last_century`?)
 
If you read @sec-original carefully, you will see that any individual legislator is placed in no more than one cohort in any analysis.
As such one particulaly clean (and clear) approach would create a table comprising the individual identifier (`id_bioguide`) and the cohort assignment for each individual.
For example, the following code creates a `first_centuries` with cohort assignments for `first_century`.

```{r}
first_centuries <-
  legislators_terms |>
  group_by(id_bioguide) |>
  summarize(first_century = century(min(term_start, na.rm = TRUE)),
            .groups = "drop")
```

### Census dates

Why do we need to use census dates?

One reason would seem to be to accounting for breaks in tenures.
Is this intentional in all cases?

Another reason would appear to relate to data collection strategies.

Finally, is there something about discretizing the data on periods?

```{r}
cohorts <-
  first_centuries |>
  inner_join(survival_data, by = "id_bioguide") |>
  mutate(exit_date = coalesce(exit_date, extract_date)) |>
  left_join(year_ends, 
             join_by(between(y$date, x$entry_date, x$exit_date))) |>
  mutate(period = coalesce(year(age(date, entry_date)), 0)) |>
  group_by(first_century, period) |>
  summarize(cohort_retained = n_distinct(id_bioguide),
            .groups = "drop")
```

```{r}
cen_pct_retaineds <-
  cohorts |>
  group_by(first_century) |>
  window_order(period) |>
  mutate(cohort_size = first(cohort_retained),
         pct_retained = cohort_retained / cohort_size) |>
  ungroup() |>
  select(first_century, period, cohort_size, cohort_retained,
         pct_retained)

cen_pct_retaineds |>
  arrange(first_century, period)
```
